NITEXT

Shair Ahmad Antonio Ambrosetti
A Textbook on Ordinary Differential Equations
Second Edition
123

UNITEXT ­ La Matematica per il 3+2
Volume 88

More information about this series at http://www.springer.com/series/5418

Shair Ahmad Antonio Ambrosetti
A Textbook on Ordinary Differential Equations
Second Edition

Shair Ahmad Department of Mathematics University of Texas at San Antonio San Antonio, USA

Antonio Ambrosetti SISSA Trieste, Italy

UNITEXT ­ La Matematica per il 3+2

ISSN 2038-5722

ISSN 2038-5757 (electronic)

ISBN 978-3-319-16407-6

ISBN 978-3-319-16408-3 (ebook)

DOI 10.1007/978-3-319-16408-3

Springer Cham Heidelberg New York Dordrecht London

Library of Congress Control Number: 2015932461

© Springer International Publishing Switzerland 2015 This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed. The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, express or implied, with respect to the material contained herein or for any errors or omissions that may have been made.

Cover Design: Simona Colombo, Giochi di Grafica, Milano, Italy Typesettingwith LATEX: PTP-Berlin,Protago TEX-ProductionGmbH, Germany (www.ptp-berlin.eu)

Springer is a part of Springer Science+Business Media (www.springer.com)

Professor Shair Ahmad wishes to thank his wife, Carol, for her continued and loving support, patience and understanding, which go far beyond what might normally be expected. He also wishes to acknowledge his grandson, Alton Shairson, as a source of infusion of energy and optimistic enthusiasm for life.

Preface
One of the authors' main motivations for writing this book has been to provide students and faculty with a more economical option when selecting an introductory textbook on ordinary differential equations (ODEs). This book is a primer on the theory and applications of ODEs. It is aimed at students of Mathematics, Physics, Engineering, Statistics, Information Science, etc. who already possess a sufficient knowledge of calculus and a minimal knowledge of linear algebra.
The first chapter starts with the simplest first-order linear differential equations and builds on this to lead to the more general equations. The concepts of initial values and existence and uniqueness of solutions are introduced early in this chapter. Ample examples, using simple integration, are provided to motivate and demonstrate these concepts. Almost all of the assertions are proved in elementary and simple terms.
The important concepts of the Cauchy problem and the existence and uniqueness of solutions are covered in detail and demonstrated by many examples. Proofs are given in an Appendix. There is also a rigorous treatment of some qualitative behavior of solutions. This chapter is important from a pedagogical point of view because it introduces students to rigor and fosters an understanding of important concepts at an early stage.
In a chapter on nonlinear first-order equations, students will learn how to explicitly solve certain types of equations, such as separable, homogeneous, exact, Bernoulli and Clairaut equations. Further chapters are devoted to linear higher order equations and systems, with several applications to mechanics and electrical circuit theory. Also included is an elementary but rigorous introduction to the theory of oscillation.
A chapter on phase plane analysis deals with finding periodic solutions, solutions of simple boundary value problems, and homoclinic and heteroclinic trajectories. There is also a section on the Lotka­Volterra system in the area of population dynamics.
Subsequently, the book deals with the Sturm­Liouvilleeigenvalues, Laplace transform and finding series solutions, including fairly detailed treatment of Bessel functions, which are important in Engineering.
Although this book is mainly addressed to undergraduate students, consideration is given to some more advanced topics, such as stability theory and existence of so-

viii Preface
lutions to boundary value problems, which might be useful for more motivated undergraduates or even beginning graduate students.
A chapter on numerical methods is included as an Appendix, where the importance of computer technology is pointed out. Otherwise, we do not encourage the use of computer technology at this level. We believe that, at this stage, students should practice their prior knowledge of algebra and calculus instead of relying on technology, thus sharpening their mathematical skills in general.
Each chapter ends with a set of exercises that are intended to test the student's understanding of the concepts covered. Solutions to selected exercises are included at the end of the book.
We wish to acknowledge with gratitude the help of Dung Le, Rahbar Maghsoudi and Vittorio Coti Zelati, especially with regard to technical issues.

San Antonio and Trieste December 2013

Shair Ahmad Antonio Ambrosetti

Preface to the Second Edition

This edition contains corrections of errata and additional carefully selected exercises and provides more lucid explanations of some of the topics addressed. Although the book is written in a rigorous and thorough style, it offers instructors the flexibility to skip some of the rigor and theory and concentrate on methods and applications, should they wish to do so. This makes the book suitable not only for students studying Mathematics but also for those in other areas of Science and Engineering. We wish to thank Weiming Cao and Erik Whalén for several useful comments.

San Antonio and Trieste January 2015

Shair Ahmad Antonio Ambrosetti

Contents
1 First order linear differential equations . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 A simple case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.3 Some examples arising in applications . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.3.1 Population dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.3.2 An RC electric circuit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.4 The general case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
2 Theory of first order differential equations . . . . . . . . . . . . . . . . . . . . . . . . 15 2.1 Differential equations and their solutions . . . . . . . . . . . . . . . . . . . . . . . 15 2.2 The Cauchy problem: Existence and uniqueness . . . . . . . . . . . . . . . . . 17 2.2.1 Local existence and uniqueness . . . . . . . . . . . . . . . . . . . . . . . . 18 2.2.2 Global existence and uniqueness . . . . . . . . . . . . . . . . . . . . . . . 24 2.3 Qualitative properties of solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 2.4 Improving the existence and uniqueness results . . . . . . . . . . . . . . . . . 30 2.5 Appendix: Proof of existence and uniqueness theorems . . . . . . . . . . . 32 2.5.1 Proof of Theorem 2.4.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 2.5.2 Proof of Theorem 2.4.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 2.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
3 First order nonlinear differential equations . . . . . . . . . . . . . . . . . . . . . . . 39 3.1 Separable equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 3.1.1 The logistic equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 3.2 Exact equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 3.3 The integrating factor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54 3.4 Homogeneous equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 3.5 Bernoulli equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 3.6 Appendix. Singular solutions and Clairaut equations . . . . . . . . . . . . . 62 3.6.1 Clairaut equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 3.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67

x

Contents

4 Existence and uniqueness for systems and higher order equations . . . 71 4.1 Systems of differential equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 4.1.1 Existence and uniqueness results for systems . . . . . . . . . . . . . 73 4.2 Higher order equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 4.2.1 Existence and uniqueness for n-th order equations . . . . . . . . . 75 4.3 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76

5 Second order equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 5.1 Linear homogeneous equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 5.2 Linear independence and the Wronskian . . . . . . . . . . . . . . . . . . . . . . . 83 5.2.1 Wronskian . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 5.3 Reduction of the order . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88 5.4 Linear nonhomogeneous equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 5.4.1 Variation of parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91 5.5 Linear homogeneous equations with constant coefficients . . . . . . . . . 93 5.5.1 The Euler equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 5.6 Linear nonhomogeneous equations ­ method of undetermined coefficients. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101 5.6.1 The elastic spring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 5.7 Oscillatory behavior of solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110 5.8 Some nonlinear second order equations . . . . . . . . . . . . . . . . . . . . . . . . 116 5.8.1 Equations of the type F .t; x0; x00/ D 0 . . . . . . . . . . . . . . . . . . 116 5.8.2 Equations of the type F .x; x0; x00/ D 0 . . . . . . . . . . . . . . . . . 116 5.8.3 Equations of the form F .t; x; x0; x00/ D 0 with F homogenous117 5.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119

6 Higher order linear equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 6.1 Existence and uniqueness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 6.2 Linear independence and Wronskian . . . . . . . . . . . . . . . . . . . . . . . . . . 126 6.3 Constant coefficients . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127 6.4 Nonhomogeneous equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130 6.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133

7 Systems of first order equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 7.1 Preliminaries: A brief review of linear algebra . . . . . . . . . . . . . . . . . . 135 7.1.1 Basic properties of matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 7.1.2 Determinants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136 7.1.3 Inverse of a matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139 7.1.4 Eigenvalues and eigenvectors . . . . . . . . . . . . . . . . . . . . . . . . . . 140 7.1.5 The Jordan normal form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142 7.2 First order systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144 7.3 Linear first order systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146 7.3.1 Wronskian and linear independence . . . . . . . . . . . . . . . . . . . . . 148 7.4 Constant systems ­ eigenvalues and eigenvectors . . . . . . . . . . . . . . . . 152 7.5 Nonhomogeneous systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158 7.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162

Contents

xi

8 Qualitative analysis of 2 2 systems and nonlinear second order equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
8.1 Planar hamiltonian systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168
8.2 A prey-predator system . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
8.2.1 The case of fishing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
8.2.2 Improving .LV / . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
8.3 Phase plane analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178 8.4 On the equation x00 D f .x/ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
8.4.1 A first example: The equation x00 D x x3 . . . . . . . . . . . . . . 181 8.4.2 A second example: The equation x00 D x C x3 . . . . . . . . . . 183 8.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184

9 Sturm Liouville eigenvalue theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187 9.1 Eigenvalues and eigenfunctions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188 9.2 Existence and properties of eigenvalues . . . . . . . . . . . . . . . . . . . . . . . . 189 9.3 An application to the heat equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193 9.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196

10 Solutions by infinite series and Bessel functions . . . . . . . . . . . . . . . . . . . . 199 10.1 Solving second order equations by series . . . . . . . . . . . . . . . . . . . . . . . 199 10.2 Brief review of power series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199 10.3 Series solutions around ordinary points . . . . . . . . . . . . . . . . . . . . . . . . 201 10.4 The Frobenius method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206 10.5 The Bessel equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211 10.5.1 The Bessel equation of order 0 . . . . . . . . . . . . . . . . . . . . . . . . . 213 10.5.2 The Bessel equation of order 1 . . . . . . . . . . . . . . . . . . . . . . . . . 216 10.5.3 Bessel equations of order m . . . . . . . . . . . . . . . . . . . . . . . . . . . 218 10.5.4 Some properties of the Bessel functions . . . . . . . . . . . . . . . . . 219 10.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223

11 Laplace transform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225 11.1 Definition and preliminary examples . . . . . . . . . . . . . . . . . . . . . . . . . . 225 11.2 Properties of the Laplace transform . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228 11.3 Inverse Laplace transform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233 11.3.1 Convolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237 11.4 Laplace transform and differential equations . . . . . . . . . . . . . . . . . . . . 238 11.5 Generalized solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240 11.6 Appendix: The Dirac delta . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243 11.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248

12 Stability theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251 12.1 Definition of stability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251 12.2 Liapunov direct method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252 12.3 Stability of linear systems and n-th order linear equations . . . . . . . . . 254 12.3.1 Stability of 2 2 systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254 12.3.2 Stability of n n linear systems . . . . . . . . . . . . . . . . . . . . . . . . 260 12.3.3 Stability of n-th order linear equations . . . . . . . . . . . . . . . . . . . 262

xii Contents
12.4 Hamiltonian systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263 12.5 Stability of equilibria via linearization . . . . . . . . . . . . . . . . . . . . . . . . . 265
12.5.1 Stable and unstable manifolds . . . . . . . . . . . . . . . . . . . . . . . . . . 267 12.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
13 Boundary value problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275 13.1 Boundary value problems for autonomous equations . . . . . . . . . . . . . 275 13.1.1 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278 13.2 The Green function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281 13.3 Sub- and supersolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284 13.4 A nonlinear eigenvalue problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289 13.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
Appendix A. Numerical methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293 A.1 First order approximation: Euler's method . . . . . . . . . . . . . . . . . . . . . . 294 A.1.1 Improved Euler's method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295 A.2 The Runge­Kutta method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298
Answers to selected exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319

Notation

The following are some notations that are used in the book.

· N denotes the set of natural numbers 0; 1; 2 : : : · Z denotes the set of integer numbers 0; 1; 2 : : :

· R denotes the set of real numbers.

· C denotes the set of complex numbers.

· If a; b 2 R, OEa; b denotes the closed interval ¹a Ä t Ä bº; .a; b/, or a; bOE,

denotes the open interval ¹a < t < bº. Moreover .a; b, or a; b, denotes the

interval ¹a < t Ä bº, while OEa; b/, or OEa; bOE, denotes the interval ¹a Ä t < bº. · If x; y 2 Rn, .x j y/ D P xi yi denotes the euclidean scalar product of the vec-

tors x; y, with components xi ; yi , i D 1; : : : ; n. In some case we will also use

x by

y jx

or .x; y/ p
j D .x

jinxs/teDadqofP.xxi2j

y/. The . If n D

corresponding euclidean norm is denoted 1 then jxj is the usual absolute value.

·

dkf dtk

D f .k/ denotes the k-th derivative of f .t/.

·

@f @xi

D @xi f

D fxi denotes the partial derivative of f .x1; : : : ; xn/ with respect

to xi.

· If Â Rn, C. ; R/, or simply C. /, is the class of continuous real valued functions f W ! 7 R defined on . C. ; Rm/ is the class of continuous functions f defined on with values in Rm.

· If Â Rn is an open set, C k. ; R/, or simply C k. /, is the class of real valued functions f W ! 7 R which are k times continuously differentiable. C. ; Rm/ is the class of functions f W 7! Rm, each component of which is k times con-
tinuously differentiable. Functions that are differentiable infinitely many times are
often called regular.

· W .f1; : : : ; fn/.t/ D W .f1.t/; : : : ; fn.t// D W .t/ represents the Wronskian of the functions f1; : : : ; fn.

· Jm = Bessel function of order m.

xiv Notation

· f g = convolution of the functions f and g.

· i.t/ = the Dirac delta function.

· Det(A) = determinant of the matrix A.

· Akl = Minor of the element akl , Ckl = cofactor of the element akl .

· L¹f .t/º.s/ D F .s/ = the Laplace transform of the function f .

· rV .x/ D .Vx1 .x/; : : : ; Vxn .x//, x 2 Rn, denotes the gradient of the real valued

function V .

·

.rV

.x /

j

f

.x//

D

Pn
1

Vxi

.x/fxi

.x/

=

scalar

product

of

rV

.x/

and

f

.x /.

1 First order linear differential equations

1.1 Introduction

A differential equation is an equation involving an unknown function and its deriva-

tives. By a solution of a differential equation we mean a function that is differentiable and satisfies the equation on some interval. For example, x0 x D 0 is a differential

equation involving an unknown function x and its first derivative with respect to an independent variable that we may call t, s, etc. We notice that .et /0 et D et et D 0 for all t in the interval I D . 1; 1/: Therefore, x.t/ D et is a solution of the dif-

ferential equation on the interval I .

A differential equation involving ordinary derivatives is called an ordinary dif-

ferential equation and one involving partial derivatives is called a partial differential

equation. For example, x00 t2x0 C2x D 0 is an ordinary differential equation, while

@2u @x2

C

@2u @y2

D

0

is

a

partial

differential

equation. In

this

book,

we

deal

with

ordinary

differential equations.

By the order of a differential equation we mean the order of the highest derivative appearing in the equation. For example, x000 C 2x00 3x0 C 2x D 0 is a third order differential equation while x00 C x D 0 is second order.

Differential equations play a central and important role not only in mathematics

but also in almost all areas of science and engineering, economics, and social sci-

ences. A differential equation may describe the flow of current in a conductor, or the

motion of a missile, the behavior of a mixture, the spread of diseases, or the growth

rate of the population of some species, etc. Often, we will have x.t/ describing a physical quantity, depending on time t, whose rate of change x0.t/ is given by the

function f .t; x.t// depending on time t and x.t/.

In the sequel we will discuss differential equations on a broader basis, including

higher order equations and/or systems. In this first chapter, however, we start with

the simplest, but very important, class of differential equations, namely first order

linear equations.

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_1

2

1 First order linear differential equations

1.2 A simple case

Let us begin with the very specific and simple equation

x0 D kx; k 2 R:

(1.1)

We will demonstrate a precise method for solving such equations below. But first
we use our intuition and familiarity with the derivative of the exponential function to
solve the simple equation (1.1). Let us first take k D 1. We seek a function whose derivative is equal to itself:
x0 D x. One such function is x.t/ Á 0. We also know that the exponential function x D et has this feature. Actually, for every constant c, the function x D cet is a solution of x0 D x. This leads us to the slightly more general case x0 D kx, which has x D cekt as a solution, for any constant c. Furthermore, as we will see below,
these are the only types of solutions that this differential equation can have.
We now illustrate a general procedure that will be used later to solve the most
general first order linear differential equations. First suppose that x.t/ satisfies the
equation

x0.t/ D kx.t/:

Multiplying both sides of the equivalent equation x0.t/

have

x0.t /e kt kx.t /e kt D 0:

kx.t/ D 0 by e kt , we

We note that the left-hand side is the derivative of .x.t/e kt /. Hence we have .x.t/e kt /0 D 0. Integrating, we obtain x.t/e kt D c, 8 t 2 R, where c is a constant. Hence x.t/ D cekt.
On the other hand, by substituting any function of the form x.t/ D cekt into the
equation (1.1), we see that x.t/ is a solution of (1.1). Therefore, x.t/ is a solution of (1.1) if and only if x.t/ D cekt for some constant c. We say that x.t/ D cekt is
the general solution of (1.1), that is, it represents the family of all solutions of this
equation.

Example 1.2.1. Consider the problem of finding x.t/ such that

x0 D 2x; x.0/ D 1:

(1.2)

This is called an initial value problem. It is asking for a function x.t/ that satisfies the differential equation and x.0/ D 1. We have shown above that x.t/ D ce2t is the general solution. So, the desired solution, if it exists, must be of the form ce2t . Substituting t D 0 in the equation x.t/ D ce2t , we obtain 1 D ce0 or c D 1. Therefore, x.t/ D e2t is a solution to the initial value problem (1.2). Since every solution to the initial value problem (1.2) is of the form x.t/ D ce2t and since by substituting
the initial values in this general solution we obtain only one constant that satisfies the
initial value problem, we conclude that the solution to the initial value problem (1.2)
exists and it is unique.

1.3 Some examples arising in applications

3

1.3 Some examples arising in applications

In spite of its simplicity, equation (1.1) arises in many fields of applied sciences. Below we discuss a couple of them.

1.3.1 Population dynamics

Let:
· t denote the time. · x.t/ denote the number of individuals of a population at time t. · b denote the birth rate of the population. · d the death rate of the population.
The simplest model of population growth, due to Malthus1 in the discrete version, assumes that b and d are constant and that the increment of the population x.n C 1/ x.n/ between t D n and t D n C 1 is equal to the number of new-born individuals b x.n/ minus the number of deaths d x.n/, namely x.n C 1/ x.n/ D bx.n/ dx.n/ D .b d /x.n/. Introducing the number k D b d as the unit growth rate, that is the growth rate per unit time, we find the recursive equation

x.n C 1/ x.n/ D kx.n/; n D 0; 1; 2; :::

(1.3)

which allows us to find x.n/ for any positive integer n. To pass to continuous time variables, we take an infinitesimal change of time t. Then the change of population x.t C t/ x.t/ between t and t C t is given by the unit growth rate k, times the population size x.t/, times the interval of time t. Thus equation (1.3) becomes x.t C t/ x.t/ D kx.t/t. Dividing by t we get
x.t C t/ x.t/ D kx.t/: t
The left-hand side is the incremental ratio of x.t/. Letting t ! 0, we find
x0.t/ D kx.t/; k D b d;
a first order linear differential equation like (1.1), whose solutions are x.t/ D cekt . If x.0/ D x0 > 0, then c D x0 > 0 and x.t/ D x0ekt . If the birth rate b is equal to the death rate d , then k D b d D 0 and x.t/ D x0e0 D x0 for all t 0, as one would expect. If b > d then k D b d > 0 and x.t/ D x0ekt grows exponentially and approaches C1 as t ! C1. On the other hand, if k < 0 then x.t/ decays exponentially to 0 as t ! C1 and the population goes to extinction. See Figure 1.1.
This model is rather rough in the sense that it does not take into account the fact that b; d , and hence the growth rate k, might depend on the population size. In Section 3.1.1 of Chapter 3, we will discuss a more realistic model of population growth,

1 Thomas R. Malthus (1766­1834).

4

1 First order linear differential equations

x

x0

O

t

Fig. 1.1. Solutions of (1.3), with k > 0 (upper curve) and k < 0 (lower curve) and k D 0 (dotted curve)

which gives rise to the so called "logistic equation" having the form x0 D x. x/, ;  positive constants.

1.3.2 An RC electric circuit

Let us consider an RC circuit with resistance R and capacity C with no external current or voltage source.
If we denote by x.t/ the capacitor voltage (x.t/ D V .t/ in Figure 1.2) and by I.t/ the current circulating in the circuit, then, according to the Kirchhoff's law, we have

R I.t/ C x.t/ D 0:

Moreover, the constitutive law of capacitor yields

I.t/ D C

d x .t / :

dt

Substituting I.t/ in the first equation, we obtain the first order differential equation

RC x0.t/ C x.t/ D 0;

Fig. 1.2. An RC circuit

1.4 The general case

5

namely

x0.t/ C x.t/ D 0; RC

which is of the form (1.1) with k D 1=RC . Also here we can look for a solution x.t/ satisfying the initial condition x.0/ D x0, which means that the initial voltage is x0. The solution is given by

x.t / D x0e t=RC :

We can see that the capacitor voltage x.t/ D V .t/ decays exponentially to 0 as t ! C1, in accordance with the experience. The number D RC is usually called the RC time constant and is the time after which the voltage x.t/ D V .t/ decays to V . / D x0e 1. Moreover we can say that the bigger is, the slower the decay. As
for the intensity of current I.t/, one finds

I.t / D C x0.t / D C x0 e t=RC D x0 e t=RC :

RC

R

Other equations arising in the electric circuit theory will be discussed in Example 1.4.3 below, in Example 5.5.5 of Chapter 5 and in Section 11.6 of Chapter 11.

1.4 The general case

Now, we solve the general first order linear differential equation

x0 C p.t/x D q.t/

(1.4)

where p.t/; q.t/ are continuous functions on an interval I Â R. If q.t/ Á 0 the linear differential equation (1.4) is called homogeneous, otherwise
it is called nonhomogeneous or inhomogeneous. Motivated by the above discussion, we try to find a differentiable function .t/, .t/ > 0 for t 2 I , such that
.t/x0.t/ C .t/p.t/x.t/ D . .t/x.t//0 :

Such a function .t/ is called an integrating factor of the equation (1.4). It has the property that if we multiply (1.4) by .t/, it renders the left side of the equation to be equal to . .t/x.t//0 , which can be easily integrated.
Although based on the discussion in the preceding section, one might guess such an integrating factor, we prefer giving a precise method for finding it.
Let x.t/ be a solution of (1.4). Multiplying the equation by .t/ we have
x0 C px D q:

Now we wish to find such that x0 C px D . .t/x.t//0 :

6

1 First order linear differential equations

Expanding the right-hand side, we have .t/x0.t/ C .t/p.t/x.t/ D .t/x0.t/ C 0.t/x.t/:

Canceling .t/x0.t/ from both sides, we obtain .t/p.t/x.t/ D 0.t/x.t/:

Assuming that x.t/ D6 0 and dividing both sides by x.t/, we find

.t/p.t/ D d : dt

Since .t/ > 0 we infer

d D p.t/dt: .t /

R Then, taking the indefinite integRrals we obtain

d .t /

D

R

p .t /d t

and

we

find

(recall

that .t/ > 0) that ln. .t// D p.t/dt.

Thus

Z .t / D eP.t/; P .t/ D p.t/dt:

In order to obtain the general solution of (1.4), we take the indefinite integral of both

sides of

. .t/x.t//0 D .t/q.t/

(1.5)

obtaining

Z .t/x.t/ D c C .t/q.t/dt

where c is a constant. Substituting .t/ D eP.t/, we have

ÄZ

Z

x.t / D e P.t/ c C eP.t/q.t /dt ; P .t / D p.t /dt:

(1.6)

We have seen that if x.t/ solves (1.4), then there exists c 2 R such that x.t/ has the form (1.6). Moreover, it is easy to check that for all c 2 R, x.t/ given above solves (1.4). This is why x.t/ in (1.6) is called the general solution of (1.4).
Now, suppose we are interested in solving the initial value problem

x0 C p.t/x D q.t/; x.t0/ D x0:

Then we can substitute t D t0, x D x0 in the general solution and solve for the constant c. Another way is to take the definite integral of (1.5) from t0 to t instead of

the indefinite integral. Doing so, we have

.t /x .t /

Zt

.t0/x.t0/ D

.s/q.s/ds:

t0

1.4 The general case

7

We

can

also

choose

P

.t /

D

Rt
t0

p.s/ds

and

then

.t /

D

Rt
e t0

p.s/ds :

Hence

.t0/ D 1 and

x.t/ D e

Rt
t0

p.s/ds

Ä x0

C

Z

t

Rs
e t0

p.s/ds

q.s/ds

:

t0

(1.7)

Remark 1.4.1. We prefer not to have to memorize (1.7) but rather go through this simple procedure each time, starting with integrating factors.

As a special case of (1.6), when q D 0, the general solution of the homogeneous

equation

x0 C p.t/x D 0

(1.8)

is

Z

x.t/ D c e P.t/; P .t/ D p.t/dt; t 2 I:

For c D 0 we obtain the trivial solution x.t/ Á 0.

If we are searching for we can solve x0 D x.t0/

Da scoleutiPo.nt0s/a.tIifsfwyientgaktheePin.itt/iaDl coRntt0dpiti.osn/dxs.,t0th/eDn

x0, then P .t0/ D

0 and we find c D x0. Thus

x.t/ D x0 e

Rt
t0

p.s/ds

is the solution of x0 C p.t/x D 0 such that x.t0/ D x0, and it is unique. As a consequence, if t0 is any number in I and x.t0/ D x0, then
1. x.t/ D 0, 8 t 2 I , if and only if x0 D 0. 2. x.t/ > 0, 8 t 2 I , if and only if x0 > 0. 3. x.t/ < 0, 8 t 2 I , if and only if x0 < 0.

In other words, if x.t/ is a solution of (1.8), then it is either identically zero, or it
is always positive or it is always negative. In particular, if x.t/ vanishes somewhere in I , then it has to be the trivial solution x.t/ D 0, for all t 2 I .
The above arguments lead to the following existence and uniqueness result for (1.4), namely for x0 C p.t/x D q.t/.

Theorem 1.4.2. Let p.t/; q.t/ be continuous in I Â R. Then

1. The general solution of (1.4) is given, for all t 2 I , by

ÄZ x.t / D e P.t/ c C eP.t/q.t /dt ;

Z P .t/ D p.t/dt;

c a constant.

8

1 First order linear differential equations

2. There is exactly one solution x.t/ satisfying the initial value x.t0/ D x0 for any numbers t0 2 I and x0 2 R. Precisely,

x.t/ D e

Rt
t0

p.s/ds

Ä x0

C

Z

t

Rs
e t0

p.s/ds q.s/ds

;

t0

t 2 I:

(1.9)

This theorem can also be deduced from general existence and uniqueness results stated in Chapter 2, Section 2.2.2.
We end this section by demonstrating, through examples, how to solve linear equations.

Example 1.4.3. Find the solution of x0.t/ C kx.t/ D h;

x.0/ D x0;

(1.10)

where h; k are constant. Equation (1.10) arises in the RC circuit when there is a gen-
erator of constant voltage h D V0, see Figure 1.3. Here p.t/ Á k and hence an integrating factor is ekt . Multiplying the equation
by ekt yields ekt x0 C kekt x.t / D hekt;

or

d

Á x.t /ekt D hekt:

dt

Integrating, we find

x.t /ekt D h ekt C c k

where c is an arbitrary constant. Thus the general solution is

x.t/ D ce

kt

C

h :

k

Fig. 1.3. RC circuit with a generator of voltage

1.4 The general case

9

To find a solution that satisfies the initial condition x.0/ D x0 we might simply substitute t D 0 in the preceding equation, finding

h

h

x0 D c C k

and hence c D x0

: k

Hence the unique solution of (1.10) is Â
x.t/ D x0

Ã

h e kt C h :

k

k

(1.11)

Alternatively, we can use (1.9) yielding

Ä

Zt

x.t / D e kt x0 C ekshds

Ä

0

D e kt

x0 C h

1 k

.e k t

Â 1/ D x0

Ã

h e kt C h

k

k

as before.

Notice

that,

as

t

!

C1,

x .t /

!

h k

,

from

below

if

x0

<

h k

(see

Figure

1.4a)

and

from above if

x0

>

h k

(see

Figure 1.4b).

The solution (1.11) implies that in this case the capacitor voltage x.t/ D V .t/ does

not decay to 0 but tends, as t ! C1, to the constant voltage h= k D V0=RC .

Example 1.4.4. Find the general solution of x0.t/ C 4tx.t/ D 8t

and the solution such that x.0/ D 1.
(a) Here p.t/ D 4t and hence we can take P .t/ D 2t2. We start by multiplying the equation by the integrating factor e2t2, which results in the equation

e2t2 x0 C 4t e2t2 x.t / D 8t e2t2 ;

x x
h/k

h/k

t

t

O

O

(a)

(b)

Fig. 1.4. Solutions of (1.10).

(a)

x0

<

h k

;

(b) x0

>

h k

10 1 First order linear differential equations

which is the same as

d

Á x.t /e2t2 D 8t e2t2 :

dt

Integrating both sides, we obtain

x.t /e2t2 D 2e2t2 C c

where c is an arbitrary constant. Therefore, the general solution is x.t / D 2 C c e 2t2 :

(b) If we require that x.0/ D 1, then the constant c is uniquely determined by the equation 1 D 2 C c e 2 0 D 2 C c, that is c D 1 and hence
x.t / D 2 e 2t2:

Alternatively, we can use the general formula (1.9) finding

x.t/ D e

4

Rt
0

sds

Ä 1

C

Z

t

e

4

Rs
0

sds

8

s ds

Ä Zt D e 2t2 1 C 8 s e2s2 ds

0

0

h

i

h

i

D e 2t2 1 C .2e2t2 2/ D e 2t2 2e2t2 1 D 2 e 2t2:

We make a couple of interesting observations concerning this equation.
1. We note that for c D 0, we obtain the constant solution x D 2. Furthermore, this solution divides all the other solutions into two groups: those that approach it from the top and those that approach it from the bottom, as t ! 1. See Figure 1.5.

x

2 t
O
Fig. 1.5. Graphs of x D 2 C ce 2t2

1.4 The general case 11
2. We could have found the constant solution x.t/ D 2 without even solving the equation, by simply noting that if x.t/ is a constant, then x0.t/ Á 0 and therefore x0.t/ C 4tx.t/ Á 8t implies x.t/ D 2 for all t.

Example 1.4.5. Find the general solution of

t 2x0 C .1 C t /x D 1 e1=t; t

t > 0:

(1.12)

The first thing we notice is that the above equation is not in the form of equation (1.4)
for which we found the integrating factor . To apply our method, we must put it in the proper form. So, we divide both sides of the equation by t2 6D 0, which yields

x0

C

.1 C t2

t/ x

D

1 t3

e1=t

t > 0:

(1.13)

We know that an integrating factor can be determined as

D eP.t/;

where

P 0.t /

D

.1 C t2

t/ :

To find P .t/ we evaluate the indefinite integral

Z

.1 C t2

t/

dt

D

Z

Â

Ã

1 t2

C

1 t

dt D

1 C ln t C c; t

t > 0:

Taking c D 0 we find that an integrating factor is given by

.t / D e 1=tCln t D e 1=t : eln t D t e 1=t :

Multiplying (1.13) by this integrating factor, we obtain the equation

.t e

1=t x/0 D t e

1=t :

1 t3

e1=t

D

1 t2

:

Integrating both sides, we get

t e 1=t x.t / D 1 C c: t

The general solution is

e1=t ce1=t

e1=t Â

Ã 1

x.t/ D t2 C t

D t

c

;

t

t > 0:

(1.14)

It is clear that all the solutions tend to 0 as t tends to C1. On the other hand, it is easy to verify that for any constant c, x.t/ given by (1.14) satisfies equation (1.13). This means that x.t/ given by (1.14) is a solution of (1.13), and hence of (1.12), if and only if x.t/ is of the form (1.14), that is the general solution of (1.12).

12 1 First order linear differential equations

If we want to solve the equation x0 C

.1Ct t2

/

x

D

1 t3

e1=t for t D6 0 we should

distinguish the two cases t > 0 and t < 0 separately. As an exercise, the reader might

repeat the calculations for t < 0.

Example 1.4.6. Solve the following initial value problem and show that the solution is defined for t > 0 and is unique:

t2x0

C .1 C t/x

D

1

1
et;

x.1/ D 0:

t

(1.15)

We have shown that the general solution of (1.12) for t > 0 is x.t/ given by (1.14), where c is a constant.
Now in order to solve the initial value problem, since all solutions are included in (1.14), we simply substitute the initial values into the equation (1.14), obtaining 0 D e C ce, and hence c D 1. Therefore,

e

1 t

e

1 t

e

1 t

Â

Ã 1

x.t/ D t2 C t D t

1

: t

The graph of x.t/ is reported in Figure 1.6. The uniqueness follows from the fact that there is only one value of c for which x.t/ obtained from the general solution (1.14) satisfies the initial value x.1/ D 0.
The reader can check, as an exercise, that the same result holds if we use the general formula (1.9).

x

1

O

t

1

Á

Fig.

1.6. x.t /

D

et t

1

1 t

,t >0

1.5 Exercises 13

1.5 Exercises

1. Find the equation whose general solution is x D c e 5t .

2. Solve x0 C .ln 3/x D 0.

3. Solve x0 C 4x D 4.

4.

Find

all

the

solutions

to

the

initial

value

problem

x

0C

2t

3Csin t C5 t 12C5

x

D 0, x.0/ D 0.

5. Solve x0 D 2x C 3 and find the solution satisfying x.1/ D 5.

6. Find k such that there exists a solution of x0 D kx such that x.0/ D 1 and x.1/ D 2.

7. Explain why the solution to the problem

x0 2.cos t/x D cos t; x.0/ D 1 2
must oscillate, i.e. it must have arbitrarily large zeros.

8. In each of the following, find the maximum interval of existence of the solution,

guaranteed by the existence theorem

(a)

x0 C

1 t2

x D 0, 1

x.

2/ D 1;

(b)

x0 C .sec t/ x D t

1 ,
1

x . 4 / D 1.

9. Solve tx0 C x D 2t2.

10. Show that there is an infinite family of solutions to the problem

t2x0 2tx D t5; x.0/ D 0;

all of which exist everywhere on . 1; 1/. Does this violate the uniqueness property of such equations?

11. Solve x0 D 2tx and find the solution satisfying x.0/ D 4.

12. Solve x0 D t2x.

13. Solve x0 C ax D bt.

14. Solve: (a) x0 D x C 2t, (b) x0 2x D 3t, (c) x0 C 3x D 2t.

15. Find the solution of x0 C ax D bt satisfying x.t0/ D x0.

16. Solve the initial value problems (a) x0

x

D

1 2

t

,

x .0/

D

1, (b) x0 C x

D

4t,

x.1/ D 0, (c) x0 2x D 2t, x.0/ D 3.

17. Given h; k 2 R, k > 0, find the limits as t ! C1 of the solutions of x0 C kx D h.

18. Consider x0 C kx D 1, where k is a constant. (a) For what value of k will all solutions tend to 2 as t ! C1? (b) Is there any value of k for which there exists a non-constant solution x.t/ such that x.t/ ! 3 as t ! C1? Explain.

14 1 First order linear differential equations

19.

Find the limits as t

!

1 of the solution of x0

D

1 1Ct 2

x, x.0/

D

1.

20. Consider x0 C kx D h, with k 6D 0. Find conditions on the constants h; k such

that

(a) all solutions tend to 0 as t tends to + infinity,

(b) it will have only one solution bounded on .0; C1/,

(c) all solutions are asymptotic to the line x D 3.

21. Show that for any differentiable function f .t/, t 2 R, all solutions of x0 C x D f .t/ C f 0.t/ tend to f .t/ as t tends to C1.

22. Find a continuous function q.t/, t 2 R, such that all solutions of x0 C x D q.t/
(a) approach the line x D 7t 5 as t ! C1, (b) approach the curve x D t2 2t C 5 as t ! C1.

23. Show that if p is differentiable and such that limt!C1 p.t/ D C1, then all the solutions of x0 C p0.t/x D 0 tend to zero as t ! C1.

24. If k 6D 0, show that the constant solution x.t/ D

1 k2

is

the

only

solution of

x0 k2x D 1 such that the limt!C1 x.t/ is finite.

25.

LR eCt1k
0

¤ ek

0
2s

and let q.s/ds

q .t / D 0.

be continuous and such Show that the solution x

that limt .t/ of the

!C1 q.t / D ivp problem

0,

and

x0 k2x D q.t/; x.0/ D x0;

tends to 0 as t ! C1 if and only if x0 D 0. 26. Show that the solution of x0 D k2x, x.t0/ D x0, is increasing if x0 > 0 and
decreasing if x0 < 0.
27. Show that the solution of x0 D kx, x.t0/ D x0 is increasing if kx0 > 0 and decreasing if kx0 < 0.
28. Find the locus of minima of the solutions of x0 C 2x D 6t.

29. Find the locus of maxima and minima of the solutions of x0 C x D at, a 6D 0.

2 Theory of first order differential equations

Before discussing methods of solving more general classes of differential equations, it is convenient to present a theoretical overview of first order equations and their solutions, which will set a rigorous layout for the rest of the book.

2.1 Differential equations and their solutions

In Chapter 1 we introduced the notion of a differential equation and the meaning of the solution of such an equation. This will now be explained in more detail and in greater generality in the present section.

Consider the first order differential equation

x0 D f .t; x/

(2.1)

where f .t; x/ is continuous, .t; x/ 2 ,

R2.

A solution of (2.1) is a differentiable real valued function x.t/ defined on an in-

terval I Â R such that

x0.t/ Á f .t; x.t//; for .t; x.t// 2 :

(2.2)

An equation in this form is said to be in normal form, to distinguish it from more
general differential equations that will be introduced later on. One of the simplest examples of a first order differential equation is x0 D h.t/,
where h is continuous on an interval I Â R. If H.t/ is an antiderivative so that H 0.t/ D h.t/, then all the the solutions are given by x.t/ D H.t/ C c, c a real
constant. We have seen in Chapter 1 that all solutions of the linear equation x0 C p.t/x D
q.t/ form a family of functions depending on a constant. We will show in the sequel that this is a general fact: solutions of x0 D f .t; x/ form a one parameter family of
functions, although, as we will see, in the nonlinear case there could be some isolated
cases of solutions that are not included in such a family.

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_2

16 2 Theory of first order differential equations
1. The reader should recall that a solution of (2.2) is a function, in contrast to the algebraic equations, whose solutions are real (or complex) numbers. Moreover, it is important to note that (2.2) is an identity; it holds for all t in the domain of x .t /.
2. The domain of definition of a solution of (2.2) is a priori unknown and may depend on several facts. It could happen that, even if f .t; x/ makes sense for all real t; x, the solutions may be defined only for t in a proper subset of R, see Example 2.2.2 below.
From a geometrical point of view, a solution of (2.1) is a curve x D x.t/, contained in the set , such that the tangent at each point .t ; x.t // on the curve has slope equal to f .t ; x.t // and hence its equation is
x D f .t ; x.t //.t t / C x.t /: For example, (see Figure 2.1) consider the curve x D et in the plane .t; x/, which is a solution of x0 D x. A generic point P on this curve has co-ordinates P D .t ; et /. The tangent to x D et at P has equation
x D et .t t / C et :
Remark 2.1.1. We have used t as the independent variable and x as the dependent one. But any other choice makes sense. For example, we could just as well name the dependent variable y and the independent variable x. With this notation, a first order differential equation would have the form
y0 D dy D f .x; y/ dx
a solution of which would be a differentiable function y.x/ such that y0.x/ D f .x; y.x// for all x where y.x/ is defined. In any case, the equation will make it clear which one is the independent or dependent variable.
x

O

t

Fig. 2.1. Tangents to x D et

2.2 The Cauchy problem: Existence and uniqueness 17

Dealing with a first order equation, one can distinguish between:

· Linear and nonlinear equations, according to whether f .t; x/ is linear with respect to x or not.
· Autonomous and non-autonomous equations according to whether f is independent of t or not.

For example, x0 D kx C c is linear and autonomous, x0 D x2 C kx C c is nonlinear and autonomous; while x0 D et x C sin t 4 is linear and non-autonomous, and x0 D tx2 tx C 3 is nonlinear and non-autonomous.

an

Notice that, appropriate

even if f subset of

is independent of R2. For example,

t, in

the domain the equation

xh0 aDs topbxe,cfon.xsi/deDredpaxs

is defipned for x 0 andphence D R ¹x 0º. Similarly, in the equation x0 D 1 x2, f .x/ D 1 x2 is defined for 1 Ä x Ä 1 and hence is the

horizontal strip R ¹ 1 Ä x Ä 1º.

More generally, let F .t; x; p/ be a real function of 3 real variables, defined on a set R Â R3. Consider the first order differential equation
F .t; x; x0/ D 0;

whose solution is a differentiable real valued function x.t/ defined on an interval

I Â R such that

F .t; x.t/; x0.t// Á 0; 8 t 2 I:

(2.3)

If F .t; x; p/ is of the form F .t; x; p/ D p f .t; x/, we can write the equation F .t; x; x0/ D 0 in normal form x0 D f .t; x/.
Even more generally, we may consider systems of n first order equa-
tions and n unknowns. We may also consider more general scalar equations F .t; x; x0; x00; : : : ; x.n// D 0 of order n.
In this chapter we deal with first order equations. Higher order equations and sys-
tems will be discussed starting with Chapter 4.

2.2 The Cauchy problem: Existence and uniqueness

The problem of solving an equation in normal form x0 D f .t; x/ coupled with the

initial condition x.t0/ D x0,

² x0

D f .t; x/

x.t0/ D x0

is called a Cauchy1 problem or an initial value problem, ivp in short.
Solve the previous ivp means finding a function x.t/ and an Interval I containing t0, such that x0 D f .t; x/ for all t 2 I and x.t0/ D x0.

1 Augustin-Louis Cauchy (1789­1857).

18 2 Theory of first order differential equations
In this section we discuss some theoretical aspects of existence and uniqueness theorems for the Cauchy problems. The proofs are given in the Appendix 2.5 at the end of the chapter.
Existence and uniqueness of solutions is important not only from a theoretical point of view but also in applications. For example, in using a numerical method or some software such as Math Lab to find a solution, it is important to know whether or not such a solution exists in the first place. And if it does exist, is there more than one solution?

2.2.1 Local existence and uniqueness

Theorem 2.2.1 (Local existence and uniqueness). Suppose that f is continuous in

Â R2 and has continuous partial derivative fx with respect to x. Let .t0; x0/ be

a given point in the interior of . Then there exists a closed interval I containing t0

in its interior such that the Cauchy problem

² x0

D f .t; x/

x.t0/ D x0

(2.4)

has a unique solution, defined in I .

We will see that this is a particular case of a more general result, see Theorem 2.4.4

below.

We are going to outline the proof of the existence part by using a method introduced by Picard,2 which is based on an approximation scheme.

We define a sequence of approximate solutions by setting

Zt
x0.t / D x0; xkC1.t / D x0 C f .s; xk.s//ds;
t0

k D 1; 2; : : : :

One shows that, under the given assumptions, there exists i > 0 such that xk.t/ con-

verges to some function x.t/, uniformly in OEt0 i; t0 C i. Passing to the limit one

finds that x satisfies

Zt

x.t/ D x0 C f .s; x.s//ds:

t0

Then x.t/ is differentiable and, using the Fundamental Theorem of Calculus, we get x0.t/ D f .t; x.t//, for all t 2 OEt0 i; t0Ci. It is also clear that x.t0/ D x0 and hence
x.t/ is a solution of (2.4), defined in OEt0 i; t0 C i. For details see the Appendix.

2 Charles Emile Picard (1856­1941).

2.2 The Cauchy problem: Existence and uniqueness 19
Let us show what happens in the particular case f .t; x/ D x, t0 D 0 and x0 D 1. The sequence is constructed as follows:

x0.t / D 1; Z t

Zt

x1.t/ D 1 C x0.s/ds D 1 C ds D 1 C t;

x2.t /
x3.t / :::
xk.t /

D D D

1C
1C ::: 1C

Z0t
Z0t
0
Zt
0

x1.s/ds D x2.s/ds D xk 1.s/ds

1C 1C D1

Z0t .1

C

s/ds

D

1

C

t

C

1 t 2;

Z0t .1

C

s

C

1 s2/ds

D

2 1C

t

C

0

2

C t C 1t2 C C 1 tk:

2

kS

1t2 2

C

1 t3; 3S

The sequence xk.t/ converges uniformly to x.t/

D

P

1 kS

tk

D

et , which is the

solution to x0 D x; x.0/ D 1.

It is important to note that Theorem 2.2.1 is local, because it ensures that the so-

lution exists (and is unique) in a suitable interval around t0. The following example shows that the solution may not be defined on all of R even if the equation makes

sense everywhere.

Example 2.2.2. Consider the ivp

² x0

D x2

x.0/ D a D6 0:

(2.5)

Let us first solve the equation x0 D x2. This is a so-called "separable equation"

and will be discussed in Section 3.1 of Chapter 3. Here, instead of using the general

method, we will find the solutions by a direct argument which uses some intuition.

We have to find functions x.t/ whose derivatives are equal to x2.t/. One choice

could be x.t/ D

1 t

,

because

x0

D

1 t2

which equals x2

D

1 t2

.

More

generally,

consider the functions

1

.t; c/ D

;

tc

c 2 R:

Since

d dt

1

.t; c/ D .t

c/2 D

2.t; c/;

it follows that, for all real constants c, the functions .t; c/ solve x0 D x2. To find the solution xa.t/ of the Cauchy problem (2.5) we impose the requirement
that .0; c/ D a, that is

aD

1

D1

"

c

D

1 :

0c c

a

20 2 Theory of first order differential equations

Thus we find

xa.t/ D

1

t

1:
a

(2.6)

Let us notice explicitly despite the fact that the

that the solution is not defined for all function x2 in the equation is defined

t

but only for t

¤

1 a

,

and continuous every-

where. This is one of the peculiarities of nonlinearity, compared with linear.

Saying that (2.6) solves (2.5) is in some sense an abuse of language because we did

not specify the interval where (2.6) has to be considered. To be precise, the solution

of the ivp (2.5) is (see Figure 2.2)

if a > 0 : xa.t/ D

1

1

t

1;
a

t

<

a

;

if a < 0 : xa.t/ D

1

1

t

1;
a

t

>

a

:

The

reason

why

we

cannot

take

all

of

R

n

¹

1 a

º

is

that

a

solution

of

a

differential

equa-

tion is differentiable and hence - in particular - continuous, which is not the case if

we

consider

(2.6)

as

defined

on

R

n

¹

1 a

º.

Now we want to extend the preceding discussion to the general case of the Cauchy

problem (2.5). Recall that solving the Cauchy problem (2.5) means to find a function xa.t/ and an interval I containing t0, such that x0.t/ D f .t; x.t// for all t 2 I and
x.t0/ D x0. In other words, we have to find not only the function x.t/ such that x0 D f .t; x/ and x.t0/ D x0, but we also have to specify the interval I where the

solution has to be considered. It is important to point out that it might happen that

this interval I is strictly contained in the set S of all t where x.t/ makes sense. As

explained before, the reason is that x.t/ could be discontinuous (or not differentiable)

on S while, as a solution of a differential equation, x.t/ has to be continuous, dif-

ferentiable indeed. The problem (2.5) discussed before is just an example in which

I

¨

S.

Actually, in

that case

S

D

¹t

2

R

W

t

¤

1 a

º

while

I

D

.

1;

1 a

/

(if

a

>

0)

or I

D

.

1 a

;

C1//

(if

a

<

0).

x

x

a

1/a

t

t

0

1/a

0

a

(a)

(b)

Fig. 2.2. Solutions of x0 D x2, x.0/ D a. (a) plot of xa.t /, a > 0; (b) plot of xa.t /, a < 0

2.2 The Cauchy problem: Existence and uniqueness 21

The following definition is in order.

Definition 2.2.3. We say that J R is the maximal interval of definition of the solution x.t/ of the Cauchy problem (2.4) if x.t/ is defined in J , and x.t/ cannot be extended in an interval greater than J .

For example, the maximal interval of definition of the solution xa.t/ of x0 D

x2; x.t0/ D a ¤ 0, discussed in the preceding Example 2.2.2, is the half line

.

1;

1 a

/

(if

a

>

0)

or

the

half

line

.

1 a

;

C1/

(if

a

<

0).

Lemma 2.2.4. Let x0.t/ be a solution of x0 D f .t; x/. Suppose, for simplicity, that the set where f is defined is all of R2. If J , the maximal interval of definition of
the solution x0.t/, is not all of R, then it cannot be closed.

Proof. By contradiction, let J D OE;  or J D . 1;  or J D OE; C1/. We deal with the first case, the other ones are similar.
Consider the new Cauchy problem
x0 D f .t; x/; x./ D x0./

in which the initial condition is prescribed at the point  and equals the value that

x0.t/ assumes at such a point. According to the local existence and uniqueness The-

orem 2.2.1, the new ivp has a unique solution x1.t/ defined in an interval OE;  C i

for some i > 0. Consider the function obtained by gluing together x0 and x1 (see

Figure 2.3), that is

´ x0.t/ if  Ä t Ä 
x.t/ D x1.t/ if  Ä t Ä  C i:

Since x0./ D x1./, the function x.t/ is continuous. Let us show that it is differentiable. This is clear for all t 6D . At t D  we consider the left and right limits of

x

x ()
0

x (t)
1
x0(t)



 +

t

Fig. 2.3. Gluing x0.t / and x1.t /

22 2 Theory of first order differential equations

the difference quotients

x. C h/ x./

x. C h/ x./

lim

; lim

:

h!0

h

h!0C

h

For h Ä 0, we have x. C h/ D x0. C h/ and hence

x. C h/

lim

h!0

h

x . / D

lim

x0. C h/

h!0

h

x0./ D x00 ./ D f .; x0.//:

Similarly, for h 0 we find

x. C h/

lim

h!0C

h

x./ D lim x1. C h/

h!0C

h

x1./ D x10 ./ D f .; x1.//:

Since x0./ D x1./, it follows that

x. C h/ x./

x. C h/ x./

lim

D lim

;

h!0

h

h!0C

h

and this means that x.t/ is differentiable at t D . We have found a solution of x0 D f .t; x/ defined in OE;  C i in contradiction
with the fact that J D OE;  is the maximal interval. The argument for the left end
point  is the same.

Proposition 2.2.5. Let f .t; x/ satisfy the assumptions of the local existence and uniqueness theorem, with D R2. If x.t/ is a solution of x0 D f .t; x/ which is monotone and bounded, then its maximal interval of definition J is all of R.
Proof. By contradiction, suppose that J is strictly contained in R. For example, let us assume that J is bounded (the other cases are treated in a similar way). Let us show that J is closed. Let  < C1 be the right extreme of J . Since x.t/ is monotone and bounded, the limit limt! x.t/ exists and is finite. Thus x.t/ is defined also at t D  and hence J contains . Same argument for the left extreme  > 1. We have shown that J is closed and this is in contradiction with the preceding Lemma.

Concerning the fact that the solution of the ivp (2.4) is unique, we have required that f be differentiable with respect to x. The following example shows that if this condition is violated, the solution may not be unique.

Example 2.2.6. Consider the Cauchy problem

² x0

D

p 2x

x.0/ D 0:

(2.7)

This is also a separable equation discussed in Section 3.1 of Chapter 3. One solution is given by x.t/ Á 0. Another solution is given by
x.t/ D t2 t 0;

2.2 The Cauchy problem: Existence and uniqueness 23

p

because

d dt

.t 2/

D

2t

D

2

t2 D 2jtj D 2t for t

0. Note that for t < 0 one has

jtj D t and hence x D t2 is not a solution for t < 0.

We have found two solutions that solve the ivp (2.7). Furthermore, one can verify

that, for any a > 0, all the functions

²

xa.t/ D

0; .t

for 0 Ä t Ä a a/2; for t a

arpe solutions. So, (2.7) has infinitely many solutions. See Figure 2.4. Notice that

2

jxj On

is not differentiable at x the other hand, the ivppx

0DD02. px,

x .0/

D

a,

has

a

unique

solution

provided

a > 0. Actually, f .x/ Theorem 2.2.1 applies.

D2 x One can

is differentiable in the open half check that the function x .t/ D

planepx tC a

>
2

0 and solves

the ivp, is defined for all t and is the unique solution.

Remark 2.2.7. An important consequence of the uniqueness result stated in Theorem 2.2.1 is that two solutions of x0 D f .t; x/ cannot cross each other. In other words, if v.t/ and z.t/ are two solutions of x0 D f .t; x/ defined on a certain interval
OEa; b and if there exists t 2 OEa; b such that v.t / D z.t /, then v.t/ D z.t/ for all
t 2 OEa; b. The reason is that both v and z satisfy the same ivp

² x0

D f .t; x/

x.t / D v.t / D z.t /:

So, by uniqueness one must have x.t/ D z.t/ on OEa; b.

We will see later on that we can also use the uniqueness result to deduce geometric properties of the solution of an ivp. See e.g. Section 2.3 below.

x

t

O

a

a

Fig.

2.4.

Solutions

of

x0

D

p x

24 2 Theory of first order differential equations

The following theorem, due to G. Peano3 shows that the existence part (but not
the uniqueness) of Theorem 2.2.1 requires only continuity of the function f . The proof of this theorem requires some more advanced topics, in particular the Ascoli4 compactness theorem,5 and is omitted.

Theorem 2.2.8 (Local existence). Suppose that f is continuous in

.t0; x0/ be a point in the interior of . Then the Cauchy problem

² x0

D f .t; x/

x.t0/ D x0

Â R2 and let

has at least one solution defined in a neighborhood of t0.

For example, this result applies to the Cauchy problem x0

D

p 2 x;

x.0/ D

0,

discussed earlier, and guarantees that it has at least one solution.

Remark 2.2.9. If the equation is F .t; x; x0/ D 0, we first have to put it in normal
form, if possible, and then use the existence and uniqueness results sated above. For example, if a.t/ 6D 0 for all t then a.t/x0 D f .t; x/ is clearly equivalent to the
equation x0 D f .t; x/ a.t /

which is in normal form. However, if a.t/ vanishes somewhere, solving a.t/x0 D
f .t; x/ is more complicated and requires a specific study. For example, for all c 2 R the straight lines x D ct are solutions of tx0 D x.
In particular, there are infinitely many solutions passing through .0; 0/. On the other hand, the solutions of tx0 D x are given by x D ct 1, c 2 R. If c D 0 we find x D 0 which is the only solution passing through .0; 0/, while if c 6D 0 the solutions are not defined for t D 0, where the equation has a singularity.
The possible zeros of a.t/ are called singular points of the equation a.t/x0 D
f .t; x/. A discussion of some linear equations with singular points will be carried
out in Chapter 10.

2.2.2 Global existence and uniqueness
As mentioned before, Theorem 2.2.1 is local. The next global result holds, provided the set is a strip and fx is bounded w.r.t. x.
Theorem 2.2.10 (Global Existence and Uniqueness). Let be the strip D OEa; b R and let .t0; x0/ be a given point in the interior of . Suppose that f is continuous in and has continuous partial derivative with respect to x and that the

3 Giuseppe Peano (1858­1932). 4 Guido Ascoli (1887­1957). 5 A statement of the Ascoli Theorem is reported in Chapter 13.

2.3 Qualitative properties of solutions 25

partial derivative fx.t; x/ is bounded in the strip. Then the Cauchy problem

² x0

D f .t; x/

x.t0/ D x0

has a unique solution defined for all t 2 OEa; b.

Corollary 2.2.11. If D R2, D OEa; C1/ R, or D . 1; b R, and fx.t; x/ is bounded in , then the solution is defined respectively on all of R, on OEa; C1/, or on . 1; b.

Theorem 2.2.10 and Corollary 2.2.11 are particular cases of the more general Theorem 2.4.5 in the next section.
The new feature of the preceding results is that now the solution is defined on the whole interval OEa; b.

Remark 2.2.12. Example 2.2.2 shows that the condition that fx is bounded in the strip cannot be removed.
Example 2.2.13. Let p; q 2 C.OEa; b/ and consider the linear equation x0 C p.t/x D q.t/ discussed in Chapter 1. In this case, f .t; x/ D p.t/x C q.t/ and fx.t; x/ D
p.t/, which is bounded in OEa; b and hence Theorem 2.2.10 applies. This provides an alternate proof of the existence and uniqueness result stated in Theorem 1.4.2 in Chapter 1. Note that the solutions of x0 C p.t/x D q.t/ are defined on the whole interval OEa; b. Moreover, Corollary 2.2.11 implies that, if p; q 2 C.R/ the solutions are defined on all of R.

2.3 Qualitative properties of solutions
In this section we study some qualitative properties of solutions, using the Global Existence and Uniqueness result stated before.
In the sequel it is understood that the assumptions of this theorem are satisfied. Moreover, for simplicity, we will also assume that D R R.
We note that a certain qualitative behavior of a solution may be found without actually solving the corresponding equation explicitly. Apart from those equations that possess solutions in terms of elementary functions (which are very few: most of them are discussed in the next chapter), the procedure involving qualitative study is often the only way to understand certain features of the solutions, such as symmetry, monotonicity, asymptotic behavior, convexity, etc.
We start with simple symmetry results.
Lemma 2.3.1. Let f .x/ be odd and let x.t/ be a solution of x0 D f .x/. Then x.t/ is also a solution.
Proof. Setting z.t/ D x.t/ we find z0 D x0 D f .x/ D f . z/ Since f is odd then f . z/ D f .z/ and z0 D f .z/.

26 2 Theory of first order differential equations
Lemma 2.3.2. Let f .x/ be even and let x0.t/ be a solution of x0 D f .x/ such that x.0/ D 0. Then x0.t/ is an odd function.
Proof. Setting z.t/ D x0. t/ we find z0.t/ D x00 . t/ D f .x0. t// D f . z/ Since f is even then f . z/ D f .z/ and z0 D f .z/. Moreover, z.0/ D x0.0/ D 0. Thus, by uniqueness, z.t/ D x0.t/, namely x0.t/ D x0. t/.

Consider the autonomous equation

x0 D f .x/:

(2.8)

First of all, it is clear that for any number x0, f .x0/ D 0 if and only if x0 is a constant

solution of (2.8). By uniqueness, the non constant solutions cannot cross the constant

ones. Roughly, the possible constant solutions divide the plane .t; x/ into horizontal

strips (which could be bounded or not), filled up by non constant solutions of (2.8). More precisely, taken any .t0; x0/ 2 R2, let .t/ denote the solution of the ivp

´ x0 D f .x/; x.t0/ D x0:

(2.9)

If f .x0/ D 0 then .t/ Á x0 is a constant solution. If f .x0/ > 0 then .t/ is
increasing, while if f .x0/ < 0 then .t/ is decreasing. If .t/ (is defined for all t and) is increasing or decreasing, it has limits L (finite or infinite) as t ! 1. The finite limits are zeroes of f . To see this, let e.g. LC < C1. In such a case it is easy to check that 0.t/ ! 0 as t ! C1. Passing to the limit in the identity
0.t/ D f . .t// we find

0 D lim f . .t// D lim f .x/ D f .LC/:

t !C1

x!LC

Furthermore, if f is differentiable, then .t/ is twice differentiable and one has

00.t/ D d 0 D d f . .t// D f 0. .t// 0 .t/ D f . .t//f 0. .t//: dt dt
This allows us to find the sign of 00.t/ and hence the convexity of .

(2.10)

Example 2.3.3. Let ; ,  <  be two consecutive zeroes of f and suppose that f .x/ > 0 for  < x < . Taking x0 2 .; /, from the discussion above it follows that .t/ is increasing,  < .t/ <  for all t and

lim .t/ D ;
t! 1

lim .t/ D :
t !C1

Moreover, let us assume that f is differentiable, and let x 2 .; / be such that f 0.x / D 0, f 0.x/ > 0 for  < x < x and f 0.x/ < 0 for x < x < . Since .t/ is increasing and  < .t/ < , then the equation .t/ D x has a unique solution
t and  < .t/ < x for t < t while x < .t/ <  for t > t . Hence (2.10)

2.3 Qualitative properties of solutions 27 x

x0 x*

t*

t0

t

Fig. 2.5. Qualitative behavior of the solution .t / of (2.9)

implies that 00.t / D 0, 00.t/ > 0 for  < t < t and 00.t/ < 0 for t < t < . See Figure 2.5 where we have taken  < 0 < x < x0 < .

Dealing with a general non autonomous equation x0 D f .t; x/

the situation is quite different. We limit ourselves to discuss the possible maxima or minima of a solution .t/. If t is such that 0.t / D 0 then, setting x D .t /, and M0 D ¹.t; x/ 2 R2 W f .t; x/ D 0º one has

f .t ; x / D 0; i:e: .t ; x / 2 M0:

Moreover, if f is differentiable, from the identity 0.t/ D f .t; .t// it follows that

00.t/ D ft .t; .t// C fx.t; .t// 0 .t/ D ft .t; .t// C fx.t; .t//f .t; .t//:

If t is such that 0.t / D 0, then

00.t / D ft .t ; x /:

(2.11)

Hence has a maximum or a minimum at t D t depending on whether ft .t ; x / < 0 or ft .t ; x / > 0. In other words, letting
M D ¹.t; x/ 2 R2 W ft .t; x/ < 0º; MC D ¹.t; x/ 2 R2 W ft .t; x/ > 0º;

one has
(i) If .t ; x / D .t ; .t // 2 M0 \ M then .t/ has a maximum at t D t . (ii) If .t ; x / D .t ; .t // 2 M0 \ MC then .t/ has a minimum at t D t .

28 2 Theory of first order differential equations x
t

Fig. 2.6. The red curve is the parabola x2 D 4t , where the solutions of x0 D x2 C 4t have minima
Example 2.3.4. (i) Consider the equation x0 D x2 C 4t. Setting f .t; x/ D x2 C 4t we find M0 D ¹.t; x/ 2 R2 W x2 D 4tº. Furthermore ft .t; x/ D 4 and thus M D ; and MC D R2. Therefore the solutions of x0 D x2 C 4t have only minima located on the parabola x2 D 4t. See Figure 2.6.
(ii) Show that the solution .t/ of x0 D x2 t2, x.a/ D a ¤ 0 has a maximum at t D a, if a > 0, a minimum if a < 0.
One has 0.a/ D 2.a/ a2 D a2 a2 D 0. Moreover, using (2.11) we infer that 00.a/ D 2a. Thus 00.a/ < 0 or 00.a/ > 0 depending on whether a > 0 or a < 0. Therefore if a > 0 then has a maximum at t D a; if a < 0 then has a minimum at t D a. See Figure 2.7. The case a D 0 is proposed as an exercise, see n.28 below.

x

x

a

a t

a

t

a

(a)
Fig. 2.7. Local behavior near t D a of the solution of x0 D x2 0; (b) a < 0

(b) t 2, x.a/ D a ¤ 0. (a) a >

2.3 Qualitative properties of solutions 29
The following proposition is a symmetry result for a general non autonomous equation.
Proposition 2.3.5. Suppose that f .t; x/ is odd with respect to t, that is f . t; x/ D f .t; x/. Then the solutions of x0 D f .t; x/ are even functions.
Proof. Let x.t/ be any solution of x0 D f .t; x/. Setting z.t/ D x. t/ one has
z0.t/ D x0. t/ D f . t; x. t// D f . t; z.t//:
Since, by assumption, f . t; z/ D f .t; z/, we deduce
z0 D f .t; z/:
Thus x.t/ and z.t/ satisfy the same equation. Moreover x; z satisfy the same initial condition at t D 0 because one has z.0/ D x.0/. Since f is continuously differentiable, the uniqueness statement in Theorem 2.4.4 applies and hence x.t/ D z.t/, namely x.t/ D x. t/, proving that x.t/ is an even function, as required.

The next result allows us to compare solutions of two differential equations.

Theorem 2.3.6. Let xa.t/; yb.t/ be solutions of the Cauchy problems

² x0

D f .t; x/

² y0

D g.t; y/

x.t0/ D a

y.t0/ D b

defined in a common interval OEt0; /. If a < b and f .t; x/ < g.t; x/, then xa.t/ < yb.t/ for all t 2 OEt0; /.

Proof. We argue by contradiction. Suppose that the set

S D ¹t 2 OEt0; / W xa.t/ yb.t/º

is not empty. Let be its infimum, namely its greatest lower bound. Since xa.t0/ D a < b D yb.t0/, by the Sign Permanence Theorem of continuous functions, there exists > 0 such that xa.t/ < yb.t/ for all t 2 OEt0; t0 C / and thus t0 C > t0. Moreover, since is the infimum of the set S then there exists a sequence tj > with tj ! and such that xa.tj / yb.tj /. Passing to the limit one finds xa. / yb . /. But xa. / cannot be strictly greater than yb. / because, otherwise, using again the Sign Permanence Theorem, we would have xa.t/ > yb.t/ in a left neighborhood of and this is in contradiction with the fact that D inf S .
Recall that xa. C h/ < yb. C h/ for h < 0 small, because D inf S . Then, taking into account that xa. / D yb. / and that h < 0 we deduce that the incremental ratios satisfy

xa. C h/

xa. / > yb. C h/

yb .

/ ;

8 h < 0; small:

h

h

30 2 Theory of first order differential equations Passing to the limit as h ! 0, h < 0, we infer that xa0 . / y0. /. But this is impossible, since, by assumption,
xa0 . / D f . ; xa. // < g. ; yb. // D y0. /:
We have proved that S is empty and therefore that xa.t/ < yb.t/ for all t 2 OEt0; /.

The next examples show how we might apply the comparison theorem.

Example 2.3.7. (i) Let xa.t/ be a positive solution of x0 D f .x/ such that x.t0/ D a.

Suppose that f .x/ < kx for some k > 0, and that xa.t/ is defined on an interval

OEt0 C 1/. Then xa.t/ decays exponentially to 0 as t ! C1. To see this, let yb.t/ be the solution of y0 D ky, y.t0/ D b > max¹a; 0º, namely yb.t/ D be k.t t0/.
Then applying the previous Proposition with g.y/ D ky, it follows that 0 < x.t/ Ä be k.t t0/ and the result follows.

(ii) Let yb.t/ be the solution of

² y0

D g.t; y/

y.t0/ D b

and suppose it is defined on OEt0 C 1/. If g.t; y/ > k > 0 and b > 0, then limt!C1 yb.t/ D C1. Applying the Proposition with f .t; x/ D k and a D 0, we infer yb.t/ k.t t0/, from which the claim follows at once.

2.4 Improving the existence and uniqueness results

The assumptions in the preceding theorems can be weakened, which means that the results can be extended to include a larger class of functions. We indicate below the main extension of this kind.

Definition 2.4.1. The function f .t; x/ defined in a set Â R2, is locally lipschitzian6

(or simply lipschitzian) at a point .t0; x0/ 2 with respect to x, if there exists a

neighborhood U

of .t0; x0/ and a number L > 0 such that

jf .t; x/ f .t; z/j Ä Ljx zj; 8 .t; x/; .t; z/ 2 U:

We say that f is globally lipschitzian on if there exists L > 0, such that

jf .t; x/ f .t; z/j Ä Ljx zj; 8 .t; x/; .t; z/ 2 :

From the definition it immediately follows that any locally lipschitzian function is continuous at .t0; x0/. Moreover, one has:
6 Rudolph Lipschitz (1832­1903).

2.4 Improving the existence and uniqueness results 31
Lemma 2.4.2. Let f .t; x/ be continuously differentiable with respect to x in . If there exists > 0 such that fx.t; x/ is bounded in U D ¹jt t0j < º ¹jx x0j < º, then f is lipschitzian on U .

Proof. Applying the Mean Value Theorem to the function f .t; x/ we infer that
f .t; x/ f .t; z/ D fx.t; /.x z/; where x < < z. Since L D sup¹jfx.t; /j W .t; / 2 U º is finite by assumption, it follows that
jf .t; x/ f .t; z/j Ä Ljx zj; 8 .t; x/; .t; z/ 2 U;

proving the lemma.

Example 2.4.3. (i) The function f .x/ D jxj is globally lipschitzian with constant

L D 1, but is not differentiable at x D 0. Actually, jf .x/ f .z/j D jjxj jzjj Ä

jx zj for all x; z 2 R. Moreover, since

²

jxj D

x if x < 0 x if x > 0

then the left derivative of f at x D 0 is 1, while the right derivative is C1. Thus f

is not differentiable at t D 0. (ii) The function f .x/ D x2 is locally lipschitzian at any point but not globally

lipschitzian on R. To prove this claim we first notice that f .x/ is differentiable with derivative f 0.x/ D 2x, which is bounded on every bounded subset of R. Then, ac-

cording to the previous lemma, f is locally lipschitzian at any point. If f were globally lipschitzian on R, then there would exist L > 0 such that jx2 z2j Ä Ljx zj for all x; y 2 R. Since jx2 z2j D jx C zj jx zj it follows that jx C zj Ä L for

all x; z 2 R, which is obviouslypfalse.

(iii) The would exist

function f .x/ D > 0 and L > 0

jxj such

tihs antotplijpxsjchitpzijaznj

atÄx

D 0. Ljx

Otherwise, there zj for all x; z 2

p

. ; /. In particular, taking z D 0, we get jxj Ä Ljxj for all x 2 . ; /, which

is obviously false.

Using the previous definition, one can prove the following local and global existence result which holds for equations in normal form and extend the existence and uniqueness Theorems 2.2.1 and 2.2.10 as well as Corollary 2.2.11.

Theorem 2.4.4. Let .t0; x0/ be a given point in the interior of . If f is locally lip-

schitzian with respect to x at .t0; x0/, then the Cauchy problem

² x0

D f .t; x/

x.t0/ D x0

has a unique solution defined in a suitable neighborhood of t0.

32 2 Theory of first order differential equations p
In Example 2.2.6 we have shown that the ivp x0 Dp2 jxj, x.0/ D 0, has infinitely many solutions. Notice that the function f .x/ D 2 jxj is not lipschitzian at x D 0 (see Example 2.4.3(iii) above). This shows that the preceding result is sharp, in the sense that we cannot guarantee uniqueness of the Cauchy problem (2.4) if f is not lipschitzian at .t0; x0/.

Theorem 2.4.5. Suppose that D OEa; b R (resp. D R R), and f is globally

lipschitzian in . Let .t0; x0/ 2 be given. Then the Cauchy problem

² x0

D f .t; x/

x.t0/ D x0

has a unique solution defined on all of OEa; b (resp. on all of R).

The proofs are given in the Appendix below.
Example 2.4.6. Since jxj is globally lipschitzian, the Cauchy problem x0 D jxj; x.0/ D x0 has a unique solution x.t/, defined for t 2 R. Precisely, if x0 D 0 then x.t/ Á 0. The other solutions x.t/ never vanish. If x0 > 0, then x.t/ > 0 and the equation becomes x0 D x, and hence x.t/ D x0et . If x0 < 0 then x.t/ < 0, the equation is x0 D x and x.t/ D x0e t . In any case x.t/ is increasing provided x0 D6 0.

2.5 Appendix: Proof of existence and uniqueness theorems

2.5.1 Proof of Theorem 2.4.5

Let us first prove Theorem 2.4.5 dealing with uniqueness and global existence of the

Cauchy problem

² x0

D f .t; x/

x.t0/ D x0

(2.12)

where f .t; x/ is defined in the strip S D ¹.t; x/ 2 R2 W a Ä t Ä bº, .t0; y0/ 2 S and f is continuous and globally lipschitzian in S . Let us recall that this means that there exists L > 0 such that

jf .t; x/ f .t; y/j Ä Ljx yj; 8 .t; x/; .t; y/ 2 S:

(2.13)

The strategy is to find a sequence of functions that converges to the solution of (2.12). For this, it is convenient to transform the ivp (2.12) into an equivalent integral equation.

Lemma 2.5.1. x.t/ is a solution of (2.12) if and only if x.t/ satisfies

Zt
x.t/ D x0 C f .s; x.s//ds;
t0

8 t 2 OEa; b:

(2.14)

2.5 Appendix: Proof of existence and uniqueness theorems 33

Proof. Let x.t/ be a solution of (2.12). This means that x0.t/ Á f .t; x.t// and

hence integrating from t0 to t we find

Zt

Zt

x0.t/dt D f .s; x.s//ds;

t0

t0

8 t 2 OEa; b:

Since x.t0/ D x0 the first integral is equal to x.t/ x.t0/ D x.t/ x0 and thus, 8 t 2 OEa; b one has

Zt

Zt

x.t/ x0 D f .s; x.s//ds H) x.t/ D x0 C f .s; x.s//ds;

t0

t0

namely x.t/ satisfies (2.14). Conversely, let x.t/ satisfy (2.14). If for t 2 OEa; b we set
Zt .t/ D f .s; x.s//ds
t0

by the fundamental theorem of calculus is continuous, differentiable and

0.t/ D f .t; x.t//:

Thus x.t/ D x0 C .t/ is differentiable in OEa; b and x0.t/ D 0.t/ D f .t; x.t//; 8 t 2 OEa; b:

Moreover,

Z t0 x.t0/ D x0 C f .s; x.s//ds D x0
t0

and hence x.t/ satisfies the ivp (2.12), completing the proof of the lemma.

Define by recurrence a sequence of functions such that for all t 2 OEa; b and all integers k D 0; 1; 2; : : :

x0.t / D x0 Z t

x1.t/ D x0 C f .s; x0/ds

Zt0t

x2.t/ D x0 C f .s; x1.s//ds

:::

:::

t0
Zt

xkC1.t / D x0 C f .s; xk.s//ds:

t0

Lemma 2.5.2. The sequence xk.t/ is uniformly convergent in OEa; b.

34 2 Theory of first order differential equations

Proof. Let us start by showing by induction that for all k D 1; 2; ::

jxk .t /

xk

1.t/j Ä

M L

jt

t0jkLk ; kS

8 t 2 OEa; b

(2.15)

where M D max¹jf .t; x0/j W t 2 OEa; bº.

To simplify notation, we carry out the proof taking t t0. The case t Ä t0 requires

obvious changes7. For k D 1 we have, using the assumption that f is lipschitzian,

jx2 .t /

x1.t /j

D

Z

t
.f .s; x1.s/

Z

t0 t

f .s; x0//ds

Ä jf .s; x1.s// f .s; x0/jds

t0Z t

Ä L jx1.s/ x0jds:

t0

On the other hand,

jx1.s/ x0j D Z s f .r; x0/d r  Ä Z s jf .r; x0/jd r  Ä M js t0j

t0

t0

and thus

jx2 .t /

Zt
x1.t/j Ä ML js
t0

ML

t0jds D

jt 2

t0j2;

8 t 2 OEa; b;

which proves (2.15) for k D 1. By induction, we assume that (2.15) holds for k 1. Repeating the previous ar-

guments, we find Zt
jxk.t/ xk 1.t/j Ä jf .s; xk 1.s// f .s; xk 2.s//jds t0Z t
Ä L jxk 1.s/ xk 2.s/jds; 8 t 2 OEa; b:
t0

Using the induction hypothesis we find

jxkC1.t /

xk.t/j Ä L

M L

Lk 1 Z t js
.k 1/S t0

t0jk 1ds

Ä M Lk jt t0jk D M jt t0jk Lk ; 8 t 2 OEa; b:

L .k 1/S k

L kS

Therefore (2.15) holds for all natural numbers k. Since (2.15) holds for all t 2 OEa; b, then

M .b

max jxkC1.t /
t 2OEa;b

xk.t/j Ä L

7
f

.Fso;rxe0x/jadmsp lÄe,

in the :::

next

equation

we

should

write

jx2.t /

a/k Lk :
kS

(2.16)

x1.t /j

Ä

 R t
t0

jf .s; x1.s//

2.5 Appendix: Proof of existence and uniqueness theorems 35

The sequence

.b a/k Lk ! 0 kS

.k ! C1/

because the series

X OEL.b a/k tk kS

is convergent to eL.b a/t. Thus (2.16) implies that the sequence xk.t/ is uniformly convergent on OEa; b, as required.

Proof of Theorem 2.4.5. By Lemma 2.5.2, the sequence xk.t/ ! x.t/, uniformly in OEa; b. Then f .s; xk.s// ! f .s; x.s//, uniformly in OEa; b and we can pass to the
limit under the integral in
Zt
xkC1.t / D x0 C f .s; xk.s//ds
t0

yielding

Zt
x.t/ D x0 C f .s; x.s//ds:
t0

According to Lemma 2.5.1 it follows that x.t/ is a solution of the ivp (2.12). It remains to prove the uniqueness. We will first consider an interval jt t0j Ä i
where i is such that Li < 1 (hereafter it is also understood that t 2 OEa; b) and show
that two solutions x.t/; y.t/ of (2.12) coincide therein. One has Zt
x.t/ y.t/ D .f .s; x.s// f .s; y.s//ds
t0

and hence jx.t/ y.t/j Ä Z t jf .s; x.s//
t0

f .s; y.s//jds Ä L Z t jx.s/
t0

y.s/jds

Ä Ljt t0j max jx.t/ y.t/j Ä Li max jx.t/ y.t/j:

jt t0jÄi

jt t0jÄi

Taking the maximum of the left-hand side on jt t0j Ä i we find

max jx.t/ y.t/j Ä iL max jx.t/ y.t/j:

jt t0jÄi

jt t0jÄi

Letting A D maxjt t0SÄi jx.t/ y.t/j > 0, we divide by A finding 1 Ä Li, a contradiction because we have chosen i such that Li < 1. Thus

max jx.t/ y.t/j D 0;
jt t0jÄi
which implies that x.t/ D y.t/ on the interval jt t0j Ä i. In particular, x.t0  i/ D y.t0  i/. We can now repeat the procedure in the interval OEt0 C i; t0 C 2i and

36 2 Theory of first order differential equations
OEt0 2i; t0 i. Then we find that x.t/ D y.t/ for all t 2 OEt0 2i; t0 C 2i. After a finite number of times we find that x.t/ D y.t/ for all t 2 OEa; b. This completes the proof.

2.5.2 Proof of Theorem 2.4.4

Here we will prove Theorem 2.4.4 on the local existence and uniqueness result for the

ivp (2.12), where it is assumed that f .t; x/ is defined in

R2 and is locally lip-

schitzian near .t0; x0/. Let us recall that this means that there exists a neighborhood

U

of .t0; x0/ and a number L > 0 such that

jf .t; x/ f .t; y/j Ä Ljx yj; 8 .t; x/; .t; y/ 2 U:

(2.17)

Without loss of generality we can take U D Ur as the (closed) square ¹.t; x/ 2 W jt t0j Ä r; jx x0j Ä r º, for some r > 0. We will deduce Theorem 2.4.4 from
Theorem 2.4.5 proved in the preceding section. To this end, let us consider the strip

Sr WD ¹.t; x/ 2 R2 W jt t0j Ä r º

and extend f to the function f W Sr 7! R defined by setting 8

< f .t; x0 r / if .t; x/ 2 Sr and x Ä x0 r

f

.t; x/

D

:

f .t; x/ f .t; x0

C

r/

if .t; x/ 2 Ur if .t; x/ 2 Sr and x

x0 C r:

It is easy to check that f is globally lipschitzian on Sr . For example, if x; y are such that x0 r < x < x0 C r Ä y, then f .t; x/ D f .t; x/, f .t; y/ D f .t; x0 C r / and one has

jf .t; x/ f .t; y/j D jf .t; x/ f .t; x0 C r /j Ä Ljx x0 r j Ä Ljx yj:

Since f is globally lipschitzian on Sr , the global Theorem 2.4.5 yields a solution x.t/, defined on OEt0 r; t0 C r , of the ivp
² x0 D f .t; x/ x.t0/ D x0:

The range of the function x.t/ could be outside OEx0 r; x0 C r , where f D6 f . To overcome this problem we use the fact that x.t/ is continuous and x.t0/ D x0. Then there exists i > 0 such that

t 2 OEt0 i; t0 C i H) jx.t/ x0j Ä r:

Therefore, for t 2 OEt0 i; t0 C i one has that f .t; x.t// D f .t; x.t// and hence x.t/, restricted to such an interval, solves the ivp (2.12).

2.6 Exercises 37

2.6 Exercises

1. Check that the local existence and uniqueness theorem applies to the ivp x0 D t C x2, x.0/ D 0.

2. Show that the function f .x/ D jxjp is not lipschitzian at x D 0 if 0 < p < 1.

3. Find a such that the existence and uniqueness theorem applies to the ivp x0 D

3 2

jxj1=3,

x .0/

D

a.

4. Check that for all t0; a the existence and uniqueness theorem applies to the ivp ln x0 D x2; x.t0/ D a.

5.

Explain why x0 C

sin t et C1

x

D

0 cannot have a solution x.t/ such that x.1/

D

1

and x.2/ D 1.

6. Transform the equation ex0 D x into an equation in normal form and show that

it has a unique solution such that x.t0/ D a, for all t0 and all a > 0.

7.

Find

the

equation whose

solution

is

the

catenary

x .t /

D

cosh t

D

1 2

.e

t

Ce

t /.

8. Check that the functions x.t/ Á 1 and

²

.t/ D

sin t if 2 Ä t Ä 2 1 if t > 2

p are solutions of the ivp x0 D 1 x2, x. 2 / D 1.

9. Find a 0 such that the Cauchy problem x0 D jxj1=4, x.0/ D a has a unique

solution.

10. Show that if p > 1 the solution of x0 D xp, x.0/ D a > 0, is not defined for all t 0.

11. Show that if 0 < p Ä 1, the solution of x0 D jxjp, x.0/ D a > 0, is defined for all t 0.

12. Show that the solutions of x0 D sin x are defined on all t 2 R.

13. Show that the solutions of x0 D arctan x are defined on all t 2 R.

14. Show that the solutions of x0 D ln.1 C x2/ are defined on all t 2 R.

15. Show that the ivp x0 D max¹1; xº, x.0/ D 1, has a unique solution defined for all t and find it.

16. Show that the ivp x0 D max¹1; xº, x.0/ D 1, has a unique solution defined for all t and find it.

17. Show that the solution of x0 D t2x4 C 1, x.0/ D 0 is odd.

18. Show that, if f .x/ > 0, resp. f .x/ < 0, the solutions of x0 D f .x/ cannot be even.

38 2 Theory of first order differential equations
19. Show that the solution x.t/ of the Cauchy problem x0 D 2 C sin x, x.0/ D 0, cannot vanish for t > 0.
20. Let f .x/ be continuously differentiable and such that f .0/ D 0. Show that the solutions of x0 D f .x/h.t/ cannot change sign.
21. Show that the solutions of x0 D sin.tx/ are even.
22. Find the limits, as t ! 1, of the solution .t/ of the ivp x0 D .x C 2/.1 x4/, x.0/ D 0.
23. Show that for every a, 1 < a < 1 the solution .t/ of the ivp x0 D x3 x, x.0/ D a is such that limt!C1 .t/ D 0.
24. Show that the solutions of x0 D arctan x C t cannot have maxima.
25. Show that the solutions of x0 D ex t cannot have minima.
26. Let .t/ be the solution of the ivp x0 D tx t3, x.a/ D a2 with a ¤ 0. Show that has a maximum at t D a.
27. Let .t/ be the solution of the ivp x0 D tx t3, x.0/ D a2 with a ¤ 0. Show that has a minimum at t D 0.
28. Show that the solution .t/ of x0 D x2 t2, x.0/ D 0, has an inflection point at t D 0.
29. Suppose that g.x/ is continuously differentiable and let .t/ be the solution of x0 D tg.x/, x.0/ D a. If g.a/ > 0, show that the function .t/ has a minimum at t D 0, for all a 2 R.
30. Show that the solution xa.t/ of x0 D 2t C g.x/, xa.0/ D a > 0 satisfies xa.t/ t C t2 for t > 0, provided g.x/ 1.
31. Let xa.t/ be the solution of of x0 D t C g.x/, xa.0/ D a,with 0 < a < 2. If xa.t/ is defined for all t > 0 and g.x/ Ä x, show using the comparison Theorem 2.3.6 that the equation xa.t/ D 0 has at least one positive solution in .0; 2/.

3 First order nonlinear differential equations

The main focus of this chapter is on learning how to solve certain classes of nonlinear differential equations of first order.

3.1 Separable equations

An equation of the form

x0 D h.t/g.x/

(3.1)

is called a separable equation. Let us assume that h.t/ is continuous with h.t/ Á6 0

and g.x/ is continuously differentiable in the domain being considered, so that the

local existence and uniqueness Theorem 2.2.1 of Chapter 2 applies.

If x D k is any zero of g, g.k/ D 0, then x.t/ Á k is a constant solution of

(3.1). On the other hand, if x.t/ D k is a constant solution, then we would have

0 D h.t/g.k/; t 2 R; and hence g.k/ D 0 since h.t/ Á6 0. Therefore, x.t/ D k is

a constant solution (or equilibrium solution) if and only if g.k/ D 0. There are no

other constant solutions. All the non-constant solutions are separated by the straight

lines x D k. Hence if x.t/ is a non-constant solution then g.x.t// 6D 0 for any t, and

we can divide

x0 D h.t/g.x/

by g.x/ yielding

x0.t/ D h.t/: g.x .t //

We

integrate

both

sides

withZrespxe0c.tt

to /

t d

and tD

oZbtain h.t /d t :

g.x .t //

Since

x0

D

dx dt

,

we

have

Z

Z

dx

D h.t/dt C c:

g.x/

(3.2)

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_3

40 3 First order nonlinear differential equations

We wish to point out that while it is very easy to express solutions of a separable

equation implicitly in terms of integrals, it may be difficult or even impossible to per-

form the actual integration in terms of simple and familiar functions. In such cases,

one can carry out a qualitative analysis to get some information about the behavior of

solutions, see for example Section 2.3 in the previous chapter. Otherwise, if needed,

one could use numerical methods or computer software to obtain approximate solu-

tions to a reasonable or needed degree of accuracy.

If we want to solve the initial value problem

² x0

D h.t/g.x/

x.t0/ D x0

(3.3)

we simply substitute the initial value x.t0/ D x0 into (3.2) and solve for c. Note that this equation has a unique solution, according to Theorem 2.2.1 of Chapter 2.
Essentially, the idea behind solving separable equations is to separate the variables and then integrate.

Example 3.1.1. (i) Consider the equation x0 D h.t/x. We notice that this is a linear

homogeneous first order equation, and we learned in Chapter 1 how to solve such

edRqehsuc.atrti/ibodentdsC.aBbcuo, twvethh.iicSsheipsyaiaerlalsdtoisnalgnstjehxpejaDvraabrRilaehbe.letq/sudaattniCdonctha.enTndhiuwnste,elgecrtaatnitninsgogcl,v1weDeitobbyetacti,hnweRemodexbxthtaoDidn

the general solution

R
x.t / D c1 e h.t/dt

in accordance with the result stated in Theorem 1.4.2 of Chapter 1.

(ii) Solve x0

D

t2 1C3x2

.

R .1TCher3exa2r/ednxoDcoRnstta2ndttsColuctiaonnds.hSeenpcaerating the variables and integrating, we have

x C x3 D t3 C c 3

which defines the solutions implicitly. Moreover, since the function ^.x/ D x C x3

is increasing and its image is all of R, it has an (increasing) inverse ' defined on all

of R. Thus ^.x/

D

t3 3

C c yields x.t/

D

'.

t3 3

C c/. Note that the solutions are

defined globally on R. The reader might check that this also follows from the Global

Existence Theorem 2.2.10 of Chapter 2. (iii) Find the solution of the initial value problem x0 D 2tx3, x.0/ D 1.
The only constant solution is x Á 0. Therefore if x.t/ is a solution such that x.0/ D 1, then, by uniqueness, x.t/ cannot assume the value 0 anywhere. Since x.0/ D 1 >

0, we infer that the solution is always positive. Using (3.2) we find

Z

Z

dx

x3 D 2t dt C c:

3.1 Separable equations 41
x

t

-1/2

O

1/2

Fig. 3.1. Plot of x D p 1
1 2t2

Carrying out the integration it follows that

1 2x2

D

t2

C c:

The initial condition x.0/ D 1 yields c D

1 2

and

hence

1 2x2

D

t2

1 :
2

Solving for x, and recalling that x > 0, we find

xDp 1 : 1 2t2

The graph of the solution is reported in Figure 3.1. Notice that in the present case

the maximal interval of definition is given by p1 < t < p1 .

2

2

3.1.1 The logistic equation

As a remarkable example of a separable equation, we consider a model, due to P.F. Verhulst1, in which one assumes that the variation x0 of the number of individuals in

a population is proportional to x, but through a factor of . x/. This leads to the

equation

x0.t/ D x.t/. x.t//; ;  > 0:

(3.4)

Contrary to the Malthusian model discussed in the first chapter, here the constant factor k is substituted by the function  x. The fact that this function is decreas-
1 Pierre François Verhulst (1804 - 1849).

42 3 First order nonlinear differential equations

ing with respect to x may be explained by the observation that the bigger x is the

more difficult it will be for an individual to find resources, such as food, space, etc,

and hence the more difficult it will be to survive. This equation is called the logistic

equation.

Since in this model, x.t/ represents the population of some species, we are inter-

ested in solutions x.t/ such that x.t/ 0. Solving x. x/ D 0 we see that x D 0

and x

D

 

are the equilibrium solutions. Such solutions play an important role in

analyzing the trajectories of solutions in general. We now study solutions x.t/, where

x.t/ > 0 for all t 0.

By uniqueness, the other solutions cannot cross the trajectories (which are lines

in this case) defined by the two equilibrium solutions. Hence for any non-constant

solution x.t/, x.t/ 6D 0 and x.t/ 6D = for any t. Thus, the two lines x D 0 and

x

D

 

divide the trajectories into two classes:

those that

lie above the line x

D

 

and

those

that

lie

between

the

lines

x

D

0

and

x

D

 

.

In Section 2.3 of the previous chapter we discussed how one might extract infor-

mation about the qualitative behavior of solutions without solving the corresponding

equations. We now discuss methods of finding solutions either explicitly or implic-

itly.

In order to solve the logistic equation, we separate the variables and obtain

dx D dt x. x/

assuming

that

x

¤

0

and

x

¤

 

.

The

left

side

can

be

integrated

by

partial

fractions

method. We search for constants A and B such that

1

DAC B

x. x/ x  x

and

find

A

D

1 

and

B

D

A

D

 

.

Therefore,

we

have

Z

Z

Z

1 dx C 

dx D dt C c

 x   x

which yields

1 ln jxj 1 ln j xj D 1 ln j x j D t C c





  x

from which we obtain

 

x .t / x .t /



D

e.t Cc/

D

ket ;

.k D ec/:

(3.5)

This is the general solution in implicit form. To solve for x we distinguish the cases

0

<

x .t /

<

 

and

x .t /

>

 

.

In

the

first

case

one has that



x.t / x.t /

>

0. Then

(3.5)

becomes

x.t / D ket  x.t/

3.1 Separable equations 43

and, solving for x,

ket x.t/ D 1 C ket :

(3.6)

If

x .t /

>

 

one has

that



x.t / x.t /

<

0.

Then

(3.5)

becomes

x.t / D ket  x.t/

and, solving for x,

x.t/ D 1

ket ket :

(3.7)

In any case, one finds that

lim

x .t /

D

 :

t !C1



This shows that all non-constant solutions approach the equilibrium solution x.t/ D

 

as t

!

1, some from above the line x

D

 

and others from below (see Fig-

ure 3.2). The reader will notice that the behavior of x.t/ is totally different from the

one found in the Malthusian model.

Assuming that the initial size of the poulation is a, we can determine the size of

the population at any time t by solving the Cauchy problem

´ x0 D x. x/;

x.0/ D a:

x

/

t O
Fig. 3.2. Solutions of the logistic equation for x.0/ > = and x.0/ < =

44 3 First order nonlinear differential equations

Assaaumi.nIgf

a 0

> <

0 and

a

<

 

a¤ then

 
k

, we D

use (3.5) and the

a a

,

while

if

a

>

initial condition

 

then k

D



to find k D

a a

,

namely

k

D



a a

.

Therefore

both

(3.6)

and

(3.7)

imply

a et

x.t/ D  a

D

1 C a et 

 a

aet a C aet :

Example 3.1.2. Solve (i) x0 D x.2 x/, x.0/ D 1 and (ii) x0 D x.2 x/, x.0/ D 3. This is a logistic equation with  D 2,  D 1, where the initial population size is given by a D 1 in case (i) and a D 3 in case (ii). Then we find

.i/

x .t /

D

2e2t 1 C e2t

;

.ii/

x.t/ D

6e2t 1 C 3e2t :

3.2 Exact equations

Consider the equations

N.x; y/ dy C M.x; y/ D 0

(3.8)

dx

and

M.x; y/ dx C N.x; y/ D 0:

(3.9)

dy

Notice that in (3.8) we use y as dependent variable and x as the independent variable, while in (3.9) the roles of x and y are exchanged: x is now the dependent variable while y is the independent variable.
The preceding equations can be stated, in a differential form, as

M.x; y/dx C N.x; y/dy D 0:

(3.10)

Let us associate with (3.10) the differential form

! D M.x; y/dx C N.x; y/dy:

We say that (3.10) is an exact equation if ! is the exact differential of a function; that is, there exists an antiderivative F .x; y/ such that dF D !, which means that
² Fx.x; y/ D M.x; y/ Fy .x; y/ D N.x; y/

and hence

M.x; y/dx C N.x; y/dy D dF .x; y/ D Fx.x; y/dx C Fy.x; y/dy:

3.2 Exact equations 45
Proposition 3.2.1. Let M; N be continuous in Â R2. Suppose that M.x; y/dx C N.x; y/dy D 0 is exact and let F .x; y/ denote an antiderivative of !. If y.x/ is a solution of (3.8) then F .x; y.x// D c, for some c 2 R. Conversely, if y.x/ is continuously differentiable and satisfies F .x; y.x// D c, for some c 2 R, then y.x/ satisfies (3.8).

Proof. Let y.x/ be a solution of (3.8). The function F .x; y.x// is differentiable and

d

dy

dx

F .x;

y.x//

D

Fx .x ;

y.x//

C

Fy .x;

y.x// dx

:

Since dF D !, then Fx D M; Fy D N and we find

d

F .x; y.x//

D

M.x; y.x//

C

N.x; y.x//

dy :

dx

dx

By assumption, y.x/ is a solution of (3.8) and hence

d F .x; y.x// D 0 dx
which implies that F .x; y.x// is constant, namely F .x; .y.x// D c, c 2 R. Conversely, let y.x/ be continuously differentiable and satisfy F .x; y.x// D c
for some c 2 R. Differentiating F .x; y.x// D c, we find

d dx

F .x; y.x//

D

Fx

.x;

y

.x//

C

Fy

.x;

y

.x

//

dy dx

D

0:

Since Fx D M and Fy D N we deduce that

M.x; y.x// C N.x; y.x// dy D 0 dx

and this means that y.x/ is a solution of (3.8).

Similarly, we have
Proposition 3.2.2. Let M; N be continuous in Â R2. Suppose that M.x; y/dx C N.x; y/dy D 0 is exact and let F .x; y/ denote an antiderivative of !. If x.y/ is a solution of (3.9) then F .x.y/; y/ D c, for some c 2 R. Conversely, if x.y/ is continuously differentiable and satisfies F .x.y/; y/ D c, for some c 2 R, then x.y/ satisfies (3.9).
We have seen that the solutions of the exact equation (3.10) are those defined by F .x; y/ D c, where F is an antiderivative of !. We will say that F .x; y/ D c is the general solution of (3.10).
The constant c depends on the initial conditions. If F .x; y/ D c is the general solution of (3.10), the solution curve passing through P0 D .x0; y0/ is given by F .x; y/ D F .x0; y0/.

46 3 First order nonlinear differential equations

Notice that at any point .x; y/ 2 such that N.x; y/ ¤ 0, equation (3.8) can be

put in the normal form

dy D

M.x; y/ :

dx N.x; y/

(3.11)

Similarly, at any point .x; y/ 2 such that M.x; y/ ¤ 0, equation (3.9) can be put

in the normal form

dx D

N.x; y/ :

dy M.x; y/

(3.12)

To these equations we can apply the existence and uniqueness Theorems discussed in the preceding Chapter.

Remark 3.2.3. At points .x ; y / such that M.x ; y / D N.x ; y / D 0 (3.10) is neither equivalent to (3.11) nor to (3.12). In Examples 3.2.4-3.2.5 below we illustrate some typical behavior of solutions near such points.

The simplest case of exact equations is when M D M.x/ and N D N.y/. In this case, one has My D Nx D 0. Notice that the corresponding equations

dy D M.x/ ( N 6D 0); dx D N.y/ ( M D6 0)

dx N.y/

dy M.x/

are also separable equations. An antiderivative of ! D Mdx C Ndy is given by

Z

Z

F .x; y/ D M.x/dx C N.x/dx;

since Fx D M.x/; Fy D N.y/ by the Fundamental Theorem of Calculus. We now discuss some examples of exact equations, starting with the simple case
M D M.x/; N D N.y/.

Example 3.2.4. (i) The equation xdx C ydy D 0 is exact and an antiderivative of

!

D

xdx

C

ydy

is

F .x;

y/

D

1 2

x2

C

1 2

y

2

.

Then

the

general

solution

is

given

by

x2 C y2 D c:

If c > 0 this is a family of circles centered at .0; 0/. If c D 0 then x2 C y2 D c reduces to the point .0; 0/. Notice that here M D x, N D y and they both vanish at
.0; 0/. (ii) The equation xdx ydy D 0 is also exact and the general solution is given
by x2 y2 D c:

If c ¤ 0 this is a family of hyperbola. If c D 0 then x2 y2 D 0 is the pair of straight lines y D x. Notice that here M D x, N D y and, as for (i), they both vanish at .0; 0/, the intersection point of the two straight lines.

3.2 Exact equations 47

Example 3.2.5. Find the solutions of 2xdx C 3.1 y2/dy D 0 passing through the

points .0; 1/ and .0; 1/ and discuss their behavior. Here M D 2x and N D 3.1 y2/ and hence the equation is exact. An antideriva-

tive of ! D Mdx C Ndy is

Z

Z

F .x; y/ D 2 xdx C 3 .1 y2/dy D x2 C 3y y3:

Thus the general solution is

x2 C 3y y3 D c:

If x D 0; y D 1 we find c D 2. Solving x2 D y3 3y C 2 with respect to x, we find p
x D .y/ D  y3 3y C 2:

Since y3

3y C 2 D .y C 2/.y 1/2 then  is defined for y 2 and one has

p

p

.y/ D  .y C 2/.y 1/2 D jy 1j y C 2:

This makes it clear that

.y/ have a cusp point at y D 1, while limy! 2C

0 

.y/

D

1.

If x D 0; y D 1 we find c D 2. Solving x2 D y3 3y 2 with respect to x,

we find

p x D .y/ D  y3 3y 2:

Since y3 3y 2 D .y 2/.y C 1/2 then  is defined on the set ¹ 1º [ ¹y 2º

and one has

´

p .y/ D  .y

2/.y C 1/2 D 0;

p

jy C 1j y

2;

if y D 1 if y 2:

In this case the .0; 1/ is an isolated point of the graph of x2 D y3 3y 2, while

limy!2C

0 

.y

/

D

1.

The

graph

of

x2

y3 C 3y D c with c D 2 is plotted in

Figure 3.3. Notice that at x D 0 and y D 1 both M and N vanish.

We have become somewhat familiar with the concept of an exact equation, but now we need to know (1) how to recognize an exact equation, (2) knowing that it is exact, how do we solve it? The following theorem and its proof provide the answers.

Theorem 3.2.6. Assume that M.x; y/ and N.x; y/ are continuous, with continuous partial derivatives with respect to x and y, on D .1; 2/ .1; 2/.
(i) If ! D M.x; y/dx C N.x; y/dy is exact, then My .x; y/ D Nx.x; y/. (ii) If My.x; y/ D Nx.x; y/ , then ! D M.x; y/dx C N.x; y/dy is exact.

Remark 3.2.7. The reader should be aware that in the previous theorem we assume that M; N are defined in a rectangular region , only for simplicity. In general, one

48 3 First order nonlinear differential equations
y
2 1
x -1

Fig. 3.3. Plot of x2 y3 C 3y D 2 (black) and x2 y3 C 3y D 2 (red)

could take any domain

R2 with the property that for any closed continuous

curve contained in , the set enclosed by is all contained in . For example, any convex domain satisfies this condition. On the contrary, R2 n ¹0º does not.

Proof of Theorem 3.2.6. .i / First let us assume that ! is exact. Then there exists a differentiable function F .x; y/ such that dF D !. This means that

² Fx.x; y/

D M.x; y/;

Fy.x; y/ D N.x; y/:

Therefore, we have

² Fxy .x; y/

D My .x; y/;

Fyx .x; y/ D Nx.x; y/:

Since the mixed second derivatives of F are equal, that is Fxy .x; y/ D Fyx.x; y/, we deduce that My .x; y/ D Nx.x; y/.

We provide two methods for proving part (ii), which can also be used for solving exact equations in general.

(ii-1) Now, we assume that My .x; y/ D Nx.x; y/ and seek a function F .x; y/ such that Fx.x; y/ D M.x; y/ and Fy .x; y/ D N.x; y/. Let
Z F .x; y/ D M.x; y/dx C h.y/

where h.y/ is a differentiable function of y, to be determined. We note that F .x; y/ already satisfies half of the requirement, since Fx.x; y/ D M.x; y/ by the Fundamental Theorem of Calculus. We wish to show that there exists a function h.y/ such

3.2 Exact equations 49

that Fy .x; y/ D N.x; y/. But Fy .x; y/ D N.x; y/ if and only if

Z

@ F .x; y/ D @ M.x; y/dx C h0.y/ D N.x; y/ "

@y

@y

Z

h0.y/ D N.x; y/ @ M.x; y/dx:

@y

@ @y

TRhis means that if we choose h.y/ to be any antiderivative M.x; y/dx, then F .x; y/ will be the desired antiderivative of

of !

N.x; y/ and we are

d@@yonRe.MB.uxt;wye/dcxanischaofousnechti.oyn/oifnythoisnlmy.aOnnthererownilsye,ifwweewcoaunldshhoawvethha0t.yN/,.xa;

y/ func-

tion of y, on the left side and a function of two variables x and y on the right side,

which does not make sense. In order to show the right side is a function of y only,

Rwe will show that its derivative with respect to x is 0. To this end, since the function M.x; y/dx has continuous mixed partial derivatives, we have

Ä

Z

Z

@

@

@

@@

N.x; y/

M.x; y/dx D N.x; y/

M.x; y/dx

@x

@y

@x

@x @y

Z

@

@@

D N.x; y/

@x

@y @x

M.x; y/dx D Nx.x; y/ My .x; y/ D 0:

In the above proof, we could have just as easily chosen Z
F .x; y/ D N.x; y/dy C h.x/

and determined h.x/ as we obtained h.y/ above.

(ii-2) Let .x0; y0/; .x; y/ be two arbitrary points in the rectangle . Consider the path  D .OEx0; x ¹y0º/ [ .¹xº OEy0; y/, which is contained in , see Figure 3.4,

and define F .x; y/ by

Zx

Zy

F .x; y/ D M.s; y0/ds C N.x; s/ds;

x0

y0

(3.13)

which corresponds to integrating the differential form ! along the path . Let us show

that F is an antiderivative of !, that is, Fx D M; Fy D N . Using the fundamental

theorem of Calculus, we find

@ Zy

Fx.x; y/ D M.x; y0/ C @x

N.x; s/ds:
y0

We may recall from Calculus, or show independently, by using the definition of the

derivative and the Mean Value Theorem, that

@ Zy

Zy @

N.x; s/ds D

N.x; s/ds:

@x y0

y0 @x

50 3 First order nonlinear differential equations

y

2

=(

,
1

)
2

(

,
1

2)

(x,y)

(x 0

,y
0

)

1O

(x,y0 )

1

Fig. 3.4. The path 

2

x

Since, by assumption, Nx D My we infer that
Zy Fx.x; y/ D M.x; y0/ C My .x; s/ds
y0
D M.x; y0/ C M.x; y/ M.x; y0/ D M.x; y/:

To prove that Fy D N , we notice that the first integral is a function of x only. So,

@ Zy

Fy D @y

N.x; s/ds D N.x; y/:
y0

In the above discussion, we could have also taken the path 1 D .¹x0º .OEx0; x ¹yº/ yielding

Zx

Zy

F .x; y/ D M.s; y/ds C N.x0; s/ds:

x0

y0

OEy0; y/ [

Example 3.2.8. Solve .2x C y/dx C .x C 2y/dy D 0. The equation is exact because

@.2x

C

y/

D

1

D

@.x

C

2y/ :

@y

@x

Using (3.13), with x0 D y0 D 0, we have

Zx

Zy

F .x; y/ D 2sds C .x C 2s/ds D x2 C xy C y2:

0

0

3.2 Exact equations 51 Therefore the general solution is given by
x2 C xy C y2 D c:

Notice that from xy

1 2

.x2

C

y

2

/

it

follows

that

x2

C

xy

C

y2

1 2

.x2

C

y2/

0

for all x; y and hence c 0. If c > 0, this is a family of ellipses centered at the

origin. To see this it is convenient to make a change of coordinates by setting

² x DuCv y D u v:

In the .u; v/ plane, we have .u C v/2 C .u2 v2/ C .u v/2 D c or u2 C v2 C 2uv C u2 v2 C u2 2uv C v2 D c, whence 3u2 C v2 D c. Hence, if c > 0, x2 C xy C y2 D c is a family of ellipses centered at the origin as claimed, see
Figure 3.5.
If c D 0 the ellipse degenerates to the point .0; 0/, the only point where M D 2x C y and N D x C 2y vanish. If c < 0 the equation x2 C xy C y2 D c has no
real solution.

Example 3.2.9. Solve

2xy dx C .x2 C y2/dy D 0:

Here M.x; y/ D 2xy and N.x; y/ D x2 C y2. Since My D 2x D Nx, the equation is exact. We give four solutions, using the four methods discussed above.

y

v

u

x

Fig. 3.5. x2 C xy C y2 D c > 0

52 3 First order nonlinear differential equations

Method 1. Let

Z F .x; y/ D 2xy dx C h.y/ D x2y C h.y/:

Then clearly, Fx D 2xy D M.x; y/. We wish to determine h.y/ so that Fy D

x2 C y2 D N.x; y/. Since F .x; y/ D x2y C h.y/, this is equivalent to having

x2 C h0.y/

D

x2 C y2, which yields h0.y/

D

y2 and hence h.y/

D

1 3

y

3

C

k.

Therefore

F .x;

y/

D

x2y

C

1 3

y3

and

the

solution

to

the

given

differential

equation

is given by

x2y C 1y3 D c: 3

Notice

that

in

the

equation

h.y/

D

1 3

y3

C

k,

we

took

k

D

0.

Otherwise,

we

would

have

F .x;

y/

D

x2y

C

1 3

y3

C

k

D

c:

and

c

k would still be an arbitrary constant

that

we

could

call

some

thing

like

l,

and

then

we

would

have

x2y

C

1 3

y3

D

l,

which

only changes the name c to l .

Method 2. Let Z
F .x; y/ D .x2 C y2/dy C h.x/ D x2y C 1 y3 C h.x/: 3

It is clear that Fy D x2 C y2 D N.x; y/. We wish to determine h.x/ so that Fx D

2xy

D

M.x; y/.

Since

F .x; y/

D

x2y

C

1 3

y3

C

h.x/,

this

is

the

same

as

having

2xy C h0.x/ D 2xy, which gives us h.x/ D k. As explained in Method 1, it is

convenient

to

take

k

and

hence

h.x/

to

be

0.

Therefore,

F .x;

y/

D

x2y

C

1 3

y3

and

the general solution is

x2y C 1y3 D c: 3

Method 3. We now use the method where F .x; y/ is given by

Zx

Zy

F .x; y/ D M.s; y0/ds C N.x; s/ds:

x0

y0

We notice that if we take y0 D 0, then M.x; y0/ D 0 for all x. Hence F .x; y/ would

involve only one integral. Then since the first integral would be 0 anyway, we need

not worry about x0. So, let y0 D 0. Then

F .x; y/

D

Z

y
N.x; s/ds

D

Z

y
.x2

C s2/ds

D

x2y

C

1 y3

0

0

3

and the solutions of the differential equation are again given implicitly by

x2y C 1y3 D c: 3

Method

4.

Here

we

take

F .x;

y/

D

Rx
x0

M.s;

y/ds

C

Ry
y0

N .x0 ;

s/ds.

Letting

x0

D

3.2 Exact equations 53

0; y0 D 0, we have

Z F .x; y/ D

x
2syds

Z C

y
s2ds

D x2y C

1 y3:

0

0

3

Thus

the

general

solution

is,

as

before,

by

x2y

C

1 3

y3

D

c.

Note that, for all x, the function

.y/

D

x2y

C

1 3

y3

is

monotone

and

its

range

is

R.

As

a

consequence,

the

equation

x2y

C

1 3

y3

D

c

has

a

positive

solution

yc .x /

if

c > 0 and a negative solution if c < 0. Such yc solve

for all c D6 0.

dy D 2xy=.x2 C y2/ dx

Example 3.2.10.

Find

the

solution

of

.x2y

C

1/dx

C

.

1 2

y

C

1 3

x3/dy

D

0

passing

through .; 0/.

Since

Â

Ã

@ x2y C 1 D x2 D @

1 y

C

1 x3

@y

@x 2 3

the equation is exact.

Let us use Method 3, with x0 D y0 D 0. Then M.x; 0/ D 1 and

F .x; y/

D

Z

x
ds

Z C

y Â1 s

C

Ã 1x3 ds

D

x

C

1 y2

C

1x3y

0

02 3

43

and the general solution is given implicitly by

x C 1y2 C 1x3y D c: 43

Substituting x D  and y D 0, we obtain c D . Therefore the solution to the initial

value problem is

x C 1 y2 C 1x3y D : 43

Alternate Solution. It may be convenient to take x0 and y0 as described by the initial

values. So, letting x0 D  and y0 D 0, we have

F .x; y/

Z D

x

Z

ds C

y

Â

1 s

C

Ã 1x3 ds

Dx

 C 1y2 C 1x3y D c:



02 3

43

Substituting x D  and y D 0, we get c D 0; so

as before.

x  C 1y2 C 1x3y D 0 43

54 3 First order nonlinear differential equations

Example 3.2.11. Solve

y2

C

1 dx

C

2y

ln xdy

D

0;

.x > 0/:

x

We note that in order to use Method 3 or 4, here we cannot take the fixed point .0; 0/. So, let us take the point .1; 1/. Then since ln 1 D 0, using Method 3, we easily obtain

F .x; y/

D

Z

x

y2

C1 ds

D

.y2

C 1/ ln x;

.x > 0/:

1

s

Thus the general solution is .y2 C 1/ ln x D c.

3.3 The integrating factor

In this section we learn how to deal with equation

M.x; y/dx C N.x; y/dy D 0

(3.14)

when it is not exact. It is possible that an equation of this type may not be exact but

it becomes exact after it is multiplied by some suitable function. For example, the

equation ydx xdy D 0; x > 0; y > 0, is not exact. But after multiplying it by the

function

1 y2

,

the

resulting

equation

1 y

d

x

x y2

dy

D

0

becomes

exact.

A nonzero function .x; y/ is called an integrating factor of (3.14) if it has the

property that when (3.14) is multiplied by this function, it becomes an exact equation.

Integrating factors exist, in general, but determining them may be quite difficult.

Nevertheless, in some special cases finding an integrating factor can be fairly simple

and it may be worth a try. We also point out that, as the following example shows,

an integrating factor need not be unique.

Example 3.3.1. The reader should verify that for x; y > 0, all of the three functions

111

; xy

x2 ;

y2 ;

are integrating factors of y dx x dy D 0:

One of the cases where finding an integrating factor can be quite simple is when the equation
M.x; y/ dx C N.x; y/ dy D 0

has an integrating factor that is either a function of x only or a function of y only. Let us assume that it has an integrating factor, which is a function of x only. Multiplying the equation by .x/, we obtain

.x/M.x; y/ dx C .x/N.x; y/ dy D 0:

3.3 The integrating factor 55

In order for this equation to be exact, we must have (notice that @ .x/= @y D 0)
.x/My .x; y/ D 0.x/N.x; y/ C .x/Nx.x; y/:
If N.x; y/ 6D 0, then we have

0.x/ D My .x; y/ Nx.x; y/ .x/: N.x; y/

(3.15)

Let  D My.x; y/ Nx.x; y/ : N.x; y/
If  is a function of x only, then integrating 0.x/ D .x/
R
D e .x/dx :

.x/, we obtain

If  is not a function of x only, then we may try to find an integrating factor .y/ which is a function of y only.
Multiplying the differential equation by .y/ and following the same procedure, we obtain the equation

0.y/ D Nx.x; y/ My.x; y/ .y/: M.x; y/
Let  D Nx.x; y/ My .x; y/ : M.x; y/
If  is a function of y only, then integrating 0.y/ D .y/ , we obtain
R
D e .y/dy :

Example 3.3.2. Find an integrating factor for the equation

x sin y dx C .x C 1/ cos y dy D 0:

Let us first check to see if we can find an integrating factor .x/. We can use (3.15) to determine if such an integrating factor exists, but we recommend that students do not memorize this formula and instead go through the process each time. Thus, multiplying by .x/, we have

.x/x sin y dx C .x/.x C 1/ cos y dy D 0; .x/x cos y D OE 0.x/.x C 1/ C .x/ cos y:

Dividing by cos y (assuming cos y ¤ 0), we have x .x/ D .x C 1/ 0.x/ C .x/

56 3 First order nonlinear differential equations

and hence 0.x/ D x 1 xC1

Â

Ã

.x/ D 1

2

.x/;

xC1

.x 6D 1/:

Integrating,

Â

Ã

0.x/ D 1

2 xC1

.x/;

.x D6 1/

we obtain

ex .x/ D .x C 1/2 ;

.x 6D 1/:

Multiplying the given equation x sin y dx C .x C 1/ cos y dy D 0 by this

have

exx .x C 1/2

sin

y

dx

C

ex .x C

1/

cos

y

dy

D

0;

.x D6 1/

.x/ we

which is now exact. Thus, we may use (3.13) either on the half space ¹x > 1º or

on ¹x < M.x; y0/

1º. D0

SfoinrcaellMx..xT;hyis/imDpl.ixeeCxs1xt/h2astiRnxx0yM, if.sw; ey0ta/dkes

x0 D

D 0.

y0

D

0,

we

see

that

Consequently,

F .x; y/

D

Zy
0

ex .x C

1/

cos

s

ds

D

ex .x C

1/

sin

y:

Thus the general solution is

ex sin y D c;
1Cx

.x ¤ 1/:

Notice that for c D 0 the solutions are straight lines given by y D k , k D

0; 1; 2; : : : .

We could have found these constant solutions without solving the equation, sim-

ply by observing that

dy D dx

x sin y .x C 1/ cos y :

For example, it is easy to see that y.x/ Á is a solution since y0 D 0 and also

x sin .x C 1/ cos

D 0:

Example 3.3.3. The equation
.y C xy C y2/dx C .x C 2y/dy D 0
is not exact because My D 1 C x C 2y while Nx D 1. Let us try to find an integrating factor .x/. We consider .x/.y C xy C y2/dx C .x/.x C 2y/dy D 0 and equate

3.3 The integrating factor 57
the partial derivatives. Then we have
.x/.1 C x C 2y/ D 0.x/.x C 2y/ C .x/
and hence .x C 2y/ .x/ D .x C 2y/ 0.x/. Therefore 0.x/ D .x/ and so we can take .x/ D ex. Now ! D ex.y C xy C y2/dx C ex.x C 2y/dy is exact. Here D R2 and we can use Method 3 to find an antiderivative. Since ex.y C xy C y2/ D 0 for y D 0, one has
Zy F .x; y/ D ex.x C 2s/ds D ex.xy C y2/
0
and hence the general solution is ex.xy C y2/ D c.

Example 3.3.4. Consider the equation ydx C .2x C 3y/dy D 0. Since My D 1 D6 Nx D 2 the equation is not exact. Here it is convenient to look for an integrating factor of the type .y/. The equation .y/ydx C .y/.2x C 3y/dy D 0 is exact

provided

d y

.y/ C

.y/ D 2 .y/

H)

d y

.y/ D

.y/

dy

dy

which yields

.y/ D y. An antiderivative of y2dx C y.2x C 3y/dy D 0 is
Zy F .x; y/ D s.2x C 3s/ds D xy2 C y3
0

and hence xy2 C y3 D c is the general solution of our equation. If c D 0 we find y D 0 and y D x. If c > 0, then y2.x C y/ D c > 0 implies y > x, while if c < 0, then y2.x C y/ D c < 0 implies y < x. See Figure 3.6.

y

c<0

c>0

x

c=0

c<0

c>0

Fig. 3.6. Plot of xy2 C y3 D c

58 3 First order nonlinear differential equations
3.4 Homogeneous equations

The equation

x0 D f .t; x/

is

called

homogeneous

if

f .t; x/

can

be

expressed

as

a

function

of

the

variable

x t

,

t D6 0: For example,

x0

D

x3 C t3 tx2 ;

t

¤ 0;

is homogeneous because if we divide the numerator and denominator by t3, we obtain

x0 D

x Á3 C1
t
x2
t

and

the

right

side

is

a

function

of

the

variable

x t

.

On the other hand,

x0 D x2 sin t

is

not

homogeneous

because

it

is

impossible

to

express

it

as

a

function

of

x t

.

So, a homogeneous equation has the form

x0 D g

xÁ :

t

(3.16)

Equation (3.16) can be transformed into a separable equation by making the substi-
tution x.t/ D tz.t/. This follows since we would have x0 D z C tz0 D g.z/ and the equation z C tz0 D g.z/ can be written as

z0

D

1 .g.z/

z/

t

which is separable.

Example 3.4.1. Consider the equation

x0

D

t2

C

x2 ;

tx

tx 6D 0:

If we divide the numerator and denominator by t2 and then let x D tz, we obtain

tz0

Cz

D

1

C

z2 ;

z

tz0 D 1 C z2 z D 1 C z2 z2 D 1

z

z

z

and hence

zz0 D 1 t

or equivalently Integrating, we get

3.4 Homogeneous equations 59 zdz D dt :
t

1 2

z2

D

ln

jt j

C

c;

z2 D 2.ln jtj C c/:

Now, what remains is to express the answer in terms of the original variables t and x. Since x D zt, z D x=t and
x Á2 D 2 ln jtj C k k D 2c; t
which gives rise, for all c, to a solution of our equation in implicit form. In this case, if we want to, we can find the solutions explicitly.

Let us now consider the more general equation

x0 D M.t; x/ N.t; x/

(3.17)

where M; N are homogeneous functions of the same order k. Let us recall that M D M.t; x/ is a k-homogeneous function if

M. t; x/ D k M.t; x/

(3.18)

for all such that M. t; x/ makes sense. If both M and N are k-homogeneous, then we have

M.t; t N.t; t

x=t/ x=t/

D

tk M.1; x=t/ tkN.1; x=t/

D

M.1; x=t/ :
N.1; x=t/

If we define

g x Á WD M.1; x=t/

t

N.1; x=t/

60 3 First order nonlinear differential equations

we deduce that

x0 D M.t; x/ D g

xÁ ;

N.t; x/

t

which shows that (3.17) is homogeneous.

It will be helpful to remember that if an equation is a quotient of two polynomials,

then it is homogeneous if and only if the sum of the exponents of the variables in

each term, which we call the total exponent, both in the numerator and denominator,

is the same. For example,

x0

D

t3x2 x5 tx4 C t3x2

has two terms in the numerator and two in the denominator, all of total exponent 5. Therefore it is homogeneous. On the other hand,

x0

D

t3x2 x5 tx4 C t2x2

is a quotient of two polynomials, but three of the terms have total exponent equal to 5 and one has total exponent equal to 4; therefore it is not homogeneous.
The proof of this rule easily follows from dividing the numerator and denominator by a certain power of t, as we did in Example 3.4.1.

Example 3.4.2. Solve

x0

D

x2

C tx t2

C

t2

;

t 6D 0:

All the terms in the numerator and the denominator have the same total exponent equal to 2. Therefore, it is homogenous.
Letting x D tz, one finds

z

C tz0

D

t2z2

C t2z t2

C t2

D z2

Cz

C 1;

tz0 D z2 C 1

H)

z0

1

z2 C 1 D t

and integrating, we have

arctan z D ln jtj C c H) z D tan.ln jtj C c/:

In conclusion the solution is

x D tz D t tan.ln jtj C c/;

which is defined for t 6D 0 and ln jtj C c D6 2 C k , k integer.

3.5 Bernoulli equations

3.5 Bernoulli equations 61

A generalization of the linear equation is the Bernoulli equation

x0 C p.t /x D q.t /xkC1

(3.19)

where p; q 2 C.OEa; b/ or p; q 2 C.R/. The equation has the trivial solution x D 0
and we are interested in finding nontrivial solutions. Of course, we will consider only solutions such that xkC1 makes sense.
If k D 0; 1 or if q.t/ Á 0 the equation becomes linear. With the exception of
these three cases, the Bernoulli equation is nonlinear. Let us show that the change of variable z D x k, (x ¤ 0 if k > 0), transforms the Bernoulli equation into a linear
equation. We have z0 D kx k 1x0. Since x0 D p.t/x C q.t/xkC1 , we get
Á z0 D kx k 1 p.t /x C q.t /xkC1 D kp.t /x k kq.t /:

Since z D x k, we have

z0 kp.t/z D kq.t/;

which is a linear equation. If z is a solution of this equation, then x.t/ D z 1=k.t/ is a solution of (3.19).

Example 3.5.1. The equation

x0 x D tx2

is a Bernoulli equation with k D 1, p D 1; q D t. One solution is x Á 0. If x 6D 0, we set z D x 1. Then we have
z0 C z D t

which is linear; and solving it, we have

z.t/ D c e t C 1 t; c 2 R

and finally, if c e t C 1 t D6 0,

1

1

x.t/ D z .t /

D

ce

t C1

; t

c 2 R:

If we want to solve an initial value problem such as

x0 x D tx2; x.0/ D 1;

(3.20)

we substitute the initial value into (3.20) and solve for c. One finds

1

1

1 D c e0 C 1 D c C 1

62 3 First order nonlinear differential equations

whence c

D

0. Thus

the solution is

x .t /

D

1 1

t

,

restricted

to t

<

1. The

more general

case that x.0/ D a > 0 is discussed in Exercise no. 46.

Example p D 2; q

3.5.2. De t

Solve x0 C and k C 1

2x D

D

1 2

,

e

t

p x,

x

.0/

namely k D

D

1.

1 2

.

TSehtitsinisgazBDernpoxu,llxi equ0a,tiwone

with find

z0 C z D 1et: 2

Solving this linear equation, we get

z D c e t C 1et: 4

Notice that z

0 implies c e

t

C

1 4

et

0, that is

c

1 e2t:

4

Substituting

z

D

p x,

namely

x

D

z2,

we

find

Â x.t/ D c e

t C 1 et Ã2 :

4

(3.21)

Inserting an initial condition such as x.0/ D 1, we find 1 D

cC

1 4

2. Solving, we

have c

C

1 4

D

1

and hence

c

D

3 4

or c

D

5 4

.

Since

(3.21),

with t

D

0,

implies

c

1 4

,

we

find

that

c

D

3 4

.

Thus

Â

x.t/ D

3 e

t C 1 et Ã2

4

4

is the solution of our initial value problem.

3.6 Appendix. Singular solutions and Clairaut equations
A solution x D .t/ of a first order differential equation F .t; x; x0/ D 0 is called a singular solution if for each .t0; x0/ with .t0/ D x0, there exists a solution .t/ D6
.t/ of F .t; x; x0/ D 0, passing through .t0; x0/, namely such that .t0/ D x0. In particular, .t/ and .t/ have the same derivative at t D t0 and thus they are tangent at .t0; x0/. Since this holds for every point .t0; x0/ this means that x D .t/ is the envelope of a family of solutions of F .t; x; x0/ D 0.
Recall that the envelope of a family of curves given implicitly by g.t; x; c/ D 0 is a curve of implicit equation Á.t; x/ D 0 that can be found solving the system
² g.t; x; c/ D 0 gc .t; x; c/ D 0:

3.6 Appendix. Singular solutions and Clairaut equations 63

When g.t; x; c/ D x

h.t; c/ the system becomes
² x D h.t; c/
hc .t; c/ D 0:

This is an easy example.

Example 3.6.1. Find the envelope of the family of parabolas x D .t preceding system becomes

²

x D .t c/2

2.t c/ D 0:

c/2. The

The second equation yields c D t and, substituting into the first equation, we find x D 0, which is the envelope of the parabolas.
Let x D .t; c/, c 2 R, be a one parameter family of solutions of F .t; x; x0/ D 0. Differentiating the identity F .t; .t; c/; 0.t; c// Á 0 with respect to c, we find
Fx.t; .t; c/; 0.t; c//@c .t; c/ C Fx0 .t; .t; c/; 0.t; c//@c 0.t; c/ Á 0:
If Fx.t; .t; c/; 0.t; c// 6Á 0 and Fx0 .t; .t; c/; 0.t; c// Á 0, we infer that @c .t; c/ Á 0. Therefore, the singular solution solves the differential system
´ F .t; x; x0/ D 0 Fx0 .t; x; x0/ D 0
and is such that Fx.t; x; x0/ Á6 0.
Example 3.6.2. Find the singular solutions of x2.1 C x02/ D 1. Here F .t; x; x0/ D x2.1 C x02/ 1. Then Fx0 D 2x2x0 and the preceding system becomes
´ x2.1 C x02/ D 1 2x2x0 D 0

whose solutions are x D 1. Since for x D 1 one has Fx D x D 1, thus the

singular solutions are x D 1.

p

Now, by substitution, we find that .t; c/ D  1 .t c/2 is a one parameter

family of solutions of x2.1 C x02/ D 1. They are a family of circles g.t; x; c/ D

.t c/2 C x2 D 1 centered at .c; 0/ with radius 1. Let us check that x D 1 are the

envelope of .t; c/. We have to solve the system

´ x D .t; c/

c .t; c/ D 0:

64 3 First order nonlinear differential equations
x

O

t

Fig. 3.7. Solutions of x2.1 C x02/ D 1

p In this case we have .t; c/ D  1 .t c/2 and hence

tc

c.t; c/ D  p 1

.t

: c/2

p So c .t; c/ D 0 for c D t. Substituting into x D .t; c/  1 .t c/2 we find x D 1, which are exactly the singular solutions found before. See Figure 3.7.

3.6.1 Clairaut equations

A typical equation where singular solutions can arise is the Clairaut equation which is a differential equation of the form

x D tx0 C g.x0/

(3.22)

where, say, g 2 C.R/. Let us note that (3.22) is not in normal form. If we let x0 D c, for any c 2 R, we find the family of straight lines

x.t/ D ct C g.c/; c 2 R

which clearly solve (3.22).

Remark 3.6.3. If g is defined in a subset of R, the solutions x D ct C g.c/ make sense only for c in the domain of g. See, e.g. Exercises nos. 40 and 41 below.

A specific feature of the Clairaut equation is that it might have singular solutions. According to the preceding discussion, we set F .t; x; x0/ D tx0 C g.x0/ x and

3.6 Appendix. Singular solutions and Clairaut equations 65

solve the system ´ F .t; x; x0/ D 0 Fx0 .t; x; x0/ D 0

´

tx0 C g.x0/ x D 0

H)

t C g0.x0/ D 0:

Notice that Fx D 1 and hence the condition Fx ¤ 0 is always satisfied. Let us suppose that g 2 C 1.R/, and that g0 is invertible. Recall that a function , defined

on a set R with range in a set S , is invertible if there exists a function defined on S

with range in R such that .r / D s if and only if r D .s/. The function , denoted by 1, is unique and satisfies 1. .r // D r for all r 2 R.
Setting h D .g0/ 1, the second equation of the preceding system, that is g0.x0/ D

t, yields

x0 D h. t/:

Substituting in the first equation we find

x.t/ D th. t/ C g.h. t//:

Therefore, this is the singular solution we were looking for.

Example 3.6.4. The equation

x D tx0 C x02

(3.23)

is a Clairaut equation with g.x0/ D x02. The function g0.x0/ D 2x0 is obviously

invertible. Solving 2x0 D

t we find x0 D

1 2

t.

Hence

the

singular

solution

is

ÂÃ ÂÃ

.t/ D t

t Cg t D

t 2 C Â t Ã2 D

1t2

2

2

2

2

4

and turns out to be the envelope of the family of straight lines

x.t/ D ct C c2; c 2 R:

Consider now the Cauchy problem

x D tx0 C x02; x.a/ D b:

(3.24)

A straight line x D ct C c2 solves (3.24) provided

b D ca C c2:

The second order algebraic equation in c, c2 C ac b D 0, can be solved yielding p
a  a2 C 4b cD
2

and hence there is a solution whenever

a2 C 4b 0; H) b

1 4

a2

:

66 3 First order nonlinear differential equations
x

x=ct+c2 (c<0)

x=ct+c2 (c>0)

O

t

Fig. 3.8. Solutions of x D tx0 C x02. The dotted curve is the singular solution x D

1 4

t

2

This means that, unlike equations in normal form, (3.24) has a solution if and only if the initial values belong to the set

¹.t; x/ 2 R2 W x

1 4

t

2

º;

above the singular solution .t/ D

1 4

t

2.

See

Figure

3.8.

Precisely,

one

has:

(i)

For and

all .a; hence

b/ such that b there are two

>

1 4

a2,

the

straight lines

equation b D of the family

ca x

C D

c2 ct

has two solutions C c2 that satisfy

(3.24).

(ii) If b D

1 4

a2,

the

equation

b

D

ca

C

c2

becomes

c2

C

ac

D

1 4

a2

and

has

only one solution given by c D

1 2

a.

Then

there

is

only

one

solution

among

the

family .t; c/ that satisfies (3.24): that is x D

1 2

at

C

1 4

a2.

This

straight

line

is tangent to x D

.t/ at .a; b/ D .a;

1 4

a2/,

due

to

the

fact

that

the

singular

solution is the envelope of the solution family x D ct C c2.

(iii) For all .a; b/ such that b <

1 4

a2,

the

equation

b

D

ca

Cc2

has

no

solution

and

hence there is no straight line of the family x D ct C c2 that satisfies (3.24).

Remark 3.6.5. If g0 is not invertible, there could be no singular solution. For example, the solutions of x D tx0 C x0 are the family of straight lines x D ct C c
passing through . 1; 0/ and the solution of the system F D 0; Fx0 D 0, that is x D tx0 C x0; 0 D t C 1, reduces to the point . 1; 0/.

Remark 3.6.6. A solution of the family x D ct Cg.c/ solves the initial value problem x D tx0 C g.x0/; x.a/ D b;

whenever b D ac C g.c/. If we assume that g is twice differentiable and g00.p/ 6D 0 (notice that this implies that g0 is invertible so that the previous discussion applies),

3.7 Exercises 67
x

t O

Fig. 3.9. The equation g.c/ D b ac with a > 0
then g is either concave or convex and the equation g.c/ D b ac, in the unknown c, has two, one or no solution, see Figure 3.9, showing that what we saw in the Example 3.6.4 is a general fact.
Remark 3.6.7. The Clairaut equation is a particular case of the D'Alambert­Lagrange equation x D tf .x0/ C g.x0/, f; g 2 C.I /. See two examples in Exercises nos. 42 and 43 below.

3.7 Exercises

1. Solve x0 D x2 C 1.

2. Solve the ivp x0 D x2 1, x.0/ D 0.

3. Solve the ivp x0 D x2 C x, x.1/ D 1.

4.

Solve the ivp x0

D

x2 Cx 2xC1

,

x .0/

D

1.

5. Let

.t/ be the solution of the ivp x0

D

x2 2x

x 1

,

x .0/

D

2.

Find

limt !

1

.t /

and limt!C1 .t /.

6. Solve x0 D 4t 3x4.

7. Solve x0 D tx2.

8. Solve x0 D et .1 C x2/, x.0/ D 0.

9.

Solve x0

D

t x

p and find the solution such that x. 2/ D 1.

10. Solve x0 D

t 4x3

and find the solution such that x.1/

D

1.

68 3 First order nonlinear differential equations

11. Solve x0 D t2x2 such that x.1/ D 2.

12.

Solve x0

D

5t

p x,

x

0, x.0/ D 1.

13.

Solve x0

D

4t

3

p x,

x

0, x.0/ D 1.

14.

Solve and discuss uniqueness for the ivp x0

p D 2t x;

x.a/ D 0, x

0.

15. Find p such that the solutions of x0 D .p C 1/tpx2 tend to 0 as t ! C1.

16. Find the limit, as t ! C1, of the solutions of x0 D .p C 1/tpx2 when p C 1 Ä 0. p
17. Solve x0 D 1 x2 and find the singular solutions. Explain why uniqueness does not hold.

18. Solve .2x2 C 1/dx D .y5 1/dy.

19. Solve .x C 3y/dx C .3x C y/dy D 0 and sketch a graph of the solutions.

20. Solve .x C y/dx C .x y/dy D 0.

21. Solve .axp C by/dx C .bx C dyq /dy D 0, p; q > 0.

22. Solve .3x2 y/dx C .4y3 x/dy D 0 and find the solution passing through .1; 1/.

23. Solve .y x1=3/dx C .x C y/dy D 0 and find the solution passing through .0; 1/.

24. Solve .ex

1 2

y 2 /d x

C

.ey

xy/dy D 0 and find the solution passing through

.0; 0/.

25. Solve .x C sin y/dx C x cos ydy D 0 and find the solution passing through .2; /.

26. Solve .x2 C 2xy y2/dx C .x y/2dy D 0 and find the solution passing through .1; 1/.

27. Solve .x2 C 2xy C 2y2/dx C .x2 C 4xy C 5y2/dy D 0. Show that there exists a such that y D ax is a solution passing through .0; 0/.

28. Solve xdx 2y3dy D 0 and describe the behavior of the solutions.

29. Find the number a such that .x2 C y2/dx C .axy C y4/dy D 0 is exact and then solve it.

30. Find the coefficients ai ; bi such that .x2 C a1xy C a2y2/dx C .x2 C b1xy C b2y2/dy D 0 is exact, and solve it.

31. Find a function A.y/ such that .2x C A.y//dx C 2xydy D 0 is exact and solve it.

32. Find a function B.x/ such that .x C y2/dx C B.x/ydy D 0 is exact and solve it.

3.7 Exercises 69
33. Show that for any differentiable f .y/ ¤ 0 and any continuous g.y/, there exists an integrating factor D .y/ for the equation f .y/dx C .xy C g.y//dy D 0.
34. Show that D x is an integrating factor for .x C y2/dx C xydy D 0 and solve it.
35. Find an integrating factor .x/ by multiplying the equation
.2y C x/dx C .x2 1/dy D 0

by .x/ and determine it so that it satisfies the condition for exactness, and then solve it.

36. Solve .x C 2y/dx C .x 1/dy D 0.

37. Solve y2dx C .xy C 3y3/dy D 0.

38. Solve .1 C y2/dx C xydy D 0.

39. Solve x0 D .x C 2t/=t, t 6D 0.

40. Solve x0 D tx=.t2 C x2/.

41.

Solve x0

D

3x2 t

2t x

2

.

42.

Solve x0

D

x2 Ct 2tx

2

.

43.

Solve x0 D

x x

t t

C1 C2

.

44.

Solve x0

D

x

x t

t C1

.

45. Solve x0 D

xCt C1 x t C1

.

46. Solve the Cauchy problem x0

tions relative to a.

x D tx2, x.0/ D a > 0 and describe the solu-

47. Find the nontrivial solutions of x0 C 2tx D 4tx3. 48. Find the nontrivial solutions of x0 tx D x2.

49. Show that the circle x2 C t2 D 1 is the singular solution of x02 D x2 C t2 1. 50. Solve x02 D 4.1 x/ and show that x D 1 is the singular solution. 51. Find a singular solution of x02 tx0 C x D 0.

52. Solve the Clairaut equation x D tx0 x02 and find the singular solution. 53. Solve the Clairaut equation x D tx0 C ex0 and find the singular solution.

54. Solve the Clairaut equation x D tx0 ln x0 and find the singular solution.

55.

Solve the Clairaut equation x

D tx0

C

1 x0

and

find the singular solution.

56. Find ;  such that x.t/ D t C  solves the D'Alambert-Lagrange equation x D th.x0/ C g.x0/, h; g 2 C.I /.

(a) Show that the equation x D t.1 C x0/ C x0 has no solution of the form x D
t C . (b) Solve the equation by setting x0 D z.

4
Existence and uniqueness for systems and higher order equations

In this chapter we extend (without proof) to systems and higher order equations, the existence and uniqueness theorems stated in Chapter 2.

4.1 Systems of differential equations

If f1; : : : ; fn are functions of the n C 1 variables .t; x1; : : : ; xn/, we consider the

system of differential equations in normal form

8 <

x10

D f1.t; x1; : : : ; xn/

:

::: xn0

D ::: D fn.t; x1; : : : ; xn/:

(4.1)

To write this system in a compact form, we introduce

01 x1
x D B@BBx:::2CACC 2 Rn;

0

1

f1.t; x/

fN.t; x/ D @BBBf2.t:::; x/CACC 2 Rn:

xn

fn.t; x/

If .t; x/ 2 Â RnC1, then fN is a function from

preceding system becomes

x0 D fN.t; x/

to Rn. With this notation, the

which is formally like the first order equation x0 D f .t; x/. For example, if n D 2, a 2 2 system is ² x10 D f1.t; x1; x2/ x20 D f2.t; x1; x2/:
If fi , i D 1; 2; : : : ; n, do not depend on t, the system is autonomous. If fi , i D 1; 2; : : : ; n, are linear with respect to x1; : : : ; xn, the system is linear.

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_4

72 4 Existence and uniqueness for systems and higher order equations

If n D 2 and f1; f2 are linear and depend only on x1; x2, ² x10 D a11x1 C a12x2 x20 D a21x1 C a22x2

is a 2 2 linear, autonomous system. To write this system in the vectorial form, it

suffices to introduce the matrix

Â

Ã

AD

a11 a12 a21 a22

:

With this notation the linear 2 2 system becomes

x0 D Ax;

ÂÃ

xD

x1 x2

2 R2:

In general, a linear autonomous system has the form

x0 D Ax;

01 x1
x D B@ ::: AC 2 Rn xn

where A is an n n maÂtrixÃ.
x
Example 4.1.1. If x D y 2 R3 and

z

0

1

123

AD@ 4 5 6 A

789

the system x0 D Ax becomes

8 < x0 D x C 2y C 3z

:

y0 z0

D D

4x C 5y C 6z 7x C 8y C 9z:

Let  D .1; : : : ; n/ 2 Rn. Given .t0; / 2 , an initial value, or a Cauchy, problem for the system x0 D fN.t; x/ is

² x0

D fN.t; x/

x.t0/ D 

(4.2)

or, in terms of the components

² xi0

D fi .t; x1; : : : ; xn/

xi .t0/ D i

i D 1; : : : ; n:

In general, one prescribes n initial values for an n n first order system.

4.1 Systems of differential equations 73

For example, an initial value problem for a 2 2 system is

8 <

x10

:

x20 x1.t0/

D f1.t; x1; x2/ D f2.t; x1; x2/ D 1; x2.t0/ D 2:

4.1.1 Existence and uniqueness results for systems

Below we state the existence and uniqueness theorems for systems in normal form.

Theorem 4.1.2. (Local existence) Let Â RnC1, let fN W 7! Rn be continuous

and let .t0; / D .t0; 1; : : : ; n/ be a given point in the interior of . Then the initial

value problem

² x0

D fN.t; x/

x.t0/ D 

(4.2)

has at least one solution defined in a suitable interval jt t0j < i.

The function fN is locally lipschitzian at .t0; / 2 with respect to x if there

exists a neighborhood U

of .t0; / and a number L > 0 such that, denoting by

j j the euclidean norm in Rn, one has

jfN.t; x/ fN.t; z/j Ä Ljx zj;

for every .t; x/; .t; z/ 2 U . If the preceding inequalities hold for all .t; x/; .t; z/ 2 , then fN is said to be globally lipschitzian in , with respect to x.
Theorem 4.1.3 (Uniqueness). If fN is continuous and locally lipschitzian with respect to x, then (4.2) has a unique solution, defined in a suitable neighborhood of t0.
Theorem 4.1.4 (Global existence). If D OEa; b Rn and fN is continuous and globally lipschitzian in with respect to x, then the solution of (4.2) is defined on all OEa; b.

Proof. (Sketch) As in the proof of the existence and uniqueness theorem for a single equation, see the Appendix 2.5 in Chapter 2, one checks that (4.2) is equivalent to the system of integral equations
Zt xi .t/ D xi .0/ C fi .t; x1.t/; : : : ; xn.t//dt; i D 1; 2; : : : ; n
0
which can be written in compact form as Zt
x.t/ D x0 C fN.t; x.t//dt
0
and is formally like the integral equation (2.14). Repeating the arguments carried in the aforementioned Appendix, one proves the local and global existence and uniqueness for (4.2).

74 4 Existence and uniqueness for systems and higher order equations
4.2 Higher order equations

If n D 2 and f1.t; x1; x2/ D x2, the system x0 D fN.t; x/ becomes ² x10 D x2 x20 D f2.t; x1; x2/:
Then x100 D x20 D f2.t; x1; x2/ D f2.t; x1; x10 / or, setting x1 D x and f2 D f ,
x00 D f .t; x; x0/

which is a second order differential equation in normal form.

In general, consider the n n system

8

^^^^^<

x10 x20

^^^^^:

:::
xn0 xn0

1

D x2 D x3 D ::: D xn D fn.t; x1; : : : ; xn/:

We find x100 D x20 , x1000 D .x20 /0 D x30 , etc. x1.n/ D xn0 . Hence, calling x D x1 and

fn D f , we find the n-th order equation in normal form

!

x.n/ D f .t; x; x0; : : : ; x.n 1//;

x.k/

D

dkx dtk

:

(4.3)

To understand what the natural initial value problem is for an n-th order equation, we

simply go back to its equivalent system. We know that, given .t0; 1; : : : ; n/ 2

an initial value problem for an n n system consists of requiring that xi .t0/ D i , for i D 1; 2 : : : ; n. Since x1 D x, x0 D x2; : : : ; x.n 1/ D xn, an initial value problem
for the n-th order equation in normal form x.n/ D f .t; x; x0; : : : ; x.n 1// is

´ x.n/ D f .t; x; x0; : : : ; x.n 1// x.t0/ D 1; x0.t0/ D 2; : : : ; xn 1.t0/ D n :

(4.4)

So, we prescribe at a certain t D t0 the value x.t0/, together with its derivatives up to order n 1, that is x0.t0/; : : : ; x.n 1/.t0/. For example, in an initial value problem for

a second order equation, we prescribe at t D t0 the unknown x.t/ and its derivative

x0.t/, that is

8 < x00

D f .t; x; x0/

:

x .t0 / x 0.t0 /

D 1 D 2:

Similar to the case for first order equations, one could consider n-th order equations in the form F .t; x; x0; : : : ; x.n// D 0, which is not the normal form; but for the sake
of simplicity we choose to work with the normal form. Some second order equations such as F .t; x; x0; x00/ D 0 will be briefly discussed at the end of Chapter 5.

4.2 Higher order equations 75
4.2.1 Existence and uniqueness for n-th order equations

From the local existence result for systems stated before, we can deduce immediately the following theorems for n-th order equations in normal form.

Theorem 4.2.1 (Local existence). Let f W 7! R be continuous and let

.t0; 1; : : : ; n/ be a given point in the interior of . Then the initial value prob-

lem

´

x.n/ D f .t; x; x0; : : : ; x.n 1//

x.t0/ D 1; x0.t0/ D 2; : : : ; x.n 1/.t0/ D n

(4.4)

has at least one solution defined in a suitable interval jt t0j < i.

Proof. It suffices to remark that if f is continuous, then

0

1

x2

fN.t; x/ D BB@BBB

x3 :::
xn

CCACCC

f .t; x1; :::; xn/

is also continuous.

Theorem 4.2.2 (Uniqueness). If f W 7! R is continuous and locally lipschitzian with respect to .x1; : : : ; xn/, then (4.4) has a unique solution, defined in a suitable neighborhood of t0.
Proof. It is evident that if f is locally lipschitzian with respect to .x1; : : : ; xn/, then fN.t; x/ is also locally lipschitzian with respect to x.

For example, the previous Theorems imply that the ivp

8

^<x00

D f .t; x/

:^xx

.t0/ 0.t0 /

D 1 D 2

has a unique solution, defined in a suitable neighborhood of t0, provided that f is locally lipschitzian with respect to x.
For the same reason, the global existence result for systems implies
Theorem 4.2.3 (Global existence). If D OEa; b Rn and f W ! 7 R is continuous and globally lipschitzian in with respect to .x1; : : : ; xn/ then the solution of (4.4) is defined on all OEa; b.

As for first order equations, the uniqueness result can be used to find some properties of the solutions. We illustrate this with two examples.

76 4 Existence and uniqueness for systems and higher order equations
Example 4.2.4. Let f .x/ be locally lipschitzian. Show that the solution of x00 D f .x/, x.0/ D 0, x0.0/ D 0, is even. Setting z.t/ D x. t/ we have z00.t/ D x00. t/ D f .x. t// D f .z/. Moreover, z.0/ D x.0/ D 0 and z0.0/ D x0.0/ D 0. Then, by uniqueness, x.t/ D z.t/, that is x.t/ D x. t/.
Example 4.2.5. Let f .x/ be locally lipschitzian and let x.t/ be a solution of x00 D f .x/, defined for all t 2 R, satisfying x.0/ D x.T /, x0.0/ D x0.T /. Then x.t/ is periodic with period T . Setting z.t/ D x.t C T / one has z00.t/ D x00.t C T / D f .x.t C T // D f .z.t// for all t 2 R. Moreover, z.0/ D x.T / D x.0/ and z0.0/ D x0.T / D x0.0/. Then, by uniqueness, x.t/ D z.t/, that is x.t/ D x.t C T /, for all t 2 R, which means that x.t/ is T -periodic.

4.3 Exercises

1. Show that the Cauchy problem x00 D xjxj, x.0/ D a; x0.0/ D b, has a unique solution, for all a; b 2 R.
2. Show that the Cauchy problem x00 D max¹0; xjxjº, x.0/ D a; x0.0/ D b, has a unique solution, for all a; b 2 R.
3. Show that for p 2 the Cauchy problem x00 D jxjp, x.0/ D a; x0.0/ D b, has a unique solution, for all a; b 2 R.

4. Let x; y be the unique solution of

8 <

x0

Dy

:

y0 x .0/

Dx D 0; y.0/ D 1:

Show that x; y verify x2 C y2 Á 1.

5. Do the same as in Problem 4 when x; y solve

8 < x0 D Ây

:

y0 x .0/

D Âx D 0; y.0/ D 1:

6. Prove that the solutions x; y of
² x0 y0

D Hy .x; y/ D Hx.x; y/;

where H W R R ! 7 R is smooth, satisfy H.x.t/; y.t// D c. 7. Find the second order equation a solution of which is x.t/ D et C e t . 8. Same for x D tet . 9. Let x be the solution of x00 C x D 0, x.0/ D 0; x0.0/ D 1. Prove that x D sin t.

4.3 Exercises 77
10. Let x be the solution of x00 C 4x D 0, x.0/ D 1; x0.0/ D 0. Prove that x D cos 2t.
11. Let f .t; x/ be T -periodic with respect to t and let x.t/ be a solution of x00 D f .t; x/, defined for all t 2 R, such that x.0/ D x.T / and x0.0/ D x0.T /. Show that x.t/ is T -periodic.
12. Let f W R 7! R be smooth and let x W R ! 7 R satisfy x0000 D f .x/, x0.0/ D 0; x000.0/ D 0. Show that x.t/ is even.
13. Show that if f is continuous and f .x/ > 0 for all x 2 R, then the solutions of x000 D f .x/, x00.0/ D 0, have an inflection point at t D 0.

5 Second order equations

This chapter is devoted to second order equations and is organized as follows. First we deal with general linear homogeneous equations, including linear independence of solutions and the reduction of order. Then we discuss general linear nonhomogeneous equations. Sections 5.5 and 5.6 deal with the constant coefficients case. Section 5.7 is devoted to the study of oscillation theory and the oscillatory behavior of solutions. Finally, in the last section we deal with some nonlinear equations.

5.1 Linear homogeneous equations

The equation

a0.t /x00 C a1.t /x0 C a2.t /x D g.t /

represents the most general second order linear differential equation. When g.t/ Á 0 it is called homogeneous; otherwise it is called nonhomogeneous.
For simplicity and convenience, we will assume that a0.t/ ¤ 0, so that we can divide the equation by a0.t/ and write the equation in the form

x00 C p.t/x0 C q.t/x D f .t/:

(5.1)

The values of t where a0.t/ vanishes are called singular points. Notice that we have used the term "singular point" also in the case of exact equations Mdx C Ndy D 0, with a somewhat different meaning. Second order equations with singular points will be discussed in Chapter 10 in connection with Bessel equations.
Before starting the theoretical study of linear second order equations, we discuss an example which highlights the importance of these equations.

Example 5.1.1 (The harmonic oscillator). Consider a body P on the x axis at the free end of an elastic spring which is attached at the origin O.

Assuming that P has unitary mass and that there is neither friction nor external force acting on the body, Hooke's law states that the force F acting on the body is

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_5

80 5 Second order equations

P

O

x

F = -2x

Fig. 5.1. The elastic spring

proportional, with a negative proportionality constant !2 < 0, to the distance x of the body to O, that is F D !2x. Notice that the minus sign is due to the fact that the force is a restoring one, namely it brings back the body to the initial position, acting oppositely to the motion of P . See Figure 5.1.
Denoting by x.t/ such a distance, dependent on time t, and by x00.t/ its acceleration, Newton's second law, Force=Mass Acceleration, yields x00 D !2x, or
x00 C !2x D 0; .! D6 0/:
This equation is of the type (5.1) with p D 0, q D !2, f D 0 and is usually referred to as the equation of the free harmonic oscillator. We will see that the solution is a superposition of sine and cosine functions and hence the body P at the free end of the spring oscillates and its motion is periodic, as expected.
We anticipate that a similar equation arises when we study the mathematical pendulum (see Example 5.5.4).
If there is an external force f .t/ acting on the body, the equation becomes
x00 C !2x D f .t /

which is a second order nonhomogeneous equation. In particular, we will study the case in which f .t/ D sin !1t which yields
x00 C !2x D sin !1t:

The solutions of this equation depend on the relationship between ! and !1 and give

rise to interesting phenomena, like resonance or beats. See Section 5.6.1. In the presence of friction proportional to the velocity x0 of P , the equation be-

comes

x00.t/ C kx0.t/ C !2x.t/ D f .t/

which is of the type (5.1) with p D k and q D !2. It is usually referred to as the equation of the damped harmonic oscillator, the damping term being kx0. Among
other applications, equations of this type arise in the theory RLC electrical circuits
(see Example 5.5.5).

Now we concentrate on the homogeneous case and state the existence and uniqueness result for such equations. The following theorem follows directly from Theorems 4.2.2 and 4.2.3 of Chapter 4.

Theorem 5.1.2 (Existence and Uniqueness). If p.t/, q.t/ are continuous on an interval I Â R, then for any number t0 in I and any numbers  and , there exists a

5.1 Linear homogeneous equations 81

unique solution x.t/ of

x00 C p.t/x0 C q.t/x D 0

(5.2)

satisfying the initial conditions x.t0/ D , x0.t0/ D . Furthermore, this solution exists for all t in I .

Recall that a solution of (5.2) is a twice differentiable function x.t/ that satisfies equation (5.2).

We note that if  and  are both 0 in the above theorem, then the solution x.t/ guaranteed by the theorem must be the trivial solution, that is x.t/ Á 0. This follows from the fact that the zero function is also a solution of (5.2) satisfying the same initial conditions as x.t/. Since there can be only one such solution, then we must have x.t/ Á 0. We state this fact as
Corollary 5.1.3. If x.t/ is any solution of (5.2) such that x.t0/ D 0 D x0.t0/, then x.t/ Á 0.

Remark 5.1.4. Unlike the solutions of the first order linear homogeneous equations, here nontrivial solutions may vanish; in fact, they may vanish infinitely many times, as indicated by the examples below. So, it is no longer true that the solutions are either always positive or always negative. However, what is true is that in view of the above Corollary 5.1.3, the maximum and minimum points of the solutions cannot lie on the t-axis; so they are either above or below the line t D 0.
Example 5.1.5. The function x D t2et cannot be a solution of the differential equation (5.2). The reason is that x and its derivative x0 D t2et C 2tet both vanish at t D 0 and being a solution would contradict Corollary 5.1.3.

We would like to point out that occasionally a second order equation, linear or nonlinear, may be written as a first order equation, and then one can try and see if the methods developed for first order equations can be applied to solve it. We illustrate this in the following example.

Example 5.1.6. Consider the differential equation

x00 C x D 0:

(5.3)

This is a special case of the equation on the harmonic oscillator, discussed in Example

5.1.1.

In spite of its appearance, this equation is essentially a first order equation. To see

this,

let

z

D

x0

D

dx dt

.

Then

by

using

the

Chain

Rule,

x00 D

dx0

D

dz

D

dz

dx

Dz

dz :

dt dt dx dt dx

82 5 Second order equations Now we can write equation (5.3) as

dz z

Cx

D

0

dx

which is a first order separable equation and, by using the differential notation, it can be written as
z dz C x dx D 0:

Integrating, we obtain

z2 2

C

x2 2

D

c, which can

be written as z2

C x2

Dpk1,

where

k1 D 2c is a non-negative constant. If k1p> 0, solving for z, we get z D  k1 x2.

Since z

D

x0, we have x0

D

dx dt

D



k1

x2, where tphe variables cpan be sepa-

rated. In order to separate the variable, we assume that k1 < x < k1 so that

k1 x2 > 0. Then, using the differential notation, we have

 dx

p

D dt:

k1 x2

(5.4)

We tC

recall from

k2 ,

or

px k1

Calculus that the plus sign in D sin.t C k2/: If we let k2

the above equation leads to p
D 0 and k1 D c1 we get

sin the

1 px k1
family

D of

solutions

x D c1 sin t:

If in equation will lead to cos

(5.4) we choose the negative sign,

1 px k2

D

t C k3, and if we let k3

the D

same 0 and

spteps k2

carried D c2,

out we

above obtain

another family of solutions

x D c2 cos t:

We will see later in Example 5.2.10 that the all the solutions of (5.3) are given by x D c1 si n t C c2 cos t.

Remark 5.1.7. In the above discussion, in order to separate the variables, we assumed

kp1 x2 ¤ 0, which was necessary so that wepwould be able to divide both sides by

pk1 x2, thus obtaining the solution x D k1 sin t is defined for all real numbers t,

k1 sin t. But now we see including thpose where k1

that x x2 D

D 0,

which can tion x00 C

occur, for example, at t D 2 . Therefore, x x D 0 for all t. This phenomenon is not

D all

k sin t satisfies the equathat uncommon in solving

differential equations, where one makes an assumption in order to carry out a certain

operation but later it turns out that the solution is valid even without the assumed

restriction. So, at the end of solving an equation, it is worthwhile to check to see if

the restrictions assumed to carry on the operations can be lifted.

Theorem 5.1.8. If x1 and x2 are any solutions of (5.2), then for any constants c1 and c2, the linear combination c1x1 C c2x2 is also a solution.

5.2 Linear independence and the Wronskian 83
Proof. Let x D c1x1 Cc2x2. Substituting x0 and x00 in equation (5.2) and regrouping terms, we have
.c1x1 C c2x2/00 C p.t /.c1x1 C c2x2/0 C q.t /.c1x1 C c2x2/ D OEc1x100 C p.t /c1x10 C c1q.t /x1 C OEc2x200 C p.t /c2x20 C c2q.t /x2 D
c1OEx100 C p.t /x10 C q.t /x1 C c2OEx200 C p.t /x20 C q.t /x2 D 0
because x1 and x2 are solutions and hence
x100 C p.t /x10 C q.t /x1 D 0 D x200 C p.t /x20 C q.t /x2;
proving the theorem.
Remark 5.1.9. The property that linear combinations of solutions is a solution is particular to linear homogeneous equations. This is an important property of such equations, often referred to as the Principle of Superposition. In particular, it is not true for nonhomogeneous equations or nonlinear equations. For example, as can be easily verified, x1 D 1 and x2 D et C 1 are both solutions of x00 3x0 C 2x D 2, but their sum x1 C x2 D 1 C .et C 1/ is not a solution.
5.2 Linear independence and the Wronskian
The goal of this section is to find the general solution of (5.2) which is, by definition, a family x D .t; c1; c2/ depending on two real parameters c1; c2 such that:
1. For all c1; c2, the function x D .t; c1; c2/ is a solution of (5.2). 2. If x.t/ is a solution of (5.2), there exist c1; c2 such that x.t/ D .t; c1; c2/.
Remark 5.2.1. Similar to the case for linear first order equations, here also the general solution includes all the solutions of (5.2).
To find the general solution of (5.2) we first introduce the notion of linear independence of functions.
Let f .t/ and g.t/ be two functions defined on an interval I . We say that f and g are linearly independent on I if the only way we can have c1f .t/ C c2g.t/ D 0 for all t is to have c1 and c2 both equal to 0. That is, if c1 and c2 are constants such that c1f .t/ C c2g.t/ D 0 for all t in I , then c1 D 0 D c2. Functions that are not linearly independent are said to be linearly dependent.
Remark 5.2.2. First we note that if there exist constants c1 and c2 such that c1f .t/ C c2g.t/ D 0 for all t in I , and f and g are not identically zero, then if one of the constants is zero, so is the other. Suppose c1 D 0 and c2 ¤ 0. Then we have c2g.t/ D 0 and this implies that g.t/ D 0 for all t. Similarly, the case c2 D 0 leads to c1 D 0.
Using the contrapositive of the statement defining linear independence, we see that f and g are linearly dependent if and only if there exist nonzero constants c1

84 5 Second order equations
and c2 such that c1f .t/ C c2g.t/ D 0 for all t in I . Thus, for any two functions, linear dependence means that one of them is a constant multiple of the other. But such a simplification is not possible for more than two functions. Therefore, we advise students to learn how to use the above definition in order to be prepared to deal with a higher number of functions later.
Example 5.2.3. Let us prove that f .t/ D sin t and g.t/ D cos t are linearly independent. We start by assuming that c1 and c2 are constants such that c1 sin t C c2 cos t D 0 for all t. Next, we show that c1 D c2 D 0. There are several ways to accomplish this. We explain three of them. Sometimes one of the methods is more convenient than the others, depending on the problem.

First method. We substitute some number t that will make one of the terms c1 sin t and c1 cos x become 0. Let, for example, t D 0. Then c1 sin 0 C c2 cos 0 D 0 implies that c2 D 0. Next, we let t D 2 and obtain c1 D 0.
Second method. We notice that if x D c1 sin t C c2 cos t D 0 for all t, then so is x0 D c1 cos t c2 sin t D 0 for all t. So, we simply solve the system of equations
² c1 sin t C c2 cos t D 0 c1 cos t c2 sin t D 0
for c1 and c2, using some method we have learned in Algebra. For example, multiplying the first equation by cos t, the second one by sin t and adding, we obtain c2.sin2 t C cos2 t/ D 0. Since sin2 t C cos2 t D 1, we must have c2 D 0. Now, returning to the equation c1 sin t C c2 cos t D 0, we are left with c1 sin t D 0, which implies that c1 D 0 since sin t cannot be 0 for all t. We note that this method is not applicable if the functions are not differentiable.

Third method. Once we obtained the system
² c1 sin t C c2 cos t D 0 c1 cos t c2 sin t D 0

above, we need not solve for c1 and c2 but simply determine whether the coefficient

determinant is zero or nonzero. Since the coefficient determinant

csoins

t t

cos t sin t



D

sin2 t

cos2 t D 1

is nonzero, we recall from Algebra or Linear Algebra that this system has a unique solution in c1 and c2. Since the pair c1 D 0 and c2 D 0 is a solution, then this is the only solution and there cannot be any nonzero solutions c1 and c2.

Next, we will see that the coefficient determinant mentioned above plays an important role in the study of linear homogeneous equations.

5.2.1 Wronskian

5.2 Linear independence and the Wronskian 85

The Wronskian of two differentiable functions f .t/ and g.t/ is defined as

W .f;

g/.t /

D

ff

.t / 0.t /

gg0..tt// D f .t/g0.t/

f 0.t/g.t/:

Note: Sometimes, instead of W .f; g/.t/, we may interchangeably use the notation W .f .t/; g.t//; and when there is no confusion about what the functions f and g are, we may simply use the notation W .t/; in other words, W .f; g/.t/ D W .f .t/; g.t// D W .t/:

Theorem 5.2.4 (Abel's Theorem). If x1 and x2 are any solutions of

x00 C p.t/x0 C q.t/x D 0

(5.2)

on a given interval I where p.t/ and q.t/ are continuous, then the Wronskian of x1

and x2 is given by

R
W .t / D ce p.t/ dt

where c is a constant. Proof. Taking the derivative of W .t/ D x1x20 x10 x2, we obtain W 0.t/ D x1x200 x2x100. Since x100 D p.t /x10 q.t /x1 and x200 D p.t /x20 q.t /x2 from equation (5.2), by substituting, we obtain W 0.t/ D OE p.t/x20 q.t/x2x1 OE p.t/x10 q.t/x1x2 D
p.t/OEx1x20 x10 x2 D p.t/W .t/. Solving the first order linear equatiRon W 0.t/ D p.t/W .t/ by the method of integrating factor, we obtain W .t/ D ce p.t/ dt .

Note: could

oInbttahienaibt oinveteprmrosoof,finthsetedaedfionfitoebitnatienginraglWW..tt//iDn tecremsRott0fpth.te/datn,twidheerriveatt0ivise,awnye

point in the interior of the interval I . This should be clear, since in solving W 0.t/ D

bypt.hte/Win.tet/g,raotninegcfoaucltdormRutt0ltpip.lty/dbot tihnsstiedaeds

of Rthe equation of p.t/dt:

W

0.t /

C

p.t/W .t/

D

0

Corollary 5.2.5. The Wronskian of two solutions is either always zero or never zero.

ProR of. Since for Rany solutions z1 and z2, by Abel's Theorem, W .z1; z2/.t/ D ce p.t/ dt and e p.t/ dt is never zero, then the only way that the Wronskian can be zero at any point is to have c D 0, in which case the Wronskian is equal to zero for all t.

Example 5.2.6. The functions x1 D et and x2 D sin t cannot be solutions of the differential equation (5.2) on I D . ; /, given that p.t/ and q.t/ are continuous on I . To see this, we examine their Wronskian W .sin t; et / D et sin t et cos t. We
see that W .0/ D 1 and W . 4 / D 0, contradicting Corollary 5.2.5.

86 5 Second order equations
Before establishing our next important theorem concerning Wronskian, let us recall some algebraic facts. Consider the system of equations
´ ax C by D 0 cx C dy D 0:

We can always obtain one solution, called the trivial solution, by letting x D y D 0.

But, does it have any other types of nontrivial solutions? The answer depends on the

determinant of the coefficients; namely the system has a unique solution if and only

if the coefficient determinant is nonzero, that is if and only if

ac

b d



¤

0:

This means that if the coefficient determinant is nonzero, then x D y D 0 is the only solution to the system; so it has no nontrivial solutions. Furthermore, since the condition on the coefficient determinant is both necessary and sufficient, it follows that the system has a nontrivial solution in x and y if and only if the coefficient determinant is zero.
The next theorem gives us a convenient criterion for determining if two solutions are linearly dependent.

Theorem 5.2.7. Two solutions x1 and x2 of (5.2) are linearly dependent if and only if W .x1; x2/.t/ D 0 for all t in I .

Proof. Two solutions x1 and x2 are linearly dependent if and only if there exist nonzero constants c1 and c2 such that c1x1.t/ C c2x2.t/ D 0 for all t in I . We note that if such numbers c1 and c2 exist, then we also have c1x10 .t/ C c2x20 .t/ D 0 for all t in I , since the derivative of the zero function is the zero function. Let t0 be some
number in I and let us look at the system of two algebraic equations
´ c1x1.t0/ C c2x2.t0/ D 0
c1x10 .t0/ C c2x20 .t0/ D 0 :

As pointed out earlier, such a system will have a nontrivial solution in c1 and c2 if

and only if

xx110 ..tt00

/ /

x2.t0 x20 .t0

//

D

0:

But this determinant happens to be the Wronskian of x1 and x2 evaluated at t0. Therefore, we can say that x1 and x2 are linearly dependent if and only W .x1; x2/.t0/ D 0. Finally, since, by Abel's theorem, the Wronskian of two solutions is either identically
zero or never zero, we can say that x1 and x2 are linearly dependent if and only if W .x1; x2/.t/ D 0 for all t in I .

5.2 Linear independence and the Wronskian 87

Example 5.2.8. The above theorem is not valid for arbitrary functions that are not solutions of the linear equation (5.2). Let x1 and x2 be defined as follows:

´

x1.t/ D

t3 if 1 < t Ä 0 t3 if 0 Ä t < 1

and x2.t/ D t3 for 1 < t < 1. The functions x1 and x2 are linearly independent on the interval . 1; 1/ and yet W .x1; x2/.t/ D 0 for all t. The student should verify this.

If x1 and x2 are linearly independent solutions of (5.2) then x1 and x2 are said to form fundamental solutions of (5.2).

Theorem 5.2.9. The general solution of (5.2) is given by c1x1 C c2x2, provided x1 and x2 are fundamental solutions.
Proof. According to Theorem 5.1.8, c1x1 C c2x2 is a solution of (5.2). Next, if y.t/ is any solution of (5.2), we have to show that there exist constants c1 and c2 such that y.t/ D c1x1.t/ C c2x2.t/. Let t0 be any fixed number in I and consider the system
´ c1x1.t0/ C c2x2.t0/ D y.t0/ c1x10 .t0/ C c2x20 .t0/ D y0.t0/

where c1 and c2 are the unknowns. This system has a unique solution c1, c2 if and only if the determinant of the coefficients is different from 0. This determinant is precisely the Wronskian W .x1; x2/.t/ which is not zero because x1; x2 are fundamental solutions.

Example 5.2.10. Show that x D c1 sin t C c2 cos t is the general solution of x00 C x D 0 and find a different fundamental set of solutions that can be used to obtain the general solution.
As we saw in Example 5.1.6, x1 D sin t and x2 D cos t are solutions. Since W .sin t; cos t/ D .sin t/. sin t/ .cos t/.cos t/ D .sin2 t C cos2 t/ D 1 ¤ 0, it follows from Theorem 5.2.9 that they form a fundamental set of solutions and hence x D c1 sin t C c2 cos t is the general solution.
To answer the second part, any pair of solutions whose Wronskian is different
from zero would generate the same general solution. Thus, any pair of solutions that are not constant multiples of each other would work. For example, if x1 D 2 sin t and x2 D 3 cos t, then W .2 sin t; 3 cos t/ D .2 sin t/. 3 sin t/ .3 cos t/.2 cos t/ D
6.sin2 xCcos2 x/ D 6 and hence they form a fundamental set of solutions. Therefore, y D c1.2 sin t/ C c2.3 cos t/ is the general solution. We note that if we replace the constant 2c1 by another constant k1 and 3c2 by k2, then the general solution becomes x D k1 sin t C k2 cos t.

88 5 Second order equations
5.3 Reduction of the order

Consider again the general linear homogeneous equation

x00 C p.t/x0 C q.t/x D 0

(5.2)

where p.t/ and q.t/ are continuous in the interval I Â R. If x1 is a solution, then we know that any constant multiple x D cx1 is also a solution. Can c be replaced by a variable function v.t/ such that x2 D v.t/x1.t/ is also a solution? The answer is yes. As shown in the theorem below, substituting x2 in the equation (5.2) reduces the order of the differential equation and is hence called the Reduction of Order Method.

Theorem 5.3.1. If x1.t/ is a solution of .5:2/ in I , x1.t/ 6D 0, then

Z

e

R p.t / dt

x2.t/ D x1.t/

x12.t / dt

is another solution. Furthermore, x1.t/ and x2.t/ form a fundamental set of solutions.

Proof. Substituting v.t/x1.x/ in equation (5.2), we have
.v00x1 C v0x10 C vx100 C v0x10 / C p.v0x1 C vx10 / C vqx1 D x1v00 C .2x10 C px1/v0 C v.x100 C px10 C qx1/ D x1v00 C .2x10 C px1/v0 D 0

since x100 C px10 C qx1 D 0, as x1 is a solution of (5.2). Now, if we let w D v0,

we obtain the first order differential equation x1w0

.

2x10 x1

Cp/w
R

D

0.

The

integrating

factor

for

this

first

C .2x10 C px1/w D 0

or
R

order equation is e2 ln x1C

w0
p dt

C D

x12e p dt : Therefore, assuming that x1 ¤ 0, we obtain

R

wD

c
R
x12e p dt

D

ce

p dt
x12 :

Recall that v0 D w. Since we only need one function v.t/ so that vx1 is a solution,

we can let c D 1 and hence

wD e

R p dt
x12 ;

Z and x2 D x1v D x1

e

R p dt
x12 dt:

To see that x1 and x2 form a fundamental set of solutions, we note that according to Theorem 5.2.9, x1 and x2 are fundamental solutions if W .x1; x2/ ¤ 0 or equiva-

lently if they are linearly independent (see Theorem 5.2.7 ). Thus it suffices to show

that they are linearly independent; or, equivalently, that one of them is not a con-

stant multiple of the other. To verify the last statement, suppose that x2 D cx1, c a

constant. Then

Z

e

R p dt

x1

x12 dt D cx1

5.4 Linear nonhomogeneous equations 89

and hence

Z

e

R p dt

x12 dt D c:

Now, taking the derivatives of both sides, we obtain

R

e

p dt
x12 D 0

R
which is a contradiction since e p dt is nonzero.

Example 5.3.2. Knowing that x1 D t is one solution, find the general solution of

x00

1x0 t

C

1 t2

x

D

0;

t > 0:

To find another linearly independent solution, using Theorem 5.3.1, we obtain

ZR e

1 t

dt

t

t2 dt D t ln t:

The general solution is x D c1t C c2t ln t:

Equations like the one in the previous exercise are called Euler equations and will be discussed in Subsection 5.5.1.

5.4 Linear nonhomogeneous equations

In this section we study the nonhomogeneous equation

x00 C p.t/x0 C q.t/x D f .t/:

(5.5)

First we state the existence and uniqueness of solutions, which follow immediately from Theorems 4.2.2­4.2.3 of Chapter 4.

Theorem 5.4.1 (Existence and Uniqueness). Suppose that p, q, and f are continuous functions on an interval I Â R. Equation (5.5) has a unique solution x.t/ such that x.t0/ D , x0.t0/ D , where t0 is any number in I and  and  are any real
numbers. Furthermore, this solution is defined for all t, t in I .

Similar to the case for homogeneous equations, the general solution of (5.5) is defined as the family of all solutions of such an equation.
The next theorem shows that in order to find the general solution of the nonhomogeneous equation, all we need is the general equation of the homogeneous equation and one solution of the nonhomogeneous equation. For the constant coefficient case, we have already learned how to find the general solution of the homogeneous

90 5 Second order equations

equation. In the next section we will learn how to find a particular equation of the nonhomogeneous equation and thus get the general solution of the nonhomogeneous equation.

Lemma 5.4.2. If x1 and x2 are two solutions of the nonhomogeneous equation (5.5), then x1 x2 is a solution of the corresponding homogeneous equation

x00 C p.t/x0 C q.t/x D 0:

(5.6)

Proof. The proof is straightforward . Since x100 C p.t /x10 C q.t /x D f .t / x200 C p.t /x20 C q.t /x2 D f .t /;
then by subtracting the second equation from the first, we obtain .x100 x200/ C p.t /.x10 x20 / C q.t /.x1 x2/ D 0;
which proves the assertion.

Theorem 5.4.3. If x D c1x1 C c2x2 is the general solution of the homogeneous equation (5.6) and xp is any solution of the nonhomogeneous equation (5.5), then z D c1x1 C c2x2 C xp, c1; c2 2 R, is the general solution of (5.5).
Proof. Let z be any solution of the nonhomogeneous equation (5.5). We want to show that there exist constants k1 and k2 such that z D k1x1 C k2x2 C xp. But since, by Lemma 5.4.2, z xp is a solution of the homogeneous equation (5.2), there exist constants k1 and k2 such that z xp D k1x1 C k2x2 because x D c1x1 C c2x2 is given to be the general solution of the homogeneous equation. Solving for z, we get the desired result z D k1x1 C k2x2 C xp.

Example 5.4.4. Consider the nonhomogeneous equation

x00

1 x0 t

C

1 t2

x

D

4t;

t > 0:

In Example (5.2), we found the general solution of the corresponding homogeneous equation to be x D c1t C c2t ln t: We also see that xp D t3 is a particular solution
of the given nonhomogeneous equation. Therefore,

x D c1t C c2t ln t C t3; t > 0

is its general solution.

So, it seems that solving the nonhomogeneous second order linear equation is quite simple if we can find the general solution of the corresponding homogeneous equation and a particular solution of the nonhomogeneous equation. But, except by inspection whenever possible, we have not yet developed a method for finding a

5.4 Linear nonhomogeneous equations 91
particular solution of the nonhomogeneous equation. Next, we discuss a method for finding a particular solution of the nonhomogeneous equation.

5.4.1 Variation of parameters

As we saw in Section 5.3, given one solution x1, we were able to find a function
v.t/ so that vx1 was also a solution. Here, given a pair of fundamental solutions x1
and x2 of the homogeneous equation (5.2), we try to find functions v1.t/ and v2.t/ such that x D v1x1 C v2x2 is a solution of (5.5). To this end, let z D v1x1 C v2x2. Calculating z0 and z00, we have z0 D v1x10 C v10 x1 C v2x20 C v20 x2: Now, since we have two unknowns v1 and v2, we would like to also have two equations involving
these unknowns. Furthermore, we realize that substituting z in (5.5) will give us one
equation. So, at this point we make the decision to let one of the equations be

v10 x1 C v20 x2 D 0

(5.7)

which will also make it convenient and simpler to calculate z00. We have now reduced z0 to z0 D v1x10 C v2x20 from which we obtain z00 D v10 x10 C v1x100 C v20 x20 C v2x200. In order to find a second equation involving v10 and v20 , we substitute z in equation
(5.5), obtaining

OEv10 x10 C v1x100 C v20 x20 C v2x200 C p.t /OEv1x10 C v2x20  C q.t /OEv1x1 C v2x2 D f .t /

which, after regrouping terms, can be written as

v1OEx100 C p.t /x10 C q.t /x1 C v2OEx200 C p.t /v20 C v2x2 C OEv10 x10 C v20 x20  D f .t /:

Since x1 and x2 are solutions of the homogeneous equation (5.6) and hence satisfy the equation, the preceding equation is reduced to

v10 x10 C v20 x20 D f .t /:

(5.8)

Thus we have reduced the problem of finding v1 and v2 to solving the algebraic system of equations (5.7)­(5.8)
´ v10 x1 C v20 x2 D 0 v10 x10 C v20 x20 D f .t /

for v10 and v20 and then integrating to obtain v1 and v2. Solving for v10 and v20 , we have

v10

D

f

0 .t

/

xx220 

W .t/

D

x2.t/f .t/ ; W .t/

v20

D

xx110 f 0.t/ W .t/

D

x1f .t/ W .t/

where W .t/ D W .x1; x2/.t/. Therefore, the particular solution z of (5.5) is given by

Z

Z

z D x1.t/

x2.t/f .t/ dt W .t/

C

x2.t /

x1.t/f .t/ dt: W .t/

(5.9)

92 5 Second order equations
We do not advise that one memorize these integrals for v1 and v2 but instead one should start with the system of equations (5.7) and (5.8) and go through the procedure outlined above.

Example 5.4.5. Consider the equation x00 x D f .t /

(5.10)

where f is a continuous function on an interval I .

To find the general solution of the associated homogeneous equation x00 x D 0,

namely x00 D x, we notice that x1 D et and x2 D e t solve the equation. Since the

Wronskian of et ; e t is

W

D 

et et

et et

 D

2

they form a fundamental set of solutions. Thus the general solution of x00 x D 0 is

x.t / D c1et C c2e t :

Finding a specific solution z.t/ of (5.10) in the form z.t/ D v1.t/et C v2.t/e t leads

to the system

´ v10 .t /et C v20 .t /e t D 0

v10 .t /et v20 .t /e t D f .t /

where the determinant of the coefficients is W D 2. Then

v10 .t / D

e

t f .t / 2

D

1 2

e

t f .t/;

v20 .t /

D

et f .t/ 2

D

1 2

et

f

.t

/:

Integrating

Z

Z

v1.t /

D

1 2

e t f .t/;

v2.t/ D

1 2

et f .t/

and hence

Z

Z

z .t /

D

1 2

e

t

e t f .t/

1 2

e

t

et f .t/:

This formula gives the particular solution in an implicit way and it holds for any function f .t/.

Example 5.4.6. Find the general solution of

x00 C x D

1 ;

cos t

<t< :

2

2

We have already seen in Example 5.2.10 that the general solution of the associated homogeneous equation x00 C x D 0 is x.t/ D c1 sin t C c2 cos t. Moreover, the
Wronskian W .x1; x2/ of x1 D sin t; x2 D cos t is equal to 1. To find a specific

5.5 Linear homogeneous equations with constant coefficients 93

solution z

of x00

Cx

D

1 cos t

we set z

D v1 sin t

C v2 cos t

and solve the system

´ v10 .t/ sin t C v20 .t/ cos t D 0

v10 .t / cos t

v20 .t / sin t

D

1 cos t

<t < ;

2

2

where the coefficient determinant is just the Wronskian W D 1. Then Cramer's rule yields

v10 .t /

D cos t

1 cos t

D 1;

v20 .t / D

sin t 1 D cos t

sin t ;
cos t

<t < :

2

2

Integrating, we get

Z v1.t/ D dt D t C c1

and v2.t/ D

Z

Z

sin t dt D cos t

d cos t cos t

D ln.cos t/ C c2;

<t < :

2

2

For convenience we can take c1 D c2 D 0 since we need only one function v1 and one function v2: Thus a specific solution is z.t/ D t sin t C cos t ln.cos t/. Finally, the general solution is

x.t/ D c1 sin t C c2 cos t C t sin t C cos t ln.cos t/;

<t < :

2

2

Remark 5.4.7. The method of Variation of Parameters has a drawback and that is that the integration may be messy or even impossible to carry out in order to find the solution explicitly. But we can always find the solution implicitly as long as we can find the general solution of the homogeneous equation.

5.5 Linear homogeneous equations with constant coefficients

A general second order homogeneous equation with constant coefficients has the

form

ax00 C bx0 C cx D 0;

(5.11)

where a D6 0. In searching for a solution, we recall that the exponential functions
have the property that their derivatives involve the same exponential functions. So, we might try to find solutions of the form x D emt . We also see that if we substitute
this exponential function in the differential equation, every term on the left side will have a constant times emt and hence we can eliminate it by dividing both sides by it.
Now we end up with an algebraic quadratic equation that we can handle. To this end, substituting y D emt into the equation, we obtain

a m2emt C b memt C c emt D 0:

94 5 Second order equations Dividing by emt , we obtain the algebraic equation

a m2 C b m C c D 0:

(5.12)

This shows that if x D emt is a solution of (5.11), then m is a solution of (5.12). Conversely, if m is solution of (5.12), then, by reversing the steps, it follows that emt

is a solution of (5.11).

Equation (5.12) is called the characteristic or auxiliary equation corresponding

to equation (5.11). We have now reduced the problem of solving (5.11) to that of

solving the characteristic equation and then analyzing the corresponding solutions.

Solving (5.12), we have

p

mD

b

b2

4ac :

2a

We have to consider three cases: (1) b2 4ac > 0, (2) b2 4ac D 0 and (3) b2 4ac < 0.

(1) The case b2 4ac > 0 (real distinct roots). In this case the characteristic equa-

tion has two distinct real roots

p

p

m1 D

b C b2 2a

4ac ;

m2 D

b

b2 4ac :
2a

The corresponding solutions of (5.11) are given by x1 D em1t and x2 D em2t . We
claim that x1 and x2 are a fundamental set of solutions. To see this, we simply evaluate their Wronskian. W .x1; x2/.t / D em1t m2em2t m1em1t em2t D em1t em2t .m1 m2/ ¤ 0 since m1 and m2 are distinct roots. This means that the general solution of
(5.11) is given by x D c1em1t C c2em2t :

Example 5.5.1. Solve the initial value problem 2x00 C x0 x D 0; x.0/ D 1; x0.0/ D 2:

By substituting x D emt , we obtain the characteristic equation

2m2 C m 1 D 0:

Solving for m, we set 2m2 C m 1 D 0 D .2m 1/.m C 1/ and find the two

roots m1 D

1;

m2

D

1 2

.

Since

the

roots

of

the

characteristic

equation

are

real

and

distinct, the general solution of the differential equation is x

D

c1e

t

C

c2e

1 2

t

.

In

order to get the solution to the initial value problem, we set x.0/ D 1; x0.0/ D 2

and solve for c1 and c2. Solving,

´ c1 C c2 D 1

c1

C

1 2

c2

D2

5.5 Linear homogeneous equations with constant coefficients 95 we obtain c1 D 1 and c2 D 2. Therefore,

xD

e

t

C

2e

1 2

t

is the desired solution.

(2) The case b2 root of

4ac D 0 (repeated roots). In this case, m D ax00 C bx0 C cx D 0

b 2a

is

a

repeated

and we have only one solution x1 D e

b 2a

t

.

In

order

to

find

another

linearly

inde-

pendent solution, we either use the method of Reduction of Order directly or we use

Theorem 5.3.1. Using the theorem, we let p.t/ D b=a, x1

De

b 2a

t

,

and

obtain

another linearly independent solution

x2 D e

Z

b 2a

t

e

b a

t

.e

b 2a

t

/2

d

t

D

e

Z

b 2a

t

e e

b a

t

b a

t

dt

D

e

Z

b 2a

t

dt D te

b 2a

t

taking the constant of integration to be zero. One can easily verify that x1 D e

b 2a

t

and x2 D te

b 2a

t

are

linearly

independent

and

hence

form

a

fundamental

set

of

so-

lutions. Therefore x D c1e

b 2a

t

C

c2t e

b 2a

t

is

the

general

solution.

Example 5.5.2. Find the general solution of x00 6x0 C 9x D 0. The corresponding characteristic equation is m2 6mC9 D 0. We see that m2 6mC9 D .m 3/2 D 0 has a repeated root m D 3. Therefore, x D e3t and te3t are two independent solutions and hence the general solution is given by x D c1e3t C c2te3t .

(3) The case b2 4ac < 0 (complex roots). We first recall a couple of simple facts
about complex numbers. 1. If C i is a root of the characteristic equation am2 C bm C c D 0, then so
is its conjugate i .
2. A complex number can be equal to 0 only if its real and imaginary parts are both 0, that is C i D 0 implies D D 0.
When the discriminant b2 4ac is negative, the characteristic equation has two
complex conjugate roots

p

mD

b

b2

4ac :

2a

But, for a complex number C i , what is e. Ci /t and how do we extract real solutions out of this? We proceed as follows.

96 5 Second order equations

First, we write, formally, the Taylor expansion for ei , obtaining

ei

D X 1 .i /n

D 1Ci

i2 2 i3 3 i4 4

C

C

C

C:::

nS

2S

3S

4S

nD0

D 1Ci

2 i3

4

C C::: :

2S 3S 4S

Regrouping the real and imaginary terms in the above series, we obtain

X 1

2k

X 1

.2kC1/

e i D . 1/k

C i . 1/k

:

.2k/S

.2k C 1/S

nD0

nD0

We recognize the first sum to be cos and the second one to be sin . Therefore, it seems reasonable to define e i as e i D cos C i sin , and consistent with the exponential laws, e C i D e e i D e .cos C i sin /.
Next, given a complex valued solution, how do we extract a real solution? To see
this, let .t/ C i .t/ be a given complex valued solution of

x00 C p.t/x0 C q.t/x D 0:

Then, substituting, we have . .t/ C i .t//00 C p.t/. .t/ C i .t//0 C q.t/. .t/ C i .t// D 0:

Now grouping the terms involving and those involving , we obtain
. 00 C p.t/ 0 C q.t/ / C i. 00 C p.t/ 0 C q.t/ / D 0:
This implies that the real and complex parts must be 0, that is 00 C p.t/ 0 C q.t/ D 0 D 00 C p.t/ 0 C q.t/ . Therefore, x1 D .t/ and x2 D .t/ are real valued solutions.
Returning to our differential equation ax00 C bx0 C cx D 0, where b2 4ac < 0, we see that if the characteristic equation has two complex valued roots, m D  i . Then the corresponding real solutions of the differential equation ax00Cbx0Ccx D 0 will be given by x1 D e t cos t and x2 D e t sin t. The fact that they are linearly independent is obvious since they are not constant multiples of each other. Therefore they form a fundamental set of solutions and the general solution is
x D c1e t cos t C c2e t sin t D e t .c1 cos t C c2 sin t/:
Summarizing, the general solution of ax00 C bx0 C cx D 0 includes three types of solutions, depending on whether the discriminant of the characteristic equation am2 C bm C c D 0 is positive, negative or zero.

Example 5.5.3. Solve the initial value problem x00 C 2x0 C 2x D 0; x.0/ D 3; x0.0/ D 7:

5.5 Linear homogeneous equations with constant coefficients 97

The roots ofpthe mD 1

characteristic 1 D 1  i.

equation m2 C 2m Therefore, x1 D e

C2 D t cos t

0 are the complex and x2 D e t sin

numbers t are the

corresponding linearly independent solutions and the general solution is

x.t/ D e t .c1 sin t C c2 cos t/:

We point out that in this example, all solutions approach 0 as t ! 1. Calculating the derivative of the general solution, we have
x0.t/ D e t .c1 cos t c2 sin t/ e t .c1 sin t C c2 cos t/:

Now, in order to find the solution satisfying the required initial values, we notice that if we let t D 0 in the general equation, we obtain x.0/ D c2. Therefore, we have to find c2 D 3. To find c1, we set t D 0 in the derivative x0 of the general solution and obtain
x0.0/ D c1 c2 D 7;
which gives us c1 D 7 C c2 D 10. Therefore,
x D e t .10 sin t C 3 cos t/

is the desired solution.

Example 5.5.4. (The pendulum equation) Consider a point P of mass m suspended from a pivot by a chord of fixed length L so that P moves along a circle of radius L in a vertical plane passing through the pivot. On the point P acts the gravity force g and there is no friction.
Referring to Figure 5.2, the tangential component of the force acting on P is mg sin Â (the minus sign takes into account that the angle Â increases in the counterclockwise sense), while the tangential component of the acceleration is LÂ00. Thus Newton's law yields mLÂ00 D mg sin Â, that is
L Â 00 C g sin Â D 0:

Recall that the Taylor expansion of sin Â is

sin Â D Â 1 Â 3 C 1 Â 5 C : : : : 3S 5S

Then, for small oscillations, we can approximate sin Â by Â and the solutions of the pendulum equation are, up to a small error, those of

L Â00 C g Â D 0;

which is the equation of the harmonic oscillatopr with !2

D

g L

.

The

characteristic

equation is L m2 C g D 0, whose roots are i g=L. Then the solutions are

p

p

Â.t/ D c1 sin g=L t C c2 cos g=L t;

98 5 Second order equations



L

P

mg sin 



mg cos 

mg

Fig. 5.2. The pendulum

p which are periodic oscillations with period T D 2 L=g. Notice that T depends only on L, not on the initial position of P . This property is the so-called isochronism of the pendulum. It is worth pointing out that isochronism is valid for the approximated equation, not for the true pendulum equation.

Example 5.5.5. (An RLC electrical circuit) In an RLC circuit with resistance R, inductance L, capacitance C and with a source with constant voltage V , see Figure 5.3, the intensity of the circulating current is governed by the second order equation

x00.t/ C R x0.t/ C 1 x.t/ D 0:

L

LC

(5.13)

Here, to keep notation uniform with that used before, we have denoted by x.t/ the current intensity usually named I.t/ or i.t/.

Fig. 5.3. RLC circuit

5.5 Linear homogeneous equations with constant coefficients 99

The reader will notice that (5.13) is palso the equation of a damped harmonic oscillator, with k D R=L > 0, ! D 1= LC > 0 and f D 0, see Example 5.1.1, discussed in the first section. In such a case kx0 represented a friction force.

Equation (5.13) is of the form of the general linear equation with constant coefficients (5.11), with a D 1, b D k and c D !2. Setting k D 2 , the characteristic equation

associated to (5.13) is

m2 C 2 m C !2 D 0

whose roots are

m1;2 D

p  2 !2:

Recalling that both ! and are positive, m1;2 are real or complex conjugates depending on whether ! or < !.
(1) Overdpamped response. If > ! > 0 , m1; m2 are real, distinct and negative (because 2 !2 < ), then the general solution of (5.13) is
x.t / D c1em1t C c2em2t :

Since m1; m2 < 0 these are decaying functions without oscillations, see Figure 5.4, blue curve. Here and below, the constants c1; c2 can be found if we impose initial conditions.

(2) Critically damped response. If D !, m1 D m2 D
is x.t / D c1e t C c2t e t ;

and the general solution

which implies fast decaying solutions without oscillations, see Figure 5.4, red curve.

x

O

t

Fig. 5.4. Overdamped (blue), critically damped (red) and underdamped (black) response

100 5 Second order equations
(3) Underdamped response. If 0 < < !, the roots of the chparacteristic equation are complex conjugates, namely m1;2 D  iÂ , where Â D !2 2. Then the general solution is
x.t/ D e t .c1 sin Â t C c2 cos Â t/ ;
which implies decaying oscillations, see Figure 5.4, black curve.
Remark 5.5.6. (i) Equation (5.13) is independent of the constant voltage V . (ii) The decay is due to the presence of k D R=L > 0. In other words, it is the pres-
ence of the resistor R that, dissipating energy, induces a decay of the current intensity. If there is no resistance, that is if R D 0, then we have an LC circuit. In this case we have D 0 and Â D !. The solution becomes x.t/ D c1 sin !t C c2 cos !t, which means that the current intensity is sinusoidal and oscillates without any decay.

5.5.1 The Euler equation

An equation of the form at 2x00 C btx0 C cx D 0;

t > 0;

is called a (homogeneous) Euler equation. Such an equation can be changed to one with constant coefficients by making the substitution t D es, or equivalently s D ln t,

as follows.

We note that

ds dt

D

1 t

D

1 es

.

For

convenience,

we

let

dx ds

D xP to distinguish it

from x0

D

dx dt

.

Then,

x

0

D

dx dt

D

dx ds

ds dt

D

xP

1 es

.

Therefore,

tx0

D es xP

1 es

D

xP :

Now,

x00

D

dx0 dt

D

dx0 ds

ds dt

D

d

.xP

1 es

/

ds

ds dt

D

esxR esxP e2s

1 es

D

xR xP e2s :

Therefore,

t 2x00 D xR xP :

We see that making the substitutions for x0 and x00 will convert the given differential equation to the linear equation with constant coefficients

a.xR xP / C bxP C cx D 0;

or axR C .b a/xP C cx D 0:

Example 5.5.7. Solve 2t2x00 C tx0 3x D 0;

t > 0:

5.6 Linear nonhomogeneous equations ­ method of undetermined coefficients 101

Using the substitutions above, we have

2.xR xP / C xP 3x D 2xR xP 3x D 0:

The corresponding characteristic equation is 2m2 m 3 D 0 and the roots are

mD

1;

3 2

.

Therefore,

the

general

solution

in

terms

of

s

is

x .s /

D

c1e

s

C

c2e

3 2

s

.

Finally, substituting s D ln t, we have x.t/ D c1t

1

C

c2t

3 2

:

Example 5.5.8. Solve t2x00 C tx0 C x D 0;

t > 0:

Making the substitution s D ln t, we obtain

xR C x D 0

whose general solution is x.s/ D c1 sin s C c2 cos s. Since s D ln t we have x.t/ D c1 sin.ln t/ C c2 cos.ln t/.

Nonhomogeneous Euler equations at 2x00 C btx0 C cx D h.t /

t > 0;

can be handled in a similar way and are briefly discussed in Remark 5.6.10 in the next section.

5.6 Linear nonhomogeneous equations ­ method of undetermined coefficients

Consider the equation

ax00.t/ C bx0.t/ C cx.t/ D f .t/;

(5.14)

where the coefficients a; b; c are constants and a D6 0. Let us consider a specific case where a particular solution z.t/ of this nonhomogeneous equation can be found by inspection. This may happen, e.g., if f .t/ is a polynomial of degree n, or an exponential e t , or a trigonometric function like sin t, cos t, or a linear combination of these. In such cases, one can try to find z, by careful guessing, as a function of the same type as f .t/. This is known as the method of undetermined coefficients.
Instead of carrying out a general discussion, we prefer to demonstrate this method by considering appropriate examples.
We first consider the case in which f .t/ D P .t/e t , where P is a polynomial. We can try to find a solution of

ax00 C bx0 C cx D P .t /e t

(5.15)

102 5 Second order equations

by setting z D Q.t/e t , where Q is a polynomial to be determined. Since z0 D Q0e t C Qe t and z00 D Q00e t C 2 Q0e t C 2Qe t , then z solves (5.15) pro-
vided

a.Q00e t C 2 Q0e t C 2Qe t / C b.Q0e t C Qe t / C cQe t D P e t :

Canceling e t we find a.Q00 C 2 Q0 C 2Q/ C b.Q0 C Q/ C cQ D P or equivalently, rearranging,

a.Q00 C 2 Q0/ C bQ0 C .a 2 C b C c/Q D P:

(5.16)

This equation allows us to find Q by means of the polynomial identity principle.
To establish the degree d.Q/ of the unknown polynomial Q, it is convenient to distinguish whether is a root of the characteristic equation am2 C bm C c D 0 or
not. The former case is called resonant, the latter non resonant.

Equation (5.15): the non resonant case. In the non resonant case is not a root of the characteristic equation, namely a 2 C b C c ¤ 0, and we can look for a
polynomial Q such that d.Q/ D d.P /, where d.P / denotes the degree of P .

Example 5.6.1. (i) Find a particular solution of 2x00 x0 C 3x D 2t. In this case

P .t/ D 2t and D 0. Setting z.t/ D At C B, we determine A; B such that z satis-

fies 2z00 z0 C 3z D 2t. Since 2z00 z0 C 3z D A C 3.At C B/ then z solves the

given equation whenever 3At C 3B A D 2t, namely 3A D 2 and 3B A D 0.

Thus

we

find

A

D

2 3

and

B

D

2 9

and

hence

z

D

2 3

t

C

2 9

.

(ii) Find a particular solution of x00 C x D 3e2t . Here P D 3 and D 2. Taking

z D Ae2t and substituting in the equation, we find 4Ae2t C Ae2t D 3e2t , and hence

5A

D

3,

namely

A

D

3 5

.

Thus

z

D

3 5

e

2t

.

Equation (5.15): the resonant case. In the resonant case is a root of the charac-

teristic equation, namely

a 2 C b C c D 0:

If this holds (5.16) becomes aQ00 C .2a C b/Q0 D P:

(5.17)

Notice that the degree of the left hand side of (5.17) is d.Q/ 1 if 2a C b ¤ 0,
otherwise it is equal to d.Q/ 2. Since both sides of (5.17) have the same degree,
it follows that d.P / is equal respectively to d.Q/ 1 or to d.Q/ 2, namely that d.Q/ D d.P / C 1 or, respectively, d.Q/ D d.P / C 2. Roughly, the feature of the resonant case is that seeking a solution of ax00 C bx0 C cx D P e t in the form z D Qe t , the degree of Q has to be greater than the degree of P .
Moreover, the polynomial on the left hand side of (5.17) contains only the deriva-
tives of Q and therefore the term of order zero plays no role and can be taken to be
zero. In other words, we can look for a polynomial Q.t/ whose lower order term has degree one. For the same reason, if is a root of a 2 C b C c D 0 and, in addition,

5.6 Linear nonhomogeneous equations ­ method of undetermined coefficients 103
2a C b D 0, then (5.17) becomes aQ00 D P and hence we can search for Q such that its lower order term has degree two, see Example 5.6.3 below.
The following simple examples can be easily extended to more general cases.

Example 5.6.2. Find a particular solution of 2x00 C 3x0 D 1 C 4t.
Here P .t/ D 1C4t and D 0, which is a (simple) root of the characteristic equation 2m2 C 3m D 0. We are in the resonant case. Looking for a particular solution z of the form z D At2 C Bt. Then we have 2z00 C 3z0 D 4A C 6At C 3B D 1 C 4t.

Using the polynomial identity principle it follows that

´ 4A C 3B D 1;

6A

D 4;

whence

A

D

2 3

and

B

D

5 9

and

z

D

2 3

t

2

5 9

t

.

Notice that d.P / D 1 while the degree of z is 2.

Example 5.6.3. (Inclined plane) Consider a body of mass m on a frictionless inclined
plane with slope , see Figure 5.5. The component of the gravitational force mg parallel to the inclined plane is F D
mg sin . If x denotes the distance of the body from the top of the inclined plane (the
point O in Figure 5.5), then, according to Newton's second law of motion, we deduce that the acceleration x00 of the body satisfies mx00 D mg sin . Canceling m, we find

x00 D g sin :

A

particular

solution

is

given

by

z .t /

D

1 2

g

t2

sin .

Notice

that

the

constant

forcing

term g sin  is resonant. Since the general solution of the corresponding homoge-

neous equation x00 D 0 is x.t/ D c1 C c2t, it follows that the general solution of

x00 D g sin  is given by

x .t /

D

c1

C

c2t

C

1 g
2

t2

sin

:

O

x

F

mg

x Fig. 5.5. The inclined plane with slope 

104 5 Second order equations

Noticing that c1 D x.0/ and c2 D x0.0/ we can write the solution as

x .t /

D

x .0/

C

x0.0/t

C

1 g

t2

sin :

2

For example, if the body is initially at rest on the top of the inclined plane, then

the initial conditions are

x .0/

D

x0.0/

D

0 and

we get x.t/

D

1 2

g

sin



t

2

.

Notice

that, as it is well known, the motion of the body is independent of its mass m.

The following example deals with other resonant forcing terms.
Example 5.6.4. (i) Find a particular solution of x00 x D 2et . Here the forcing term is f .t/ D P .t/e t with P .t/ D 2 and D 1. Since D 1 is a root of the characteristic equation m2 1 D 0, we are in the resonant case. Let us try to find a particular solution of the form z D Atet . One finds z00 D 2Aet C Atet and hence z00 z D 2Aet C Atet Atet D 2Aet . Then z00 z D 2et yields A D 1 and hence z D tet:
(ii) Find a particular solution of x00 x0 D .t C 2/et . This is also a resonant case, because D 1 is a root of the characteristic equation m2 m D 0. Setting z D t.At C B/et D .At2 C Bt/et , we find
z0 D .2At C B/et C .At2 C Bt/et D OEAt2 C .2A C B/tet

and z00 D .2At C 2A C B/et C OEAt2 C .2A C B/tet D OEAt2 C .4A C B/t C 2A C Bet :
Then z00 z0 D .t C 2/et yields OEAt2 C .4A C B/t C 2A C B OEAt2 C .2A C B/t D t C 2;

whence

2At C 2A C B D t C 2:

Thus

we

find

A

D

1 2

and

2A C

B

D

2,

whence

B

D

1.

In

conclusion,

z

D

.

1 2

t2

C

t /et .

Remark 5.6.5. If f .t/ D f1.t/ C ::: C fn.t/, a particular solution can be sought as

z D z1 C ::: C zn, where zi solve ax00 C bx0 C cx D fi . For example, to find a

particular solution of x00 x D et C e2t we can solve separately z100 z1 D et and

z200

z2

D

e2t .

The

former

is

resonant

and

we

find

z1

D

1 2

t

e

t

.

The

second

equation

is not of x00

resonant and we find z2 x D et C e2t .

D

1 3

e2t

.

Thus

z

D

1 2

t

e

t

C

1 3

e2t

is

a

particular

solution

We now consider the equation ax00 C bx0 C cx D P1.t/ sin t C P2.t/ cos t

(5.18)

5.6 Linear nonhomogeneous equations ­ method of undetermined coefficients 105
where P1; P2 are polynomials and ¤ 0 (this will be always understood in the sequel, otherwise the forcing term becomes a polynomial, a case discussed previously). We can try to find a particular solution of (5.18) by setting z D Q1.t/ sin t C Q2.t/ cos t, where Q1; Q2 are polynomials to be determined.
First of all, let us see what what the resonant case is for (5.18). If the forcing term is P e t we have seen that the resonant case arises when is a root of the characteristic equation am2 C bm C c D 0. Dealing with (5.18) and recalling the Euler formula ei t D cos t C i sin t, it is natural to say that P1.t/ sin t C P2.t/ cos t is a resonant forcing term provided i is a root of the characteristic equation am2 C bm C c D 0, namely provided a 2 C b i C c D 0. Since a complex number is zero whenever its real and imaginary parts are zero, it follows that we are in the resonant case if and only if b D 0 (recall that ¤ 0) and c D a 2. We will see that resonance for (5.18) has the same feature as resonance when the forcing term is P e t : in the latter case seeking a particular solution in the form Qe t , the degree of Q is greater than the degree of P ; similarly, dealing with a resonant equation like (5.18), looking for a particular solution in the form Q1 sin t C Q2 cos t, the degrees of Qi are greater than the degrees of Pi . This confirms that the definition of resonance for (5.18) given above is the correct one.
Equation (5.18): the non resonant case. We first discuss some examples dealing with the non resonant case, namely when either b ¤ 0, or c ¤ a 2, or both. As we will see, in this case we can seek a particular solution in the form z D Q1 sin t C Q2 cos t, where the degrees of Qi are the same as those of Pi .
Example 5.6.6. Find a particular solution of the following equations with non resonant forcing terms.
(i) x00 Cx0 Cx D sin t. Setting z D A sin t CB cos t we find z0 D A cos t B sin t and z00 D A cos t B cos t, whence z00 Cz0 Cz D . A cos t B cos t/C.A cos t B sin t/ C .A sin t C B cos t/ D B sin t C A cos t. Then from z00 C z0 C z D sin t we infer that A D 0 and B D 1. Hence z D cos t.
(ii) x00Cx0Cx D sin 2t. Setting z D A sin 2t CB cos 2t one has z0 D 2A cos 2t 2B sin 2t and z00 D 4A sin 2t 4B cos 2t, whence
z00 C z0 C z D . 4A sin 2t 4B cos 2t/ C .2A cos 2t 2B sin 2t/
C A sin 2t C B cos 2t
D . 3A 2B/ sin 2t C .2A 3B/ cos 2t:
It follows that z00 C z0 C z D sin 2t provided one has . 3A 2B/ sin 2t C . 3B C 2A/ cos 2t D sin 2t, for all t 2 R. Taking first 2t D 2 and after t D 0 we find that A; B satisfy the algebraic system
´ 3A 2B D 1;
2A 3B D 0:

106 5 Second order equations

This system has a unique solution given by A D

3 13

and

B

D

2 13

.

Thus

z

D

3 13

sin

2t

2 13

cos

2t

.

(iii) x00 C x D sin 3t. Setting A sin 3t C B cos 3t and repeating the previous cal-

culations we find

z00 C z D 8A sin 3t 8B cos 3t:

Then z00 C z D sin 3t implies A D

1 8

,

B

D

0

and

hence

z

D

1 8

sin

3t .

The next example deals with non constant polynomials P1; P2.

Example 5.6.7. Find a particular solution of x00 x D t sin t. Also in this case the
forcing term is not resonant because i is not a root of the characteristic equation m2 1 D 0. If we set z D .A1t C B1/ sin t C .A2t C B2/ cos t we find

z0 D A1t sin t C .A1t C B1/ cos t C A2 cos t .A2t C B2/ sin t z00 D 2A1 cos t .A1t C B1/ sin t 2A2 sin t .A2t C B2/ cos t:

Then z00 z D t sin t yields

2A1 cos t .A1t C B1/ sin t 2A2 sin t .A2t C B2/ cos t .A1t C B1/ sin t .A2t C B2/ cos t D t sin t:

Rearranging we find

OE2A1 2.A2t C B2/ cos t OE2.A1t C B1/ C 2A2 sin t D t sin t:
Then it follows that A1; A2; B1; B2 satisfy the algebraic system ´ 2A1t 2B1 2A2 D t; 2A2t C 2A1 2B2 D 0;

which implies A1 D

1 2

,

A2

D

0,

B1

D

0

and

B2

D

1 2

.

In

conclusion

we

get

z

D

1 2

t

sin

t

1 2

cos

t.

Remark 5.6.8. As we have seen in the preceding examples, even if the forcing term is P1 sin t or P2 cos t, we cannot - in general - find a particular solution containing only sine or cosine terms.

Equation (5.18): the resonant case. Next, we consider the resonant case which arises if b D 0 and c a 2 D 0 and the equation (5.18) becomes

ax00 C a 2x D P1.t/ sin t C P2.t/ cos t:

(5.19)

As anticipated before, looking for a particular solution of (5.19) in the form z D Q1 sin t C Q2 cos t, we have to seek polynomials Q1 D A1t C A2t2 C ::: and Q2 D B1t C B2t2 C ::: whose degrees are greater than the degrees of P1; P2.

5.6 Linear nonhomogeneous equations ­ method of undetermined coefficients 107

Example 5.6.9. Find a particular solution of the following equations with a resonant forcing term: (i) x00 C x D sin t and (ii) x00 C x D t sin t.
(i) Taking z D At sin t C Bt cos t, we find
z0 D A sin t C B cos t C At cos t Bt sin t z00 D A cos t B sin t C A cos t B sin t At sin t Bt cos t
D 2A cos t 2B sin t At sin t Bt cos t z00 C z D 2A cos t 2B sin t At sin t Bt cos t C At sin t C Bt cos t
D 2A cos t 2B sin t:

Then z00 C z D sin t implies A D 0 and B D

1 2

and

thus

z

D

1 2

t

cos

t.

(ii) If take z D .A1t C A2t2/ sin t C .B1t C B2t2/ cos t, we can write z D z1 C z2,

where z1 D A1t sin t C B1t cos t and z2 D A2t2 sin t C B2t2 cos t. Using the cal-

culations in (i) we find z100 C z1 D 2A1 cos t 2B1 sin t. As for z2 we find

z200 D .2A2 4B2t A2t 2/ sin t C .2B2 C 4A2t B2t 2/ cos t z200 C z2 D .2A2 4B2t / sin t C .2B2 C 4A2t / cos t:

Then

z00 C z D z100 C z1 C z200 C z2 D .2A2 4B2t 2B1/ sin t C .2B2 C 4A2t C 2A1/ cos t

and the equation z00 C z D t sin t yields ´ 2A2 4B2t 2B1
2B2 C 4A2t C 2A1

D t; D 0:

Solving this algebraic system we find A2 D B1 D 0, B2 D

conclusion,

z D 1 t sin t 1 t2 cos t:

4

4

1 4

,

and A1

D

1 4

.

In

So far we have taken f D P e t or f D P1 sin t C P2 cos t but, more gen-

erally, we could deal with a forcing term f D f1 C : : : C fn , where each fi is

in one of the forms discussed above. As in Remark 5.6.5, a particular solution of

ax00 C bx0 C cx D f can be found as z1 C ::: C zn where azi00 C bzi0 C czi D fi . For

example, to find a particular solution of x00 2x D et C sin t we set z D z1 C z2,

where z100 2z1 D et and z200 2z2 D sin t. With calculations similar to the previ-

ous ones we find z1 D et and z2 D

1 3

sin

t

.

Thus

a

particular

solution

is

given

by

z D z1 C z2 D et

1 3

sin

t

.

Remark 5.6.10. (Nonhomogeneous Euler equations) As for the homogeneous Euler equation, the substitution t D es transforms the nonhomogeneous Euler equation

at2x00 C btx0 C cx D h.t/; t > 0;

108 5 Second order equations

into

a

d 2x ds2

C .b

a/ dx C cx D h.es/; ds

which is a linear nonhomogeneous equation with constant coefficients and can be handled either by the method of Variation of Parameters or using the method of Undetermined Coefficients.

Example 5.6.11. Find a particular solution z.t/ of t2x00 C tx0

Setting t D es we get

d 2x ds2

x D e2s

es:

x D t2

t, t > 0.

Let

us

first

find

a

solution

of

d2x ds2

x D e2s. To this end, we let x1 D Ae2s. Substi-

tuting, we obtain 4Ae2s

Ae2s D e2s and hence A

1 3

,

which

yields x1

D

1 3

e

2s.

So,Nweextl,ewt xe2fiDndAasseosl.uStiuobnstoitfutddi2ns2xg,

x D es. Now we obtain Ases C

we are 2Aes

in the Ases

resonant case. D es, which

implies that A D

1 2

and

x2

D

1 2

s

es

.

Using

Remark

5.6.5,

it

follows

that

a

particular

solution

of

d2x ds2

x D e2s

es is

x1

C x2

D

1 3

e2s

1 2

s

es.

Substituting t D es, namely s D ln t, we find that a particular solution of t2x00 C

tx0

x D t2

t,

t

>

0,

is

given by

z .t /

D

1 3

t

2

1 2

t

ln

t

.

In the next subsection we discuss a remarkable example arising in applications.

5.6.1 The elastic spring

Let us consider the second order nonhomogeneous equation x00 C !2x D sin !1t:

(5.20)

As we saw in Example 5.1.1, this equation models the motion of a body attached to
a fixed point by an elastic spring, under the assumption that the body is subjected to a sinusoidal external force f .t/ D sin !1t.
We have already seen that the general solution of the associated homogeneous equation x00 C !2x D 0 is

x.t/ D c1 sin !t C c2 cos !t:

To find a solution of the nonhomogeneous equation it is convenient to distinguish the cases whether ! 6D !1 or not.
(1) Case ! D6 !1. Setting z.t/ D  sin !1t, one finds z00 D !12 sin !1t. Then z00 C !2z D sin !1t yields
!12 sin !1t C !2 sin !1t D sin !1t:

5.6 Linear nonhomogeneous equations ­ method of undetermined coefficients 109
x(t)

Fig. 5.6. Beats: solutions of (5.20) when !1 !

Dividing through by sin !1t, we get .!2 !12/ D 1. Since !12 D6 !2 we find  D

1=.!2 !12/ and hence

z.t / D !2 1 !12 sin !1t:

(5.21)

Thus the general solution of (5.20) is given by

x.t/ D c1 sin !t C c2 cos !t C !2 1 !12 sin !1t:

The resulting wave is a superposition of two oscillations with frequency !1 and !. Particularly interesting is the case shown in Figure 5.6 in which the two frequencies are very close. This phenomenon is called beat.

(2) Case ! D !1. This is the resonant case when the equation becomes x00 C !2x D sin !t:

(5.22)

As in Example 5.6.4 - (i), we can find a particular solution in the form z D At sin !t C Bt cos !t. Repeating the calculations carried out therein, one finds

z00 C !2z D 2A! cos !t 2B! sin !t:

Then z00 C !2z D sin !t yields A D 0; B D

1 2!

and

hence

z.t/ D

1 t cos !t

2!

(5.23)

is a particular solution of the nonhomogeneous equation.

110 5 Second order equations
x
t

Fig. 5.7. Resonance: solution of (5.22) for t > 0

Therefore the general solution of (5.22) is given by

t

x.t/ D c1 sin !t C c2 cos !t

cos !t: 2!

The graph of the solutions is shown in Figure 5.7 and shows that the presence of

t 2!

cos !t

has

the

effect

of

producing

oscillations

of

increasing

amplitude.

Let us check this claim. To simplify the notation, we take c1 D ! D 1 and c2 D 0 so

that x.t/ If we

D let

sin t sn D

t 2

cos

2n ,

t. The general case is quite similar we have sin sn D 0 and cos sn D

and is left as an exercise. 1 so that x.sn/ D n

which tends to 1. If we let tn D .2nC1/ , then sin tn D 0 and cos tn D 1 so that

xlim.tns/uDpt!nC1Cx2.tw/hDichCte1nd. sMtoorCeo1ve.rT, hbiys

implies that lim inft!C1 x.t/ D the Intermediate Value Theorem,

1 and between

sn and tn there are zeros of x.t/.

5.7 Oscillatory behavior of solutions

Consider the second order linear homogeneous equation x00.t/ C p.t/x.t/ D 0:

(5.24)

For simplicity, we assume that p.t/ is continuous everywhere. Obviously, we can restrict it only to the relevant interval, if we wish.
We say that a nontrivial solution x.t/ of (5.24) is oscillatory (or it oscillates) if for any number T , x.t/ has infinitely many zeros in the interval .T; 1/; or equivalently, for any number , there exists a number > such that x. / D 0. We also call the equation (5.24) oscillatory if it has an oscillatory solution.
We will see below that simple observations about the coefficient p.t/ can give us very interesting and important information about the oscillatory behavior of the solutions of (5.24).

5.7 Oscillatory behavior of solutions 111

First let us consider the special case x00 C k2x D 0

which is the well-known equation for harmonic oscillator. If k is a nonzero constant, then the roots of the characteristic equation are given by m D k i and hence x1 D sin k t and x2 D cos k t are two linearly independent oscillatory solutions.
To start with, let us note that for k D 1, x1 D sin t is a solution of x00 C x D 0 and this solution has exactly one zero in the interval .0; 2 /, namely at t D .
For k D 2, x2 D sin 2t is a solution of x00 C 4x D 0 and it has three zeros in the interval .0; 2 /, one at t D =2, one at t D and one at t D 3 =2.
Based on the above observation, one would estimate that the larger the constant k is, the faster the solutions oscillate. Actually, this happens to be a general fact that
was discovered by Jacques Charles Francois Sturm in 1836, and it has laid the foun-
dation for the theory of oscillation. We now state and prove two beautiful and simple theorems due to Sturm.1
The first theorem below shows that the zeros of solutions are interlaced, that is,
between any two zeros of a given solution, there is a zero of any other linearly inde-
pendent solution. In the constant coefficient case, we see that this is true, since for any k ¤ 0, x1 D sin kt and x2 D cos kt have this property; then it can be verified that all solutions have this property (see Example 5.7.5 below).

Theorem 5.7.1 (Sturm Separation Theorem). Let x1.t/ and x2.t/ be two linearly independent solutions of (5.24) and suppose a and b are two consecutive zeros of x1.t/, with a < b; that is x1.a/ D x1.b/ D 0 and x1.t/ ¤ 0 on .a; b/. Then x2.t/ has exactly one zero in the interval .a; b/.

Proof. Notice that x2.a/ ¤ 0 ¤ x2.b/, otherwise x1 and x2 would have a common zero and hence their Wronskian would be 0 and they could not be linearly independent.
Suppose, by way of contradiction, that x2.t/ ¤ 0 on the open interval .a; b/. Then x2.t/ ¤ 0 on the closed interval OEa; b. Let

h.t/ D x1.t/ : x2.t /

Then h is differentiable on OEa; b and h.a/ D h.b/ D 0. Therefore by Rolle's lemma, there exists a number c, a < c < b, such that h0.c/ D 0. But h0.c/ D 0 implies that

x2.c/x10 .c/ x1.c/x20 .c/ x22.c/

D

0:

This implies that x2.c/x10 .c/ x1.c/x20 .c/ D 0, which in turn implies that the Wronskian of x1.t/ and x2.t/ vanishes at t D c, contradicting their linear independence.

1 Sturm, C.: Mémoire sur les équations différentielles linéaires du second order. J. Math. Pures Appl. 1, 106­186 (1836).

112 5 Second order equations
x
a

x1(t) x2(t)

b t

Fig. 5.8. The zeros of x1.t / and x2.t /

This proves that x2.t/ vanishes in the interval .a; b/. What remains to be shown is that it cannot have more than one zero in this interval. See Figure 5.8.
Suppose that there exist two numbers t1 and t2 in the interval .a; b/ such that x2.t1/ D x2.t2/ D 0. Then by what we have just proved, there would exist a number d between t1 and t2 such that x1.d / D 0, contradicting the fact that a and b are consecutive zeros of x1.t/.

An immediate consequence of this theorem is

Corollary 5.7.2. If (5.24) has one oscillatory solution, then all of its solutions are oscillatory.

Theorem 5.7.3 (Sturm Comparison Theorem). Consider the two equations

x00 C p.t/x D 0; y00 C q.t/y D 0:

(5.25) (5.26)

Suppose that x.t/ is a nontrivial solution of (5.25) with consecutive zeros at x D a and x D b. Assume further that p.t/ and q.t/ are continuous on OEa; b and p.t/ Ä q.t/, with strict inequality holding at least at one point in the interval OEa; b. If y.t/ is any nontrivial solution of (5.26) such that y.a/ D 0, then there exists a number c, a < c < b, such that y.c/ D 0.

Proof. Assume that the assertion of the theorem is false. First of all, we can assume, without any loss of generality, that x.t/ > 0 on the interval .a; b/, otherwise we can replace x.t/ by x.t/ which is also a solution of the same equation and has the same zeros as x.t/. Similarly we can assume that y.t/ > 0 on the interval .a; b/. Multiplying the first equation by y.t/, the second equation by x.t/ and subtracting the resulting second equation from the first equation, we obtain

y.t/x00.t/ x.t/y00.t/ C .p.t/ q.t//x.t/y.t/ D 0:

Since yx00

xy00 D .yx0

xy0

0
/

,

if

we

integrate

the

above

equation

from

a

to

b,

5.7 Oscillatory behavior of solutions 113

we obtain

Zb .yx0 xy0/jab D .q.t/ p.t//x.t/y.t/dt:
a

Since x.a/ D x.b/ D y.a/ D 0, the above equation can be written as
Zb y.b/x0.b/ D .q.t/ p.t/x.t/y.t//dt:
a

(5.27)

Since x.t/ > 0 to the left of b and x.b/ D 0, we must have x0.b/ Ä 0. Furthermore, since y.t/ is continuous and y.t/ > 0 for t to the left of b, we must have y.b/ 0. Therefore, on the left-hand side of (5.27), we have y.b/x0.b/ Ä 0.
Since, by assumption, q.tN/ p.tN/ > 0 for some tN in the interval OEa; b and q.t/ p.t/ is continuous, then it will stay positive on some subinterval of OEa; b containing tN. Since .q.t/ p.t//x.t/y.t/ 0 in OEa; b and .q.t/ p.t//x.t/y.t/ > 0 in some subinterval of OEa; b, it follows from the definition of the Riemann integral that
Zb .q.t/ p.t//x.t/y.t//dt > 0:
a

We have shown that the right-hand side of (5.27) is positive and the left-hand side is less than or equal to 0. This contradiction proves the theorem.

Corollary 5.7.4. All solutions of (5.26) vanish between a and b.
Proof. Let z.t/ be a given solution of (5.26). We have shown that y.t/ vanishes at a and at some number c, a < c < b. By the Sturm Separation Theorem, z.t/ has a zero between a and c and hence between a and b if z and y are linearly independent. If they are linearly dependent, then they are constant multiples of each other and have the same zeros. Since y.t/ has a zero in .a; b/, then so does z.

Example 5.7.5. Show that between any two zeros of cos t there is a zero of 2 sin t 3 cos t.
We recall that sin t and cos t are two linearly independent solutions of x00Cx D 0. In view of the Sturm Separation Theorem, it suffices to show that cos t and .2 sin t 3 cos t/ are linearly independent solutions. Evaluating their Wronskian, we have
W .cos t; 2 sin t 3 cos t/ D 2 sin2 t C 2 cos2 t D 2:

Therefore the two functions are linearly independent.
Example 5.7.6. x1 D et and x2 D .t2 1/e2t cannot be solutions of (5.24) for any continuous function p.t/.
This follows from the fact that t D 1 are two zeros of x2 but x1 has no zero between 1 and 1, contradicting the Sturm Separation Theorem.

114 5 Second order equations
Proposition 5.7.7. If limt!C1 p.t/ > 1, then x00 C p.t/x D 0 is an oscillatory equation.

Proof. Since limt!C1 p.t/ > 1, we can choose a number T such that for t T , p.t/ > 1. Comparing the solutions of x00 C p.t/x D 0 with those of x00 C x D 0, it follows that for t T , every solution of x00 C p.t/x D 0 has a zero between any
two zeros of sin t. The assertion follows from the fact that the zeros of sin t are not
bounded above.

Although, for simplicity, in the above we chose limt!1 p.t/ D 1, the proof shows that for any  > 0, limt!1 p.t/ D  would imply oscillation.

Example 5.7.8. Show that

x00

C

2t6 t6

2t4 C 3t C 3t2 C 1

1 xD0

(5.28)

is an oscillatory equation. Dividing by t6, we see that

2t6 2t4 C 3t 1

lim
t !1

t6 C 3t2 C 1

D 2:

Using the preceding Proposition, we infer that (5.28) is oscillatory.

Theorem 5.7.3 is completed by the following proposition.
Proposition 5.7.9. If p.t/ Ä 0, p.t/ 6Á 0; then no solution of (5.24) can have more than one zero.

Proof. Suppose that (5.24) has a solution x1.t/ with two zeros t1 and t2. Then consider the equation y00Cq.t/y D 0, where q.t/ Á 0, so that y00 D 0. Since q.t/ p.t/ and q.t/ 6Á p.t/, by Corollary 5.7.4, every solution of y00 D 0 has a zero between t1 and t2. This is obviously false, since y Á 1 is a solution of y00 D 0.

A careful examination of the above results shows that there is an obscure assumption that the zeros of solutions of (5.24) are isolated, that is, in any finite interval OE; , there can be only a finite number of them. If this were not the case, then we would not be able to take two consecutive zeros, just as we cannot take two consecutive rational numbers. Recall that t1 and t2 are two consecutive zeros of x.t/ if x.t1/ D x.t2/ D 0 and x.t/ ¤ 0 in .t1; t2/. How do we know that the interval .t1; t2/ does not contain infinitely many zeros of x1.t/ for any number t2 > t1?
We now give a proof of the fact that zeros of solutions of (5.24) are isolated. The proof can be easily followed by readers with adequate knowledge of introductory

5.7 Oscillatory behavior of solutions 115
level Analysis. Those who do not have the proper background may skip the proof and simply note and use this property of the zeros of solutions, when needed.
Definition 5.7.10. A number  is a limit point (or accumulation point) of a set S of real numbers if every open interval containing  contains infinitely many points of the set S .
The following theorem is a special case of a theorem due to Bernard Bolzano and Karl Weierstrass, 1817. It can be found in almost all introductory level Analysis books. We skip the proof of this theorem and ask interested readers to consult an Analysis book.
Theorem 5.7.11 (Bolzano­Weierstrass). Every infinite bounded set of real numbers has a limit point.
Theorem 5.7.12. Let y.t/ be a nontrivial solution of (5.24) and let OEa; b be any closed interval. Then y.t/ has a finite number of zeros in OEa; b.
Proof. Suppose that y.t/ has infinitely many zeros in the interval OEa; b. Let S be the set of zeros of y.t/ in OEa; b. Then by the Bolzano­Weierstrass Theorem, S has a limit point tN, which, by the definition of limit points, cannot be outside the interval OEa; b. By the definition of limit points, for every natural number k, the interval .tN 1= k; tN C 1= k/ contains a point of S distinct from tN, denoted by tk. It is then clear that the sequence .tk / converges to tN as k ! 1.
By Rolle's Lemma, in each interval .tN 1= k; tN C 1= k/, there is a number sk such that y0.sk / D 0. This follows from the fact that the interval .tN 1= k; tN C 1= k/ contains infinitely many zeros of y; applying Rolle's lemma to any two zeros of y in this interval will give us a number sk where y0 vanishes. Again, it is clear that the sequence .sk/ converges to tN as k ! 1.
It follows from continuity of y.t/ and y0.t/ that y.tk / ! y.tN/ and y0.sk/ ! y0.tN/. Now, since for each k, y.tk / D y0.sk/ D 0, it follows that y.tN/ D y0.tN/ D 0.
Since z.t/ Á 0 is also a solution of (5.24) satisfying the initial conditions z.tN/ D z0.tN/ D 0, it follows from the uniqueness of solutions that y.t/ Á 0, contradicting the assumption that y.t/ is nontrivial.

We wish to point out an important fact concerning the results in this section and that is the fact that studying equations of the form (5.24) instead of

x00 C p.t/x0 C q.t/x D 0

(5.29)

is not a great disadvantage. This is because any equation of the form (5.29) can be transformed into an equation of the form (5.24) by making the substitution

x.t/ D y.t/e

1 2

R

p.t /dt

assuming that p0.t/ and q.t/ are continuous. Notice that x.t/ and y.t/ have the same set of zeros. The proof is left as an exercise.

116 5 Second order equations
5.8 Some nonlinear second order equations

In this section we briefly deal with some special classes of nonlinear second order equations that can be solved by a reduction of the order.

5.8.1 Equations of the type F.t; x0; x00/ D 0

Consider the equation

F .t; x0; x00/ D 0

(5.30)

where the dependent variable x is missing. We let z D x0 and get z0 D x00, and we find F .t; z; z0/ D 0 which is a first order
equation. If z.t/ D .t; c/ is a family of solutions of this equation, then integrating x0 D z D .t; c/ we find
Z x.t/ D .t; c/dt C c0

which is a solution of F .t; x0; x00/ D 0, for all c0 2 R.

Example 5.8.1. Solve the initial value problem x00 D 2tx0, x.0/ D 0; x0.0/ D 1.

The equation x00 D 2tx0 is of the form (5.30). Setting z D x0 we reduce the prob-

lem to the first order separable equation z0 D 2tz. Then z.t/ D c et2. For t D 0

from x0.0/ Integrating,

D z.0/ we find

D1 x .t /

iDt foRl0ltoewt2sdtht awt h1icDh

c. Since x0 D z we find x0.t/ D et2 . takes into account the initial condition

x.0/ D 0.

5.8.2 Equations of the type F.x; x0; x00/ D 0

Consider the equation

F .x; x0; x00/ D 0

(5.31)

where the independent variable t is missing. As in Example 5.1.6, we let z D x0. But now we use the Chain Rule, obtaining

x00 D

dx0

D

dz

D

dz

dx

Dz

dz :

dt dt dx dt dx

(5.32)

Substituting in Equation (5.31), we obtain the first order equation

F .x; z; z dz / D 0: dx

(5.33)

Let z D .x; c1/ be a family of solutions of (5.33), depending on a constant c1. Then

from z D x0 we infer

dx D dt

.x; c1/

5.8 Some nonlinear second order equations 117

which is a separable equation that can be integrated. Assuming that

vanishes we obtain solutions of (5.31) in the form

Z

dx .x; c1/

D

t

C

c2;

c2 2 R:

.x; c1/ never

An important class of equations that can be solved using the preceding method is

x00

D

f .x/. In this case

we find the

separable equation

z

dz dx

D

f .x/ that can be

in-

tegrated. Equations like x00 D f .x/ will be discussed more extensively in Chapter 8.

Example 5.8.2. Solve x00 D 2xx0; x.0/ D 0; x0.0/ D 1. The equation x00 D 2xx0

is of the form (5.31). We let z D x0 and then using the Chain Rule, we have x00 D

dz dt

D

dz dx dx dt

D

z

dz dx

.

Now

we

have

reduced

the

problem

to

solving

the

first

order

equation

dz z D 2xz:
dx

One solution is z Á 0, but it does not satisfy the initial condition z.0/ D 1. Dividing

by z, we find

dz dx

D

2x, hence

z.x/

D

x2

C c1.

For x

D

0

we have z.0/

D

1 and

hence c1 D 1. The problem becomes x0 D x2 C 1 with x.0/ D 0. Integrating we

find

Z

dx

x2 C 1 D t C c2

namely arctan x D t C c2. The initial condition x.0/ D 0 yields c2 D 0. Thus arctan x D t and finally x.t/ D tan t, jtj < 2 .

5.8.3 Equations of the form F.t; x; x0; x00/ D 0 with F homogenous

Consider the equation

F .t; x; x0; x00/ D 0

(5.34)

where F is a homogeneous function of degree k with respect to x; x0; x00, namely
F .t; x; x0; x00/ D k F .t; x; x0; x00/, for all 2 R for which k makes sense. The homogeneity of F suggests to try to find solutions such that x0 D xz. Setting
x0.t/ D x.t/z.t/ we find x00 D zx0 Cxz0 D xz2 Cxz0 and hence F .t; x; x0; x00/ D 0 yields F .t; x; xz; xz2 C xz0/ D 0. Using the homogeneity of F one finds

F .t; x; xz; xz2 C xz0/ D xkF .t; z; z2 C z0/;

yielding the first order equation
F .t; z; z2 C z0/ D 0:
For example, if the given equation is x00 D f .t; x; x0/ and f is homogeneous of degree 1 with respect to x; x0, we find z2 C z0 D f .t; z/.

118 5 Second order equations
If .t; c1/, c1 2 R, is a family of solutions of F .t; z; z2 C z0/ D 0, then x0.t/ D x.t/ .t; c1/ yields x.t/ D c2 e .t;c1/, c2 2 R. To this two parameter family of solutions we have to add the trivial solution x.t/ Á 0.
If we want to solve the initial value problem
F .t; x; x0; x00/ D 0; x.t0/ D x0 6D 0; x0.t0/ D x1;
then from x.t/ D x0.t/z.t/ we infer x1 D x0z.t0/ that is z.t0/ D x1=x0. So we have to solve the ivp F .t; z; z2 C z0/ D 0, z.t0/ D x1=x0.

Example 5.8.3. Solve xx00 x02 2tx2 D 0; x.0/ D 1; x0.0/ D 0:
Here F .t; x; x0; x00/ D xx00 x02 2tx2 is homogeneous of degree 2. Setting x0 D xz we find x00 D xz2 C xz0. Hence
x.xz2 C xz0/ x2z2 2tx2 D 0 and canceling x2z2, we get x2z0 2tx2 D 0, namely

x2.z0 2t/ D 0:

Notice that in the present case, the trivial solution x.t/ Á 0 does not satisfy the initial condition x.0/ D 1. The general integral of the first order equation z0 2t D 0 is z D .t; c1/ D t2 C c1. For t D 0, one has z.0/ D x0.0/ D 0 and hence c1 D 0. Then z.t/ D t2 and x0 D xz yields the separable equation

x0 D t2x

H)

x .t /

D

c2

e

1 3

t3

:

Using the initial condition x.0/ D 1, we obtain c2 D 1. Thus

x .t

/

D

e

1 3

t3

is the solution we were seeking.

For second order equations one can consider problems like x00 D f .t; x; x0/; x.a/ D ; x.b/ D ;

that are called boundary value problems because we require that the solution assumes some given values for t at the boundary of the interval OEa; b.
One can also take the interval to be all the real line and seek solutions that have a prescribed limit as t ! 1. Problems of this kind related to the equation x00 D f .x/ will be discussed in Chapters 8 and 13.

5.9 Exercises 119

5.9 Exercises

A. Linear independence and Wronskian

A1. Show that x1 D t3 t2 and x2 D t3 3t are linearly independent. A2. Consider the functions f .t/ D sin t and g.t/ D t2.
a) Using the definition of linear independence, explain why they are linearly independent.
b) Using a Wronskian argument, explain why they are linearly independent. c) Explain why they cannot be solutions of a differential equation x00 C
p.t/x0 C q.t/x D 0, where p and q are continuous functions. A3. Show that if x1 and x2 are linearly independent, then so are their linear com-
binations z1 D 2x1 C 3x2 and z2 D 2x1 3x2. A4. a) Prove that if the Wronskian of two differentiable functions f .t/ and g.t/,
not necessarily solutions of differential equations, is nonzero at one point of an interval I , then they are linearly independent. b) Prove that if they are linearly dependent, then their Wronskian is identically equal to 0. A5. Show that x1 D tan t and x2 D sin t are linearly independent on the interval .0; /. A6. Solve the initial value problem
W .t2 C 1; f .t// D 1; f .0/ D 1:

A7. Show that if x1.t/ and x2.t/ are two linearly independent functions, and z.t/

is a function such that z.t/ > 0 on I , then zx1 and zx2 are also linearly inde-

pendent on I .

A8. Give an example to show that the following statement is false: if two func-

tions f1 and f2 are linearly independent in an interval I , then they are also

independent in any subinterval J of I .

A9. Show that if x1 and x2 are linearly dependent on an interval I , then they are

linearly dependent in any subinterval J of I .

A10. Show that if two solutions of a second order homogeneous differential equa-

tion with continuous coefficients on I have a common zero then all their zeros

are in common.

A11.

Let x1 and x2 be two solutions of x00 C

x0 t

C q.t/x

D 0;

t

> 0, where q.t/ is

a continuous function. Given that W .6/ D 7, find W .7/.

B. Homogeneous equations with constant coefficients
Solve each of the following: B1. 2x00 C x0 x D 0. B2. x00 C 2x0 C 2x D 0. B3. x00 C 8x0 C 16x D 0.

120 5 Second order equations
B4. x00 C 2x0 15x D 0; x.0/ D 1; x0.0/ D 1. B5. x00 3x0 C 2x D 0; x.1/ D 0; x0.1/ D 1. B6. 4x0 C 2x00 D 5x; x.0/ D 0; x0.0/ D 1. B7. x00 6x0 C 9x D 0; x.0/ D 0; x0.0/ D 1. B8. Show that for  0, x00 C x0 x D 0 will always have some solutions that
do not approach 0 as t ! C1.
B9. For which values of  will all solutions of
x00 C x0 x D 0
go to 0 as t goes to 1? B10. Show that all the solutions of x00 C 4x0 C kx D 0 go to 0 as t ! C1 if and
only if k > 0. B11. Show that the equation x00 C bx0 C cx D 0 has infinitely many solutions and
none of them, except the trivial solution, can have a maximum or a minimum point on the t-axis.
B12. Find a second order linear homogeneous equation whose corresponding characteristic equation has m D 3 7i as one of its roots.
B13. Show that any solution of x00 C 5x0 C 6x D 0 tends to zero as t ! C1. B14. Show that if p > 0 then any solution of x00 C px0 D 0 tends to a constant as
t ! C1, while if p < 0 only constant solutions tend to constants. B15. Find a such that the solution of x00 C x0 2x D 0, x.0/ D a; x0.0/ D 1 tends
to zero as t ! C1. B16. Show that all solutions of x00 2x0 C 2x D 0 are bounded on . 1; 0, and
unbounded on as OE0; 1/. B17. Find conditions on a; b such that the solutions of x00 2ax0 C bx D 0 are
oscillating functions. B18. Find D6 0 such that the boundary value problem x00 C 2x D 0, x.0/ D
x. / D 0, has nontrivial solutions. B19. Find a D6 b such that the boundary value problem x00 C x D 0, x.a/ D x.b/ D
0, has nontrivial solutions. B20. Show that the boundary value problem x00 x D 0, x.0/ D x.1/ D 0, has
only the trivial solution. B21. Show that the problem x00 C x0 2x D 0, x.0/ D 0, limt!C1 x.t/ D 0 has
only the trivial solution x.t/ D 0. B22. Solve x00 2x0 C 5x D 0, x.0/ D 1, x. =4/ D 0. B23. Find Â such that x00 2x0 C 5x D 0, x.0/ D 0, x0.Â / D 0, has only the trivial
solution. B24. Solve x00 C 2x0 D 0, x.0/ D 0, limt!C1 x.t/ D a.

5.9 Exercises 121
C. Nonhomogeneous equations with constant coefficients
C1. Solve x00 4x D t. C2. Solve x00 4x D 4t 2. C3. Solve x00 C x D t2 2t. C4. Solve x00 C x D 3t2 C t. C5. Solve x00 x D e 3t . C6. Solve x00 x D 3e2t . C7. Solve x00 x D t e2t . C8. Solve x00 3x0 x D t 2 C t. C9. Solve x00 4x0 C 13x D 20et . C10. Solve x00 x0 2x D 2t C et . C11. Solve x00 C 4x D cos t. C12. Solve x00 C x D sin 2t cos 3t. C13. Solve x00 C 2x0 C 2x D cos 2t. C14. Solve x00 C x D t sin 2t. C15. Solve x00 x0 D t. C16. Solve x00 x D ekt , k 2 R. C17. Solve x00 x0 2x D 3e t . C18. Solve x00 3x0 C 2x D 3tet . C19. Solve x00 4x0 C 3x D 2et 5e2t .
p C20. Solve x00 C 2x D cos 2 t. C21. Solve x00 C 4x D sin 2t. C22. Solve x00 C x D 2 sin t C 2 cos t. C23. Solve x00 C 9x D sin t C sin 3t. C24. Solve the boundary value problem x00 x D t, x.0/ D x.1/ D 0. C25. Find k such that the solution of x00 C 4x0 C x D k, x.0/ D 0; x0.0/ D 0 tends
to 1 as t ! C1.
C26. Show that if D6 0 and h.t/ > 0 then any (possible) nontrivial solution of the boundary value problem x00 2x D h.t/, x.a/ D x.b/ D 0 cannot be non negative in .a:b/.
C27. Show that for all a D6 0 the boundary value problem x00 2x D 2et, x.0/ D x.a/ D 0, has a unique solution.

122 5 Second order equations

D. Miscellanea D1. Show that

x00

C

t5 t4

C C

1 x
5

D

0

is an oscillatory equation.

D2. Which one of the following two equations has solutions that oscillate more

rapidly?

p x00 C t6 C 3t5 C 1 x D 0;

x00 C 2t3x D 0:

D3. Explain why no nontrivial solution of (5.24) can vanish at each of the numbers 0; 1; 1=2; 1=3; : : :1=n : : :.

D4. Consider the boundary value problem x00 p.t/x D q.t/; x.a/ D x.b/ D 0:

Show that if p.t/ and q.t/ are continuous, with p.t/ > 0, on the interval OEa; b,

then there is a unique solution of this boundary value problem.

D5. Show that, assuming that p0.t/ and q.t/ are continuous, the substitution

x.t/ D y.t/e

1 2

R

p.t /dt

transforms the equation x00 C p.t/x0 C q.t/x D 0

into the form (5.24).

D6. Determine the oscillation of x00 C x0 C x D 0

in two ways (a) by transforming it to the form x00 C p.t/x D 0,
(b) by solving the equation explicitly.

D7. Determine the oscillation of

x00 1 tx0 C x D 0: 4

D8. Let u00 C p1.t/u D 0 and v00 C p2.t/v D 0, with v.t/ 6D 0 in OEa; b.

(a) Prove the Picone Identity

u .u0v v

uv0/Á0 D .p2

p1/u2 C u0

v0 u Á2 : v

b) Use this to prove the Sturm comparison theorem.

D9. Let u00 C p1.t/u D 0 and v00 C p2.t/v D 0 with p2.t/ > p1.t/ in .a; b/. Suppose that u.a/ D v.a/ D 0, u0.a/ D v0.a/ D  > 0. Show that there
exists > 0 such that v.t/ > u.t/ in .a; a C /.

5.9 Exercises 123
D10. Solve the initial value problem x00 D x0 , x.1/ D 0, x0.1/ D 1. t
D11. Solve x00 D 2x0.x 1/, x.0/ D 0, x0.0/ D 1. D12. Solve x00 D 2x03x. D13. Solve xx00 2x02 x2 D 0. D14. Solve .a/ xx00 x02 C et x2 D 0, x.0/ D 1, x0.0/ D 1, and .b/ xx00 x02 C
et x2 D 0, x.0/ D 1, x0.0/ D 1: D15. Solve the Euler equation t2x00 2x D 0; t > 0. D16. Solve t2x00 C atx0 C x D 0, t > 0. D17. Solve t2x00 tx0 3x D 0; x.1/ D 0; x0.1/ D 1, t > 0. D18. Solve the nonhomogeneous Euler equation t2x00 C tx0 C x D t; t > 0. D19. Solve t2x00 C 3tx0 3x D t 2; t > 0: D20. Show that a solution of x00 tx0 C 3x D 0 is a polynomial P of degree 3.

6 Higher order linear equations

6.1 Existence and uniqueness

Almost everything we learned in Chapter 5 about second order equations can be easily seen to be true for the corresponding higher order equations. Therefore, in order to avoid unnecessary repetition, here, for the most part, we simply state the more general results and give examples. In a few cases, when the generalizations are not so obvious, we will provide the explanations and proofs.
First we state the existence and uniqueness theorem, which follows from Theorems 4.2.2 and 4.2.3 in Chapter 4.

Theorem 6.1.1. Consider the equation

p0.t /x.n/.t / C p1.t /x.n 1/.t / C : : : C pn.t /x.t / D f .t /;

.6:1/

where the coefficient functions pi .t/, 0 Ä i Ä n, and f .t/ are continuous on a given interval I Â R, with p0.t/ ¤ 0. Then for any number t0 in I , there exists a unique solution x.t/ of .6:1/ satisfying the initial conditions

x.t0/ D 1; x0.t0/ D 2; : : : ; x.n 1/.t0/ D n;

where i ; 1 Ä i Ä n are any real numbers. Furthermore, this solution exists for all t in I .

In equation .6:1/, we normally take the leading coefficient p0.t/ to be equal to one, which is the same as dividing the equation by p0.t/. The above theorem treats the most general linear nonhomogeneous equation. If we take f .t/ Á 0, we have the existence and uniqueness theorem for the most general linear homogeneous equation.

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_6

126 6 Higher order linear equations
6.2 Linear independence and Wronskian

Similar to the case for second order equations, functions f1; f2; : : : ; fn are said to be linearly independent on an interval I if for any n constants c1; c2; : : : ; cn, c1f1.t/ C c2f2.t/ C : : : C cnfn.t/ Á 0, t in I , implies that c1 D c2 D : : : D cn D 0. Functions that are not linearly independent are said to be linearly dependent, i.e. they are linearly dependent if there exist constants ci , 1 Ä i Ä n, not all 0, such that c1f1.t / C c2f2.t / C : : : C cnfn.t / Á 0.
We recall that linear dependence had an easy and very useful characterization in the second order case, that is two functions are linearly dependent if and only if one of them is a constant multiple of the other. For higher order equations, an analogous statement would be that n functions are linearly dependent if and only if any one of them is a linear combination of the others, which is not as useful as in the second order case. However, it is useful to know that if any subset of two or more of a given set of n functions are linearly dependent, then all n of them are linearly dependent. The converse is, of course, false.

Expample 6.2.1. The functions f1.t/ D sin t; f2.t/ D cos t; f3.t/ D et ; f4.t/ D 2 sin t apre linearly depenpdent since f1 and f4 are lineaprly dependent. We note that since . 2p/ sin t C .1/ 2 sin t Á 0, we can write . 2/ sin t C .0/ cos t C .0/ et C .1/ 2 sin t Áp0, which satisfies the definition of linear dependence of f1; f2; f3; f4 with c1 D 2; c2 D 0; c3 D 0; c4 D 1.

We now extend the notion of the Wronskian to n functions and write

W .f1; f2; : : : ; fn/.t / D f1.ffn110:::..1tt///.t /

f2.t / f20.t /
f2.n 1/.t /

fn fn0
fn.n

.t / .t /
1/ .t

/

:

Theorem 6.2.2 (Abel's Theorem). If x1; x2; : : : ; xn are solutions of

x.n/.t / C p1.t /x.n 1/ .t / C : : : C pn.t /x.t / D 0

.6:2/

on some interval I , where the coefficients pi , 1 Ä i Ä n, are continuous, then
R
W .x1; x2; : : : ; xn/.t / D c e p1.t/dt :

As a consequence, W .x1; x2; : : : ; xn/.t/ is either identically zero or it never vanishes.

We give the proof for n D 3. The proof for higher order equations is identical but cumbersome.

6.3 Constant coefficients 127

Proof. Using the formula for the derivative of a determinant and the fact that xi000 D p1xi00 p2xi0 p3xi , i D 1; 2; 3, we have

W 0.t /

D

d dt

xxx111000

x2 x20 x200

xxx333000 D xxx1110000

x20 x20 x200

xxx3330000 C xxx1110000

x2 x200 x200

xxx3330000 C xxx1011000

x2 x20 x2000

xxx3033000 D

D  p1x100

x1 x10 p2x10

p3x1

p1 x200

x2 x20 p2x20

p3x2

p1x300

x3 x30 p2x30

p3x3 :

Now, if we multiply the first row in the last determinant by p3 and add it to the

third row and then multiply the second row by p2 and add it to the third row, we

obtain

W 0.t/ D 

x1 x10 p1x100

x2 x20 p1 x200

pxx1330x300 D

p1.t/W .t/:

This shows that W 0 C p1.t/W D 0. Solving this linear first order equation for W , the assertion of the theorem follows.

We now summarize some obvious generalizations of the second order equations. 1. Any linear combination x.t/ D c1x1.t/ C c2x2.t/ C : : : C cnxn.t/ of solutions
x1; x2; : : : xn of (6.2) is also a solution. 2. The Wronskian of solutions of (6.3) is either always zero or it is never zero in the
interval where the solutions are defined.
3. If the Wronskian of arbitrary functions f1; f2; : : : ; fn is different from zero at one point of an interval where it is defined, then the functions are linearly independent on that interval. The contrapositive statement would be that if they are linearly dependent, then their Wronskian is identically equal to zero.
4. If x1; x2; : : : ; xn are solutions of (6.2), then they are linearly independent if and only if their Wronskian is different from zero.
5. If x1; x2; : : : ; xn are solutions of (6.2), whose Wronskian is different from zero, then they are a fundamental set of solutions, that is,
x D c1x1 C c2x2 C : : : C cnxn
is the general solution of (6.2).

6.3 Constant coefficients

Consider

x.n/ C a1x.n 1/ C : : : C anx D 0;

(6.3)

128 6 Higher order linear equations

where ai , 1 Ä i Ä n, are constant real numbers. As in the case of second order equations, in order to solve (6.3) we substitute x D emt in the equation, which gives rise
to the characteristic (or auxiliary) equation

C.m/ D mn C a1mn 1 C : : : C an D 0:

The biggest difference between the second order equations with constant coefficients and the more general equations is that for the second order, we could always solve the characteristic equation by the Quadratic Formula, whereas for the more general case there is no method by which we can explicitly solve the above characteristic equation. Nevertheless, reducing the original differential equation to an algebraic equation is still simpler to deal with and has important theoretical implications.
The following is a summary of the extensions. We give proofs when the extensions do not follow from arguments similar to those given in the second order case.

Theorem 6.3.1. (i) Let m1; m2; : : : ; mr be the distinct roots of the characteristic
equation corresponding to .6:3/, and let qi represent the multiplicity of mi . Then tkemit is a solution for k D 1; : : : ; qi 1.
(ii) The solutions tkemit ; k D 0; 1; : : : ; qi 1I i D 1; 2; : : : ; r are linearly in-
dependent.

We prove this theorem for n D 3. Suppose that the characteristic equation m3 C a1m2 C a2m C a3 D 0 has distinct

roots m1; m2; m3. First of all, it is easy to check the fact that em1t ; em2t ; em3t are solutions of

the given differential equation. To show that they are linearly independent, we sup-

pose, by contradiction, that there exist constants c1; c2; c3, not all zero, such that c1em1t C c2em2t C c3em3t D 0. Suppose, without loss of generality, c3 ¤ 0. Then multiplying both sides of the equation by e m1t , we obtain c1 C c2e.m2 m1/t C c3e.m3 m1/t D 0: Taking the derivative of both sides and multiplying by em1t , we get c2.m2 m1/em2t C c3.m3 m1/em3t D 0. We multiply both sides by e m2t , obtaining c2.m2 m1/ C c3.m3 m1/e.m3 m2/t D 0. Taking the derivative again and multiplying both sides by em2t , we have c3.m3 m1/.m3 m2/em3t D 0. Since
m1; m2; m3 are all distinct, i.e. not equal to each other, we must have c3 D 0, which

is a contradiction.

An alternate proof of linear independence consists of using Abel's theorem. Let W .t / be the Wronskian of em1t ; em2t ; em3t . One has

W .t/

D

mme121mee1mmt11

t t

e m2 t m2em2t m22em2t

e m3 t m3em3 m23em3

t t



:

For t D 0 one has

W .0/ D mm1211

1 m2 m22

mm1233 :

6.3 Constant coefficients 129

Multiplying the first row by m1 and adding it to the second row, and multiplying
the first row by m21 and adding it to the third row one obtains W .0/ D .m3 m2/.m3 m1/.m2 m1/. Since mi 6D mj if i 6D j , then W .0/ D6 0 proving that em1t ; em2t ; em3t are linearly independent.

Next, suppose that one of the roots is a simple root and one of them is a double

root. Without loss of generality, assume that m1 is a simple root and m2 is a double root. To show that the corresponding solutions em1t ; em2t ; tem2t are linearly inde-
pendent, we show that their Wronskian at t D 0 is nonzero.

W .t / D mme112mee1mmt11tt

e m2 t m2em2t m22em2t

2

t em2t em2t C t m2em2t m2em2t C t m22em2t



and hence

W .0/ D mm1211

1 m2 m22

2m01 2 D mm222

2m1 2

mm112 2m1 2

D 2m22 m22 2m1m2 C m12 D m22 2m1m2 C m21 D .m2 m1/2 6D 0:

Finally, suppose that the characteristic equation has one triple root m1, i.e. .m m1/3 D 0 is the characteristic equation. Again, we show that the Wronskian of the corresponding solutions emt ; temt t2emt is nonzero at t D 0:

W .t / D mme2ememmt tt

temt emt C mtemt m2t emt C 2memt

m2t

2

t2emt mt2emt C 2temt emt C 4mtemt C

2

em

t



;

W .0/ D mm12

0 1 2m

002 D 2:

Example 6.3.2. Given that 1; 2; 56i; 56i are the roots of the characteristic equa-
tion, the general solution of the corresponding differential equation can be determined to be x D c1et Cc2e2t Cc3e5t sin 6t Cc4e5t cos 6t Cc5t e5t sin 6t Cc6t e5t cos 6t .

Example 6.3.3. Find the general solution of the differential equation x0000 C 4x D 0

which has application to the vibrating rod problem.
In order to solve this equation, we need to find all the roots of the characteristic equation m4 C 4 D 0, which is equivalent to finding the fourth roots of the num-

130 6 Higher order linear equations

ber 4. For this we use de Moivre's formula.

.

4/1=4

D

p 2.

1/1=4

D

p 2

OEcos.

C 2n

/ C i sin.

C 2n

/1=4 D

ph

nÁ

n Ái

2 cos C C i sin C

:

42

42

Letting n D 0; 1; 2; 3, we obtain the roots m D 1 C i; 1 C i; 1 i; 1 i . Therefore, the general solution of the differential equation x0000 C 4x D 0 is x.t/ D et .c1 sin t C c2 cos t/ C e t .c3 sin t C c4 cos t/:

6.4 Nonhomogeneous equations

The following theorem shows that, as with the second order equations, in order to find the general solution of the nonhomogeneous equation .6:1/, we need the general solution of the homogeneous equation .6:2/ and one solution of the nonhomogeneous equation. The proof is similar to the case for the second order equations.
Theorem 6.4.1. If y D c1x1 C c2x2 C : : : C cnxn is the general solution of the homogeneous equation .6:2/ and xp is any solution of the nonhomogeneous equation .6:1/, then x D y C xp is the general solution of .6:1/.
As in the second order case, we may use the method of Variation of Parameters or Undetermined Coefficients to find a particular solution of the nonhomogeneous equation. These methods are straightforward generalizations of the second order equations.

Method of Variation of Parameters. In using the method of Variation of Parameters, given that x1; x2; : : : ; xn are linearly independent solutions of .6:2/, one finds functions v1; v2; : : : ; vn such that xp D v1x1 C v2x2 C : : : C vnxn is a solution of .6:1/. This is accomplished by solving the following system of n equations for v10 ; : : : ; vn0 and then integrating each:
v10 x1 C v20 x2 C : : : C vn0 xn D 0 v10 x10 C v20 x20 C : : : C vn0 xn0 D 0 v10 x100 C v20 x200 C : : : C vn0 xn00 D 0 ....................................... v10 x1n 1 C v20 xn 1 C : : : C vn0 xnn 1 D f .t /
Now we give an illustrative example of this method.

Example 6.4.2. Use the method of Variation of Parameters to find the general solu-

tion of

x000 x00 C x0 x D et :

6.4 Nonhomogeneous equations 131

First we find the general solution of the homogeneous equation

x000 x00 C x0 x D 0:

In order to do so, we find the roots of the characteristic equation m3 m2 Cm 1 D 0. This equation can be factored as .m 1/.m2C1/ D 0, yielding the roots m D 1; i; i ;
which in turn gives us the general solution of the homogeneous equation to be y.t/ D c1et C c2 sin t C c3 cos t .
In order to find a particular solution of the nonhomogeneous equation, we set xp D v1et Cv2 sin t Cv3 cos t and require that the functions v1, v2, v3 satisfy the following
equations:

et v10 C .sin t / v20 C .cos t / v30 D 0; et v10 C .cos t / v20 .sin t / v30 D 0; et v10 .sin t / v20 .cos t / v30 D et :

Solving for v10 ; v20 ; v30 , we obtain v10

D

1 2

;

v20

D

1 2

.e

t

sin t

C

et

cos t /; v30

D

1 2

.et

cos

t

et sin t/. Integrating, we have

Ä

1

v1

D

t; 2

v2 D

1 1 et .sin t 22

cos t/ C 1 et .sin t C cos t/ D 1 et sin t

2

2

Ä

v3 D

1 1 et .sin t C cos t/ 22

1 et .sin t 2

cos t/ D

1 et cos t: 2

Consequently,

xp

D

1tet 2

1 et sin2 t 2

1 et cos2 t D 1 t et

2

2

1 et D 1 et .t 22

1/

and the general solution of the given nonhomogeneous equation is x.t/ D c1et C

c2

sin

t

C

c3

cos

t

C

1 2

et

.t

1/:

Method of Undetermined Coefficients. Recall that this method depends on making

a good guess and can be much simpler, when it works.

At first glance, it seems reasonable to try xp D aet and determine a so that xp

satisfies the equation x000 x00 C x0 x D et . But when we substitute, we get 0

on the left side. This is because aet is a solution of the corresponding homogeneous

equation. So, we try xp D at et . Then setting xp000 xp00 C xp0 xp D et , we obtain

2aet

D

et,

which

gives

a

D

1 2

.

Thus

xp

D

1 2

t

et

.

Remark 6.4.3. Notice that the answer we got by the second method is not the same as the one we got by using the first method. This should not be surprising since we were only asking for solutions without specifying any initial values. There are infinitely many solutions of the nonhomogeneous equation because each initial value problem has a unique solution.

132 6 Higher order linear equations

Also, if we think about it, the solution we got by using the first method can be

reduced

to

the

one

we

got

by

using

the

second

method.

This

is

because

1 2

e

t

.t

1/ D

1 2

t

e

t

1 2

e

t

and

hence

x .t /

D

c1et

C c2 sin t

C c3 cos t

C

1 2

e

t

.t

1/ becomes

x.t/ D .c1

1 2

/et

C

c2

sin

t

C

c3

cos

t

C

1 2

et

:

Calling

c10

D

c

1 2

,

we

find

x .t /

D

c10 et

C

c2

sin

t

C

c3

cos t

C

1 2

e

t

.

Example 6.4.4 (The Euler­Bernoulli beam equation). As an important problem

where higher order equations arise, we discuss the Euler­Bernoulli theory of the

(static) bending of an elastic uniform beam. According to this theory, the cross sec-

tions of the beam under deflection remain plane and normal to the deflected centroid

axis of the beam. See Figure 6.1. Experience shows that this assumption is realistic

at least for small deflections. The internal forces acting on each cross section keep

attached the two parts in which the section divides the beam. One finds that the deflection of the beam z D z.x/ satisfies the 4th order equation

d2 Â dx2 EI

d 2z dx2

Ã

D

f

.x/;

where E is the elastic Young's modulus of the beam, I is the second moment of area, f .x/ is the distributed load. Note that here x is the independent variable and z the dependent one. If both EI and f .x/ D are constant, we find

EI

d 4z dx4

D

:

The characteristic equation is m4 D 0 whose root is m D 0, with multiplicity 4. Thus the general solution is z.x/ D c1 C c2x C c3x2 C c4x3 C zp where zp.x/ is a partic-

0

x

z(x)

Fig. 6.1. The elastic beam

6.5 Exercises 133
ular solution of the equation. It is easy to check that we can take zp.x/ D 24EI x4. Then
z.x/ D c1 C c2x C c3x2 C c4x3 C 24EI x4: If we prescribe the deflection of the beam and its slope at the endpoint x D 0 to be zero, we have to impose the conditions
z.0/ D z0.0/ D 0
which yield c1 D c2 D 0 and hence
z.x/ D c3x2 C c4x3 C 24EI x4:
6.5 Exercises
1. Find the general solution of 2x000 D 0. 2. Find the general solution of x000 x0 D 0. 3. Find the general solution of x000 C 5x0 6x D 0. 4. Find the general solution of x000 4x00 C x0 4x D 0. 5. Find the general solution of x000 3x00 C 4x D 0. 6. Find the solution to the initial value problem x000 C 4x0 D 0; x.0/ D 1; x0.0/ D
1, x00.0/ D 2. 7. Find the solution of x000 x0 D 0 satisfying x.0/ D 1 and limt!C1 x.t/ D 0. 8. Find the solution of x000 x0 D 0, x.0/ D 0, x0.0/ D 0, x00.0/ D 1.
9. Solve the initial value problem
x000 C x00 2x D 0; x.0/ D 0; x0.0/ D 0; x00.0/ D 1:
10. Show that there exists a solution of x000 C ax00 C bx0 C cx D 0 such that limt!C1 x.t/ D 0, provided c > 0.
11. Show that for 0 < k < 2 the equation x000 3x0 C kx D 0 has a unique solution such that x.0/ D 1 and limt!C1 x D 0.
12. Find the general solution of x0000 6x00 C 5x D 0. 13. Find the solution of x0000 x D 0, x.0/ D 1; x0.0/ D x00.0/ D x000.0/ D 0. 14. Find the solutions of x0000 x00 D 0, x.0/ D 1; x00.0/ D 0. 15. Find the solution x.t/ of x0000 4x00 C x D 0 such that limt!C1 x.t/ D 0 and
x.0/ D 0; x0.0/ D 1. 16. Show that the only solution of x0000 8x000 C 23x00 28x0 C 12x D 0, such that
limt!C1 x.t/ D 0, is the trivial solution x.t/ Á 0.

134 6 Higher order linear equations
17. Show that x0000 C 2x00 4x D 0 has one periodic solution such that x.0/ D 1; x0.0/ D 1.
18. Find the general solution of x.5/ x0 D 0. 19. Find the general solution of x.5/ C x0000 x0 x D 0. 20. Show that x.5/ C x D 0 has at least one solution such that limt!C1 x.t/ D 0. 21. Find the general solution of x.6/ x00 D 0. 22. Find the general solution of x.6/ 64x D 0. 23. Find the general solution of x0000 C 3x000 C 2x00 D et
(a) by the method of Variation of Parameters, (b) by the method of Undetermined Coefficients. 24. Find the general solution of x000 C 4x0 D sec 2t. 25. Solve x000 x00 D 1. 26. Solve x000 x0 D t, x.0/ D x0.0/ D x00.0/ D 0. 27. Solve x0000 C x000 D t , x.0/ D x0.0/ D x00.0/ D 0.
28. Explain whether the functions
5; t; t2; t3; sin t; 3 t 2; cos t; et ; e t
are linearly dependent or independent. 29. Explain why x.t/ D sin t5 cannot be a solution of a fourth order linear homoge-
neous equation with continuous coefficients. 30. Evaluate W .t; t2; t3; sin t; cos t; t4; et ; e t ; t4 t2/. 31. Consider x0000 3x000 C 2x0 5x D 0. If x1; x2; x3; x4 are solutions and
W .x1; x2; x3; x4/.0/ D 5, find W .x1; x2; x3; x4/.6/. 32. Explain why et ; sin t; t cannot be solutions of a third order homogeneous equa-
tion with continuous coefficients. 33. Solve t 3x000 C 4t 2x00 C 3tx0 C x D 0; t > 0. 34. Show that if x1.t/ satisfies the equation x000 C p1.t/x00 C p2.t/x0 C p3.t/x D 0,
then the substitution x D vx1 reduces the order of the equation from 3 to 2.

7 Systems of first order equations

7.1 Preliminaries: A brief review of linear algebra

In this preliminary section we recall some facts from Linear Algebra, mainly concerning matrices and vectors. We limit ourselves to discuss only the topics that will be used in this book. For more details and further developments we refer to any book on Linear Algebra, such as the one by H. Anton and C. Rorres (see References).

7.1.1 Basic properties of matrices

A matrix .aij /; 1 Ä i Ä n; 1 Ä j Ä m, is a rectangular array displayed as

0

1

a11 a12

a1m

BBB@a2::: 1 a22

a2m ACCC

an1 an2

anm

where the real number aij (we consider here only matrices with real entries) is the

element belonging to the i th row and j th column. Such a matrix is said to be n m,

where n refers to the number of rows and m refers to the number of columns. An n 1

matrix is called a column vector while a 1 n matrix is called a row vector . We shall

be mostly interested in n n matrices, called square matrices, and column vectors,

simply referred to as vectors.

We use capital letters to represent matrices and small letter with bars on top, such

as v, to represent vectors. When it is clear from the context, we will simply use 0 to

represent matrices all of whose elements are 0.

Addition and subtraction of square matrices are performed element-wise. For ex-

ample,

Â

ÃÂ

ÃÂ

Ã

1 3

2 4

C

5 7

6 8

D

4 4

8 12

:

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_7

136 7 Systems of first order equations

If A D .aij / and B D .bij / are two n n matrices, then their product is defined as AB D C , where C D .cij / is the matrix such that
X cij D aihbhj i:e: cij D ai1b1j C ai2b2j C : : : C ainbnj :
h

For example

0

10

1 01 1 0

@ 2 1 3A @ 2 0

10

1

0

3A D @ 3

1 23 1 2 0

2

1 21 6 5A :
65

We note that the product of an n n matrix and an n-dimensional vector is an n-

dimensional vector. For example

0

10 1 0 1

121 1

6

@ 0 1 3A @2A D @11A :

103 3

8

It follows from the definition that multiplication of matrices is associative, that is

A.BC / D .AB/C:

However, unlike multiplication of numbers, multiplication of matrices is not commu-

tative, that is, AB is not necessarily equal to BA, as shown by the following simple

example.

Â ÃÂ Ã Â

Ã Â ÃÂ Ã Â

Ã

12 01

2 1

1 3

D

4 1

5 3

¤

21 13

1 0

2 1

D

2 1

3 5

:

For any natural number n, the n n matrix

0

1

10

0

In D I D BB@B0::: 1

0ACCC ;

00

1

whose diagonal elements are 1 and the rest are 0, is called the identity matrix. It can easily be checked that for any n n matrix A, AI D IA D A:

7.1.2 Determinants
We define the determinants of square n n matrices by induction as follows: If n D 1, that is A D .a/ consists of one element, the determinant is defined as
det A D a. Assuming to have defined the determinant of an .n 1/ .n 1/ matrix, we define
det A of an n n matrix A as follows:

7.1 Preliminaries: A brief review of linear algebra 137

1. Choose any entry akl of A and consider the matrix Akl obtained by eliminating the row and the column to which akl belongs (that is, the k-th row and l -th column). The determinant of Akl , called the minor of akl , is defined by induction hypothesis since it is n 1 n 1.

Setting Ckl D . 1/kCl det Akl (Ckl is called the cofactor of akl ), we define

X

det A D

akl Ckl :

1Äl Än

For example, if we choose the elements akl along the second row, then det A D

a21C21 C a22C22 C a23C23 C : : : C a2nC2n.

Let us indicate the calculation for n D 2; 3. The determinant of a 2 2 matrix is

det A D aa2111

a12 a22



D

a11a22

a12 a21 ;

because the cofactor of a11 is det.a22/ and the cofactor of a12 is det.a21/ D a21.

The determinant of a 3 3 matrix A D .aij /, is

det A D aaa312111

a12 a22 a32

a13 a23 a33



D

a11C11

C

a12C12

C

a13C13

D a11 aa2322

a23 a33



a12 aa2311

aa3233 C a13 aa2311

a22 a32



D a11.a22a33 a23a32/ a12.a21a33 a23a31/ C a13.a21a32 a22a31/:

Here we have chosen the first row. If we decide to use, say, the second column, then det A D a12C12 C a22C22 C a32C32, etc.
We state the following important general rule without proof.

The sum of the products of the elements by their corresponding cofactors along any row or column is the same.

Example 7.1.1. Let us evaluate the determinant



1 3 1

0 1 1

221

first along the second row and then along the third column.

Along the second row, we have:



1 3 1

0 1 1

221 D

3 10

12 C 

1 1

12

2 

1 1

01 D 4:

138 7 Systems of first order equations

Along the third column, we have:



1 3 1

0 1 1

122 D 

3 1

11

2 

1 1

10 C 2 13

01 D 4:

In concrete examples, it is convenient to choose a row or a column involving zero

entries, whenever possible. For example, in order to evaluate



1 3 1

2 0 1

241

it is convenient to choose either the second row or the second column since that will

involve only two nonzero terms to add, instead of three. Let us evaluate it along the

secondco131lum021n.214ThDen

2 

3 1

42

13 21 D 2 .12 C 2/

.2

3/ D 27:

For example, if A is a triangular matrix, namely if aij D 0 for all j > i , then choos-

ing the first column we find

det

A

D



a11 0 :: 0

a12 a22 :: 0

a13 a23 :: 0

::: ::: :: :::

a1n a2n :: ann

 D a11 

a22 0 :: 0

a23 a33 :: 0

::: ::: :: :::

a2n a3n :: ann

 :

To evaluate the last determinant again we choose its first column, yielding



a22 0 :: 0

a23 a33 :: 0

::: ::: :: :::

a2n a3n :: ann



D

a22 

a33 0 :: 0

a34 a44 :: 0

::: ::: :: :::

a3n a4n :: ann

 :

Repeating the procedure we find

det A D a11a22 : : : ann:

(7.1)

We now recall some additional properties of determinants.

1. Multiplying a row or a column of a determinant by a constant k is the same as multiplying the determinant by k.
2. Exchanging two rows (or columns) of a determinant changes the sign of the determinant.
3. Multiplying a row (or column) by a constant and adding it to another row (or column) does not change the value of the determinant.
4. det .AB/ D det .A/ det .B/.
5. If two rows (or columns) of a determinant are constant multiples of each other, then the value of the determinant is zero.

7.1 Preliminaries: A brief review of linear algebra 139

6. det A ¤ 0 if and only if the rows (and columns) of A form a set of linearly independent vectors.

For example,

1=153

2 2=3
6

371 D 0

since the first row is 3 times the second row. Since the determinant is 0, item 6 implies

that the rows of the matrix are linearly dependent.

The preceding properties allow us to simplify the calculation in evaluating det A

by making all the elements of A, except one, of a certain row (or column) to be 0.

For example, let us evaluate



1 3 5

2 1 1

124 :

Suppose we decide to make the second two elements of the first column 0. We can

do this by adding 3 times the first row to the second and 5 times the first row to the

third, obtaining

100

2 7 9

111 D 

7 9

11 D 7 C 9 D 16:

7.1.3 Inverse of a matrix

We call a matrix B the inverse of a matrix A if AB D BA D I . The inverse, if it

exists, is unique. For AB D BA D I and AC D CA D I , would imply AB D AC

and hence B.AB/ D B.AC / which can be regrouped as .BA/B D .BA/C . Since

BA D I by assumption, we have B D C .

Á

Not all nonzero matrices have inverses. For example, let A D

1 1

2 2

. Suppose

C D .cij / is a matrix such that AC D I . Then we would have

Â ÃÂ

ÃÂ Ã

12 12

c11 c21

c12 c22

D

1 0

0 1

:

Multiplying the first row of A by the first column of C , we obtain c11 C 2c21 D 1. But multiplying the second row of A by the first column of C , we get c11 C2c21 D 0, which is impossible. Therefore, A has no inverse.

When a matrix A has an inverse, it is called nonsingular, otherwise it is called singular. The reader familiar with Linear Algebra my recall that
"A is singular if and only is its determinant is 0."

140 7 Systems of first order equations

The next question is: when a matrix does have an inverse, how do we find it? There

are several ways and short cuts to find the inverse of a matrix. Here we explain the

method of using cofactors. The inverse of a matrix .aij /, when it exists, is the matrix

.cij /, where

cij

D

Cj i : detA

For example, let us determine the inverse of

0

1

210

A D @0 3 0A :

101

In order to determine the determinant, we choose to use the cofactors along the last

column. Since two of the elements of this column are 0, we can ignore them and see

immediately that

012

1 3 0

010 D 02

13 D 6:

Since the determinant is nonzero, we know that A has an inverse.
We now list the cofactors: C11 D 03 01 D 3; C12 D 01 01 D 0; C13 D 01 30 D 3:

Similarly, C21 D 1; C22 D 2; C23 D 1; C31 D 0; C32 D 0; C33 D 6: Now recalling that the ij -th element of A 1 is Cj i divided by the value of the determinant,

which is 6, we have

0 1=2
A 1D@ 0

1 1=6 0 1=3 0A :

1=2 1=6 1

7.1.4 Eigenvalues and eigenvectors

If a real or complex number and a nonzero vector v satisfy the equation

Av D v;
then is called an eigenvalue of the n n matrix A D .aij /, aij 2 R, and v D6 0N is called an eigenvector associated with (or the corresponding eigenvector). We note that the above equation can be written in the equivalent form

.A I /v D 0:

To find the eigenvalues of A we have to solve the equation det.A I / D 0. If this equation has no solution, then Kramer's rule implies that the equation .A /v D 0 has only the trivial solution v D 0. The determinant of A I is a polynomial of de-

7.1 Preliminaries: A brief review of linear algebra 141

gree n in , called the characteristic polynomial and the equation det.A is called the characteristic equation or the auxiliary equation of A.
For example, if A is a triangular matrix, then (7.1) yields

I/ D 0

det .A I / D .a11 /.a22 / .ann /:

Hence the eigenvalues of A are i D aii , i D 1; 2; : : : ; n. An eigenvector associated with the eigenvalue j is found by solving the system
.A j I /v D 0N. This system has nontrivial solutions if j is a solution of det.A I / D 0. Of course, if v is an eigenvector of A, then so is v for all  2 R,  6D 0. The
space E j D ¹x 2 Rn W Ax D j xº is called the eigenspace corresponding to j . If x; y 2 E j then x C y 2 E j for all ;  2 R, because
A.x C y/ D Ax C Ay D  j x C  j y D j .x C y/:

Thus E j is a closed subspace of Rn. If j is a real number and k dDef d i m.E j / > 1 it means that there are k linearly independent real eigenvectors corresponding
to j . The d i m.E j / is called the geometric multiplicity of j . The algebraic multiplicity of j is defined as the multiplicity of the root D j of the characteristic
polynomial. For example, the characteristic polynomial of the matrix

0

1

210

A D @0 2 0A

003

is . 2/2. 3/ and hence 2 is an eigenvalue of algebraic multiplicity 2, while 3 is an eigenvalue of algebraic multiplicity 1. To evaluate their geometric multiplicity, we have to solve the system .A /v D 0 namely

8 < .2 :

/v1 C v2 D 0 .2 /v2 D 0 .3 /v3 D 0.

If D 2 we find v2 D v3 D 0, while if D 3 we find v1 D v2 D 0. Thus the corresponding eigenspaces are spanned by .1; 0; 0/ and .0; 0; 1/ respectively. As a

consequence, the geometric multiplicity of both the eigenvalues is 1. On the other

hand, if we consider the matrix

0

1

200

B D @0 2 0A

003

the characteristic polynomial is still . 2/2. 3/ and hence, as before, the algebraic multiplicity of 2; 3 is 2 and 1, respectively. To evaluate their geometric multiplicity

142 7 Systems of first order equations

we solve the system

8 < .2

:

.2 .3

/v1 D 0 /v2 D 0 /v3 D 0.

It follows that the eigenspace E2 is 2-dimensional and spanned by .1; 0; 0/ and .0; 1; 0/, while the eigenspace E3 is one-dimensional and spanned by .0; 0; 1/. Thus the geometric multiplicity of D 2 is 2 and that of D 3 is 1.
It can be shown that, in general, the geometric multiplicity is less than or equal to
the algebraic multiplicity.
Let us point out that the eigenvalues of A might be complex numbers. However, since the coefficients of the characteristic polynomial of A are real, if  C i is an eigenvalue of A so is  i. If u C i v, with u; v 2 Rn, is an eigenvector corresponding to  C i, then it is easy to check that u i v is an eigenvector corresponding to
D  i.
The following result will be used later.

Theorem 7.1.2. If v1; : : : ; vj are eigenvectors of A corresponding to distinct real eigenvalues, 1; : : : ; j , then they are linearly independent.

Proof. The proof is based on the Induction Principle. For j D 1, it is trivially true. Suppose it is true for j D k, k 1, that is, any k vectors with distinct eigenvalues are linearly independent. We will now show that the statement is also true for j D k C 1. Suppose not. Then there exist k C 1 linearly dependent eigenvectors v1; : : : ; vkC1, with corresponding distinct eigenvalues 1; : : : ; kC1. Therefore, there exist constants c1; : : : ; ckC1, not all zero, such that

c1v1 C c2v2 C : : : C ckC1vkC1 D 0:

(7.2)

Multiplying this equation by A we obtain

c1Av1 C c2Av2 C : : : C ckC1AvkC1 D c1 1v1 C c2 2v2 C : : : C ckC1 kC1 vkC1 D 0:

(7.3)

If we multiply equation (7.2) by 1 and subtract it from the second equation in (7.3), we obtain
c2. 2 1/v2 C : : : C ckC1. kC1 1/vkC1 D 0:

But this is a linear combination of k eigenvectors v2; : : : ; vkC1 with distinct eigenvalues 2; : : : ; kC1. Therefore, by induction hypothesis, we must have c2 D : : : D ckC1 D 0. This changes (7.2) to c1v1 D 0, which implies that c1 D 0 (recall that an
eigenvector is nonzero by definition). This contradiction completes the proof.

7.1.5 The Jordan normal form
If A is a nonsingular matrix, there exist two nonsingular matrices J and B such that A D B 1JB, or equivalently BA D JB. J is called the Jordan normal form (or

7.1 Preliminaries: A brief review of linear algebra 143

simply Jordan matrix) of A. The Jordan matrix J is triangular (but not necessarily diagonal).
If is a real eigenvalue of A the Jordan block relative to is the p p matrix

0

J D B@BBBBBB

0 ::: :::

0

1 0 ::: ::: :::
::: ::: ::: 0

1 0

0 :::
1

CCCCCCCA

where all the entries are zero, except the entries am;mC1 above the diagonal am;m which are 1. Its characteristic polynomial is . /p and hence J has a unique eigenvalue with algebraic multiplicity p. Moreover, solving the system .J I /v D

0 we find that the corresponding eigenspace is one-dimensional and spanned by

.1; 0; : : : ; 0/ so that the geometric multiplicity of (with respect to J ) is 1.

If the eigenvalues of A are real, it is possible to show that the Jordan normal form

associated with A is the n n matrix

0

1

J1

0

J D @B

:::

AC

0

Jh

where the sub-matrices J1; : : : ; Jh are Jordan blocks relative to the eigenvalues. As we will see later on, Jordan matrices are useful when we deal with linear sys-
tems x0 D A.x/. Let us show what happens if n D 2, which is the case we will deal with in the
sequel. Let A be a 2 2 matrix with eigenvalues 1; 2. Then the Jordan matrix is
as follows.

1. If 1, 2 are real and distinct, then their algebraic and geometric multiplicity is 1

and hence

Â

Ã

JD

1
0

0
2

:

(J1)

2. If 1 D 2 is real, then its algebraic multiplicity is 2. Either its geometric multiplicity is also 2, a case where

Â

JD

1
0

Ã 0;
1

(J2.1)

or its geometric multiplicity is 1, a case where

Â

JD

1
0

Ã 1:
1

(J2.2)

144 7 Systems of first order equations

Furthermore, if the eigenvalues are complex conjugate, 1;2 D   i, then one

can show that

Â

Ã

JD

 

 

:

(J3)

Moreover, let v 6D 0N be an eigenvector of A corresponding to the eigenvalue , namely such that Av D v. Using the Jordan normal form, we find B 1JBv D v whence JBv D Bv. In other words,
v is an eigenvector of A if and only if Bv is an eigenvector of J .

7.2 First order systems

Consider the system of first order differential equations

xi0 D fi .t; x1; x2; : : : ; xn/; i D 1; 2; : : : ; n:

(7.4)

By a solution of such a system we mean n functions y1.t/; y2.t/; : : : ; yn.t/ such that yi0.t/ D fi .t; y1.t/; y2.t/; : : : ; yn.t//; i D 1; 2; : : : ; n: The corresponding initial
value problem can be expressed as

xi0 D fi .t; x1; x2; : : : ; xn/; xi .t0/ D xi0; i D 1; 2; : : : ; n

where t0 is some point in the domain being considered. Systems of differential equations arise in many areas such as Chemistry, Biology,
Physics and Engineering. Examples arising in Population Dynamics are discussed in Chapter 8. In what follows we will study some important systems that are significant both theoretically and practically and we will develop methods of solving certain types of systems.
However, some systems can be solved by simply rewriting them and then using known methods to deal with them. We start with a couple of such systems.

Example 7.2.1. Solve the system
² x0 y0

D 3x C y D 2x:

Taking the derivative of the first equation, we have x00 3x0 y0 D 0 and then substituting 2x for y0, we obtain

x00 3x0 C 2x D 0:

The characteristic equation m2 3m C 2 D 0 has roots m D 1; 2 and hence the general solution for x is x D c1et C c2e2t : Therefore, y D x0 3x D c1et C 2c2e2t 3.c1et C c2e2t / D 2c1et C c2e2t . Thus x D c1et C c2e2t and y D
2c1et C c2e2t solve the given system.

7.2 First order systems 145

Example 7.2.2. Solve the initial value problem ´ x0 D y; x.0/ D 1 y0 D x2; y.0/ D 2:

We note that x00 D y0 D x2. We recall that we can solve the equation x00 D x2 by

letting v

D

x0;

and

using

the

Chain Rule

to

get

x00

D

v

dv dx

,

which

results

is

a

first

order

equation

v

dv dx

D

x2

. Solving this first order equation for v

and then integrating

v, and determining the constants from the initial values, we obtain

x.t/ D

r

!2

12

t C1 :

23

As we have seen in Chapter 4, any system of the form

x D x1; x10 D x2; x20 D x3; : : : ; xn0 1 D xn; xn0 D f .t; x1; x2; : : : ; xn/
can be written as a single equation x.n/ D f .t; x; x0; : : : ; x.n 1//. Conversely, any equation of the form x.n/ D f .t; x; x0; : : : ; x.n 1// can be written as a system of first order equations as follows: Let x D x1. Then we can write the system as x10 D x2; x20 D x3; : : : ; xn0 1 D xn; xn0 D f .t; x; x0; : : : ; x.n 1// D f .t; x1; x2; : : : ; xn/:

Example 7.2.3. Write the following initial value problem as a system.

x000 C 2x00 .x0/3 C x D t 2 C 1; x.0/ D 0; x0.0/ D 1; x00.0/ D 1:

Let x D x1; x0 D x2; x00 D x3: Then we have the system

8 ^< x10

:^

x20 x30

D x2 D x3 D 2x3 C x23

x1 C t2 C 1

subject to the initial conditions x1.0/ D 0; x2.0/ D 1; x3.0/ D 1.

We have already seen that single higher order equations can be written as first order systems, also higher order systems generally may be written as first order systems. But the resulting system is normally more complicated. We demonstrate this in the following example.

Example 7.2.4. Write the system
² x000 C x0 D t y00 y2 D 1

as a first order system.

146 7 Systems of first order equations

Let x D x1 , x10 D x2, x20 D x3, and y D y1, y10 D y2: Then we can write the

system

8

^^<^^^^

x10 x20

D D

x2; x3;

^:^^^^^

x30 y10 y20

C x2 D D y2;
y12 D

t 1:

7.3 Linear first order systems

The following is the general form of a first order linear system:

8 ^<^

x10 :::

D

a11.t /x1.t /

C

a12.t /x2.t /

C

:::

C

a1n.t /xn.t /

C

f1.t /

^^: xn0 D an1.t /x1.t / C an2.t /x2.t / C : : : C ann.t /xn.t / C fn.t /:

(7.5)

The functions fi .t/; 1 Ä i Ä n, are called the forcing functions. When there are no forcing functions in the system, i.e. fi .t/ Á 0, 1 Ä i Ä n, the system is called homogeneous, otherwise it is called nonhomogeneous.
The next theorem and some of the concepts developed here are fairly similar to the high order linear homogeneous differential equations.
Theorem 7.3.1. Suppose that aij , 1 Ä i; j Ä n, and fi ; 1 Ä i Ä n; are continuous in an interval I . If t0 2 I , then for any numbers x10; x20; : : : ; xn0, there is exactly one solution x1; x2; : : : ; xn of (7.4) satisfying the initial condition x1.t0/ D x10; x2.t0/ D x20; : : : ; xn.t0/ D xn0: Furthermore, this solution is defined everywhere in I .
Proof. It follows immediately from Theorems 4.2.2 and 4.2.3 of Chapter 4.

For convenience and efficiency, we write the system (7.5) in terms of matrices and

vectors. In particular we let

0

1

01

01

a11.t / a12.t /

a1n.t /

x1.t /

f1.t /

A.t/ D BB@Ba21:::.t/

a22.t / :::

:::

a2n.t/CACC; x.t/ D B@BBx2:::.t/CCAC; fN.t/ D BBB@f2:::.t/CCCA :

an1.t / an2.t /

ann.t /

xn.t /

fn.t /

Then the system (7.5) can be written in the equivalent form

x0.t/ D A.t/x.t/ C fN.t/

(7.6)

7.3 Linear first order systems 147

with the corresponding homogeneous system

x0.t/ D A.t/x.t/:

(7.7)

Example 7.3.2. The system

8 <

x10 .t /

D

2 tx1 .t /

et x2.t/ C 2tx3.t/ C sin.t/

:

x20 .t / x30 .t /

D D

x1.t / 4x1.t /

3x2.t/ C 5t2x2.t/ C cos.t/ 5tx2.t / C 5t 3x3.t / C et

can be written as

0x10

.t

1 /

0 2t

@x20 .t/A D @ 1

x30 .t /

4

et

10 1 2t x1.t/

01 sin t

3 5t2A @x2.t/A C @cos tA :

5t 5t 3 x3.t /

et

Theorem 7.3.1 can be stated in matrix form as:
Theorem 7.3.3. If A.t/ and fN.t/ are continuous in an interval I , then there exists exactly one solution x.t/ of (7.6) satisfying the initial condition x.t0/ D x0, where
01 x10
x0 D B@ ::: AC xn0
is any vector with n components, consisting of arbitrary real numbers. Furthermore, x.t/ is defined everywhere in I .

Theorem 7.3.4. If x1; x2; : : : ; xn are solutions of (7.7), then any linear combination c1x1 C c2x2 C : : : C cnxn of these solutions is also a solution of (7.7).

Proof. It suffices to prove it for n D 2; the general case will then easily follow from

the Principle of Mathematical Induction. Let x1; x2 be two solutions of (7.7). Then

.c1x1

C

c2x2/0

D

c1x

0 1

C

c2x02

D

c1.A.t /x1/ C c2.A.t /x 2/

D

A.t /.c1x1

C c2x2/:

This shows that c1x1 C c2x2 is a solution of (7.7).

Definition 7.3.5. Vectors x1; x2; : : : ; xn are said to be linearly independent if for any constants c1; c2; : : : ; cn, c1x1 C c2x2 C : : : C cnxn D 0 implies c1 D c2 D : : : D cn D 0.
If they are not linearly independent, then they are called linearly dependent.

Example 7.3.6. Check the vectors 01 1

01 2

x1 D @0A ; x2 D @1A ;

1

1

for linear independence.

01 4
x3 D @1A
3

148 7 Systems of first order equations

The idea is similar to what we did in the case of a single higher order equation. We indicate two ways to solve this problem.

1. c1x1 C c2x2 C c3x2 D 0N is equivalent to the system

8 < c1 C 2c2 C 4c3 D 0

:

c2 C c3 D 0 c1 C c2 C 3c3 D 0.

We solve the system for c1; c2; c3 by subtracting the last equation from the first and obtain c2 C c3 D 0, which is the same as the second equation and has infinitely many solutions. For each such pair of solutions, we can solve for c1. For example, let c2 D 1. Then, c3 D 1. Substituting these values of c2 and c3 in the first equation, we have c1 C 2 4 D 0, or c1 D 2. Therefore, 2x1 C x2 x3 D 0. This shows that x1; x2; x3 are linearly dependent.

2. Instead of solving for c1; c2; c3 in the above system, we simply evaluate the

determinant of their coefficients

110

2 1 1

413 :

Multiplying the first row by 1 and adding it to the last row we get

100

2 1 1

141 D 1 C 1 D 0:

Therefore the above system has nontrivial solutions in c1; c2; c3, which implies that the vectors x1; x2; x3 are linearly dependent.

7.3.1 Wronskian and linear independence

Consider the linear homogeneous scalar differential equation

x000.t / C a1.t /x00.t / C a3x.t / D 0:

We defined the Wronskian of solutions x; y; z of this equation as

W .x; y; z/ D xxx000

y y0 y00

zzz000 :

We also explained above how we can write the scalar differential equation x000.t/ C a1.t /x00.t /Ca3x D 0 as the system x1 D x; x10 D x2; x20 D x3. y000.t /Ca1.t /y00 .t /C a3y D 0 can be written as the system y1 D y; y10 D y2; y20 D y3. Similarly, if y and z are solutions, we let y1 D y; y10 D y2; y20 D y3 and z1 D z; z10 D z2; z20 D z3.
This suggests that the definition of Wronskian may be extended to three vector func-

tions as follows:

7.3 Linear first order systems 149

W .x; y; z/ D xxx213

y1 y2 y3

z1 z2 z3



where

01

01

01

x1

y1

z1

x D @x2A ; y D @y2A ; z D @z2A :

x3

y3

z3

So, we extend the definition of Wronskian to vector functions and define the Wron-

skian of n vector functions

0

1

0

1

x11.t /

x12.t /

x1.t/ D BBB@x21:::.t/CACC ; x2 D @BBBx22:::.t/CCCA ;

0

1

x1n.t /

; xn D B@BBx2n:::.t/ACCC

(7.8)

xn1.t /

xn2.t /

xnn.t /

as

W .x1; x2;

;

xn/.t

/

D

xxxn21111:::...ttt

/ /
/

x12.t / x22.t /
:::
xn2.t /

:::

xxxn21nnn...ttt///

(7.9)

in which the i -th column is the vector xi .t/.

Theorem 7.3.7. Vector functions x1.t/; x2.t/; ; xn.t/ are linearly independent if their Wronskian is nonzero at some point t0.

Proof. Suppose c1x1.t/ C c2x2.t/ C : : : C cnxn.t/ D 0, where xi ; 1 Ä i Ä n, are

denoted as in (7.8). Then, at t0, this is equivalent to the system

8

^<^^

c1x11 .t0 / c1x21.t0/

C C

c2x12 .t0 / c2x22.t0/

C C

: :

: :

: :

C C

cn x1n .t0 cnx2n.t0

/ /

D D

0 0

^^:^c1 xn1 .t0 /

C

c2xn2 .t0 /

::: C

:

:

:

C

cn xn n .t0 /

D

0:

This algebraic system of equations has no nontrivial solution in c1; c2; : : : ; cn if the coefficient determinant is nonzero. But the coefficient determinant is precisely the Wronskian of x1; x2; : : : ; xn at t D t0. Therefore, c1 D c2 D : : : D cn D 0 and the proof is complete.

Theorem 7.3.8. Suppose that x1; x2; : : : ; xn are solutions of x0 D A.t/x

150 7 Systems of first order equations

where A.t/ is an n n matrix, continuous on an interval I . Then their Wronskian

W .t/ is given by

W .t/

D

W

.t0

/e

Rt
t0

.a11.s/Ca22

.s/C:::Cann

.s//ds

where a11; a22; : : : ann are the diagonal elements of A.t/.

Proof. We give the proof for n D 2. The proof for the general case follows exactly

the same way, but the notations become cumbersome. Suppose that

Â

Ã

ÂÃ

ÂÃ

A.t/ D

a11 a21

a12 a22

; x1 D

x11 x21

; x2 D

x12 x22

:

The Wronskian of x1; x2 is given by

W .t/

D

xx1211..tt

/ /

x12.t x22.t

//

:

Then

W

0.t /

D

xx120 11

.t .t

/ /

x10 2 x22

.t .t

//

C

xx210 11

.t .t

/ /

x12.t x20 2.t

//

:

Since x01 D A.t /x, it follows that x10 1 D a11x11 C x21a12; x20 1 D a21x11 C a22x21; x10 2 D a11x12 C a12x22; x20 2 D a21x12 C a22x22: Making these substitutions in the above equation for W 0.t/, we obtain

W

0.t /

D

a11x11

C a12x21 x21

a11

x12 C a12 x22

x22

C

a21x11

x11 C a22x21

a21

x12 x12 C a22x22



:

Now, we multiply the second row of the first determinant by a12 and add it to the

first row. We also multiply the first row of the second determinant by a21 and add

it to the second row. Then we obtain W 0.t / D a1x12x111 a1x12x212 C a2x21x121

a2x21x222 D a11W C a22W D .a11 C a22/W:

Integrating W 0 D .a11 C a22/W from t0 to t proves the theorem.

Corollary 7.3.9. The Wronskian of n solutions of (7.7) is either always zero or never zero.

The sum of the diagonal elements of a matrix is called the trace of the matrix and

denoted by t r .A/. With this notation we can write

W .t/

D

Rt
W .t0/e t0

t r .A.s//ds:

7.3 Linear first order systems 151 Example 7.3.10. Consider the scalar differential equation

x.n/ C a1.t /x.n 1/ C : : : C an.t /x D 0:

Recall that if x1; x2; : : : ; xn are sRolutions of this differential equation, then their

WronskRitan W .t0/e t0

is
a1

given .s/ds .

by As

W .t / D ce a1.s/ds indicated above, we

, or can

in terms convert

of definite integral, W .t/ this equation to a system

D by

letting x1 D x; x10 D x2; : : : ; xn0 1 D xn; xn0 D a1xn a2xn 1 : : : anx1.

This system can be written in matrix form as

0x10 1 BBB@x:::20 CCAC
xn0

D

0 BBBBB@

0 0 ::: 0 an

1 0 ::: 0 an 1

0 1 ::: 0 an 2

0 0
0 an 3

0 0
1 a1

1 CCCCAC

01 x1
@BBBx:::2 CCCA xn

:

As we can see, the trace of the matrix is a1.t/. So, applying Theorem 7.3.8, we

obtain

Rt
W .t / D W .t0/e t0

a1.s/ds

which agrees with what we found by the method of scalar equations.

Theorem 7.3.11. Let x1; x2; : : : ; xn be linearly independent solutions of (7.7), on an interval I where A.t/ is continuous. Then the general solution of (7.7) is given by x.t / D c1x1 C c2x2 C : : : C cnxn, ci 2 R.

P Proof. By Theorem 7.3.4 we know that x D ci xi is a solution of (7.7). We have to show that given any solution y of (7.7), there then exist constants c1; c2; : : : ; cn such that y D c1x1 C : : : C cnxn. For this, let

0

1

01

x1i .t /

y1.t /

xi .t/ D BB@Bx2i:::.t/CACC ; i D 1; 2; : : : ; n; and y.t/ D BBB@y2:::.t/ACCC

xni .t /

yn.t /

and let t0 be any number in I . Then c1x1.t0/ C c2x2.t0/ C : : : C cnxn.t0/ D y.t0/ is equivalent to the system

8

^^<^

c1x11.t0/ c1 x21 .t0 /

C C

c2 x12.t0 / c2x22.t0/

C C

: :

: :

: :

C C

cn x1n .t0 / cn x2n .t0 /

D D

y1 .t0 / y2 .t0 /

^:^^c1xn1 .t0 /

C

c2 xn2 .t0 /

C

::: :

:

:

C

cn xn n .t0 /

D

yn .t0 /:

152 7 Systems of first order equations

This system will have a unique solution in c1; c2; : : : ; cn if the coefficient determinant

xxx12n111:::...ttt000

/ /
/

x12.t0/ x22.t0/
:::
xn2 .t0 /

:::

xxxn21nnn...ttt000///

is nonzero. But this determinant is precisely the Wronskian of x1; x2; : : : ; xn, which is nonzero by assumption. Now it follows from the uniqueness theorem that c1x1.t/C c2x.t/ C : : : C cnxn.t/ D y.t/ for all t in I .

7.4 Constant systems ­ eigenvalues and eigenvectors

In this section we consider the homogeneous system x0 D Ax

(7.10)

where A D .aij / is a constant matrix, that is the entries aij , 1 Ä i; j Ä n, are
constants, and it is nonsingular. We recall that in the case of homogeneous scalar
equations with constant coefficients, we were able to find the general solution by substituting emt for the dependent variable. This suggests that we try substituting x D e t v in (7.10). Doing so, we obtain x0 D e t v D Ae t v; which gives rise to the equation Av D v. The last equation may be written as

.A I /v D 0N

(7.11)

where I is the n n identity matrix and 0N 2 Rn is the zero vector. It is now clear that x D e t v will be a solution of (7.10) if and v satisfy equation (7.11). Using the
notation introduced in Section 7.1, this means that is an eigenvalue of the matrix A and v 6D 0N is an eigenvector associated with . We have also seen that we must have
that is a solution of the characteristic polynomial

det.A I / D 0:

(7.12)

Example 7.4.1. Let

0 1
A D @0
1

1 30 2 0A :
13

(a) Find the characteristic equation of A.
(b) Find the eigenvalues and the corresponding eigenvectors of A. (c) Find the solutions of x0 D Ax corresponding to each eigenvalue.
(d) Show that the solutions in (c) are linearly independent.
(e) Find solution y.t/ satisfying the initial condition 01 1
y.0/ D @0A :
1

7.4 Constant systems ­ eigenvalues and eigenvectors 153

Solution. (a)

det .A

I/

D

1

0 1

3 2
1

0 0 3

 D .1

/.2

/.3

/:

Therefore, the characteristic equation is .1 /.2 /.3 / D 0.

(b) The eigenvalues of A are 1 D 1; 2 D 2; 3 D 3. To find an eigenvector v1

corresponding to 1 D 1, we substitute 1 D 1 in (7.11) and solve for v D v1. If the

components of v1 are x; y; z, then

0

10 1 0 1

0 30 x

0

.A I /v1 D @0 1 0A @yA D @0A :

112 z

0

We obtain y D 0 and z D

1 2

x

.

Thus,

01

x

v1 D @ 0 A :

1 2

x

We can take x to be any nonzero number. So, let x D 1. As mentioned before, any v ,  2 R,  6D 0, is also an eigenvector. Hence, taking  D 2 we have
01 2
v1 D @ 0 A :
1

Similarly, substituting tively, we obtain

D 2 and D 3 in (7.11) and solving for v2 and v3, respec-

01 3

01 0

v2 D @ 1A ; v3 D @0A :

2

1

Once more, we point out that there are many ways, in fact infinitely many ways, to choose an eigenvector. We should try to choose options that seem convenient.

(c) The corresponding solutions are

01 2

01 3

01 0

x1 D @ 0 A et ; x2 D @ 1A e2t ; x3 D @0A e3t :

1

2

1

(d) In order to show that these solutions are linearly independent, we show that

their Wronskian

W .t/ D 

2et
0 et

3e2t e2t 2e2t

0
0 e3t



154 7 Systems of first order equations

is nonzero. Expanding the determinant above along the third column, we see that W .t/ D e3t .2e3t / D 2e6t , which is never zero for any t.
We point out that in general we only need to show that the Wronskian is nonzero at some convenient point. It will then follow from Corollary 7.3.9 that it is always
nonzero.

(e) By part (d), y.t/ D c1x1.t/Cc2x2.t/Cc3x3.t/ is the general solution. There-

fore, there exist constants c1; c2; c3 such that c1x1.0/ C c2x2.0/ C c3x3.0/ satisfies

the given initial condition. We find these constants by solving the system

01 2

01 3

01 01

0

1

c1 @ 0 A C c2 @ 1A C c3 @0A D @0A

1

2

1

1

which is equivalent to the system

8 < 2c1 C 3c2 D 1

: c1

c2 D 0 2c2 C c3 D 1:

We see that c1 D

1 2

;

c2

D 0;

c3

D

3 2

.

Therefore,

the

desired

solution

is

01

01 0

1et

@

2 0A

C

3 e3t

0 @0A

D

@

et 0

10 AC@

0 0

10 AD@

et 0

1 A:

21

21

1 2

e

t

3 2

e

3t

1 2

e

t

C

3 2

e

3t

We first deal with the case when the eigenvalues of A are real and distinct.
Theorem 7.4.2. If v1; : : : ; vn 2 Rn are n eigenvectors of the n n matrix A and the corresponding eigenvalues 1; : : : ; n are real and distinct, then x.t/ D c1v1e 1t C : : : C cnvne nt is the general solution of (7.10).
Proof. To any i 2 R and vi 2 Rn, i D 1; : : : ; n, we can associate a function xi .t/ D vi e i t which is a solution of x0 D Ax. According to Theorem 7.3.11, x.t/ is the general solution provided xi are linearly independent. Since xi .0/ D vi , then their Wronskian at t D 0 is the determinant of the matrix whose columns are the vectors v1; : : : ; vn. Thus xi are linearly independent if and only if vi are so. On the other hand, by Theorem 7.1.2 proved in Section 7.1, xi are linearly independent provided
1; : : : ; n are distinct. This completes the proof.

Notice that part (d) of Example 7.4.1 is an immediate consequence of this Theorem.

In Theorem 7.4.2 it was shown that if the eigenvalues of A are distinct (hence simple), then the n corresponding eigenvectors are linearly independent. It follows from the proof of this theorem that any k distinct eigenvalues, 1 Ä k Ä n, give rise to k linearly independent eigenvectors. The situation for repeated eigenvalues is not

7.4 Constant systems ­ eigenvalues and eigenvectors 155

so simple. For example, a double eigenvalue may or may not yield two linearly independent eigenvectors. In other words, if A has some repeated eigenvalues, it may or may not have n linearly independent eigenvectors. One class of matrices that have the property that to each eigenvalue that is repeated k times, there correspond k linearly independent eigenvectors, is the class of symmetric matrices. We give below some examples that illustrate both possibilities. The student can easily understand how to handle other similar cases.

Example 7.4.3. Find the general solution of x0 D Ax, where

0

1

10 0

AD @ 0 1 0 A:

00 1

The eigenvalues of A are D 1 and D 1 (double). Moreover,

01 1

01 0

01 0

v1 D @ 0 A ; v2 D @ 1 A ; v3 D @ 0 A ;

0

0

1

are 3 linearly independent eigenvectors. Then x1 D v1et , x2 D v2e t and x3 D v3e t solve x0 D Ax and are linearly

independent because xi .0/ D vi , i D 1; 2; 3, are so. Thus the general solution is x D c1v1et C c2v2e t C c3v3e t .

As an exercise, the student can find the same result noticing that the components

x1; x2; x3 of x satisfy the uncoupled system

8 < x10 D x1;

:

x20 x30

D D

x2; x3:

Example 7.4.4. Find the general solution of x0 D Ax, where

0

1

300

AD @ 0 3 0 A:

112

Since

d e t .A

I/

D



3

0 1

0 3
1

0 0 2

 D .3

/2 .2

/;

the eigenvalues of A are D 3 (double) and D 2.

It is easy to check that A has 3 eigenvectors given by

01

01

01

1

0

0

v1 D @ 0 A ; v2 D @ 1 A ; v3 D @ 0 A ;

1

1

1

156 7 Systems of first order equations

which are linearly independent because



1 0 1

0 1 1

0 0 1



D

1:

Then x1 D v1e3t , x2 D v2e3t and x3 D v3e2t solve x0 D Ax and are linearly
independent because xi .0/ D vi , i D 1; 2; 3, are so. Thus the general solution is x D c1v1e3t C c2v2e3t C c3v3e2t .

Example 7.4.5. Find the general solution of x0 D Ax where

Â

Ã

AD

a 0

;

with ; a D6 0. Now, is a double eigenvalue bÁut the eigenspace correspoÁnding to

is one-dimensional and spanned by v1 D

1 0

, which yields x1 D

1 0

e t , but it

is not obvious how to find a second linear independent solution.

Let us take x2 D v1te t C ue t and determine u such that x1; x2 are linearly

independent

and

x

0 2

D

Ax2.

As

before,

from

x1.0/

D

v1;

x2.0/

D

u,

it

follows

that

for x1; x2 to be linearly independent it suffices that v1; u are so.

On the other hand, the equation x20 D Ax2 is equivalent to

t e t v1 C e t v1 C e t u D A.t e t v1 C e t u/ D Av1 t e t C Au e t :

Since Av1 D v1, we have t e t v1 C e t v1 C e t u D v1 t e t C Au e t :
Canceling te t v1, we obtain e t v1 C e t u D Au e t and hence

v1 C u D Au:

This can be written as

.A I /u D v1

namely

Â

ÃÂ Ã Â Ã

²

0a 00

u1 u2

D

1 0

i:e:

au2 D 1; 0 D 0:

Á

Thus u D

0 1=a

, which is obviously linearly independent from v1. In conclusion

the general solution of x0 D Ax is

h

i

x D c1x1 C c2x2 D c1v1e t C c2 v1t e t C ue t

D

Â

1 0

Ãh c1e

t

C c2te

iÂ t C c2

0 1=a

Ã e

t;

7.4 Constant systems ­ eigenvalues and eigenvectors 157

that is,

´ x1 x2

D c1e t C c2te t ;

D

c2 a

e

t:

The reader will recognize that the preceding procedure is similar to that carried out for the scalar second order equation x00 2 x0 C 2x D 0 whose characteristic equation has the double root m D .
Our last example deals with the case in which A has complex eigenvalues.

Example 7.4.6. Find the general solution of x0 D Ax, where

Â

Ã

AD

1 1

4 1

:

The characteristic equation is given by

d e t .A

I / D 1 1

4 1

 D

2

2 C1C4D 2

2 C 5 D 0:

Solving the quadratic equation 2 2 C 5 D 0, we find the eigenvalues to be

1 D 1 C 2i and 2 D 1 2i . Let

ÂÃ

vD

x y

:

In order to find the eigenvector v corresponding to 1 C 2i , we set Av D .1 C 2i /v, which is equivalent to the system
² x C 4y D .1 C 2i /x; x C y D .1 C 2i /y:

Simplifying the equations in this system, we obtain 2y D ix and x D 2iy. We note

that if we multiply the first equation by i , we get the second equation. Therefore, we

actually have only one equation and two unknowns. This means that we can assign

an arbitrary value to one of the unknowns and then solve for the other. To this end,

let x D 2. Then y D i . This means that the solution corresponding to the eigenvalue

1 C 2i is

ÂÃ

xD

2 i

e.1C2i /t :

Now, using Euler's formula e.1C2i/t D et cos 2t C i et sin 2t, we extract real solu-

tions:

x

D

e.1C2i /t

ÂÃ 2 i

D D

ÂÂ22i..eeeettttcsccoioonsss2222ttttÃCCCiiieetÂt ss2ieinnet t22csotti//snÃ22ttDÃÂ: 2eet tcsoisn22tt

C

i

.2et

sin

2t

Ã /

C i.et cos 2t/

158 7 Systems of first order equations

Now we can take the two real solutions to be

x1

D

Â 2

et

cos

et sin

Ã 2t 2t

;

x2

D

Â 2e et

t sin 2t cos 2t

Ã

:

Evaluating their Wronskian, we see that

W

.t

/

D

2eett

cos sin

2t 2t

2e et

t sin 2t cos 2t



D

2e2t

¤

0:

Therefore, x1 and x2 are linearly independent and x D c1x1 C c2x2 is the general solution.

7.5 Nonhomogeneous systems

Consider the nonhomogeneous system

x0 D A.t/x C fN.t/

(7.13)

where the coefficient matrix A.t/ and the forcing function fN.t/ are continuous in

an interval I . Let x1; : : : ; xn be a fundamental set of solutions of the homogeneous

equation

x0 D A.t/x

(7.14)

and let xp be a particular solution of (7.13). If y is any solution of (7.13), then, as in the scalar case, it is easy to see that y xp is a solution of the homogeneous equation (7.14). Therefore, there exist constants c1; : : : ; cn such that y xp D c1x1 C : : : C cnxn; and hence y D xp C c1x1 C : : : C cnxn. We state this as

Theorem 7.5.1. If x1; : : : ; xn is a fundamental set of solutions of (7.14) and xp is any particular solution of (7.13), then y D xp C c1x1 C : : : C cnxn is the general solution of (7.13).

Once again it is important to find a particular solution of the nonhomogeneous equation. This may be accomplished by the Method of Undetermined Coefficients, which is pretty much a selective guessing scheme.

Method of undetermined coefficients. This method involves making a calculated guess for each situation. It may be used when the functions involved are familiar functions whose derivatives share some similarity with them. For example, the derivative of a polynomial is a polynomial with one degree less. Other such functions are sin t, cos t, and exponential functions.

Example 7.5.2. Find the general solution of the system

x0

D

Â x

0

Ã

y0

D

Â

1 3

ÃÂ Ã Â

Ã

1 5

x y

C

2t 2 4t

:

7.5 Nonhomogeneous systems 159

Here it seems reasonable to try

Â

Ã

xp D

at C b ct C d

and determine the constants a; b; c; d . Substituting xp in the above system, we obtain the algebraic system
² a D .at C b/ C .ct C d / C 2t 2 c D 3.at C b/ C 5.ct C d / 4t

which reduces to the system
² .a C c C 2/t C .b C d 2 a/ D 0 .3a 5c C 4/t C .c C 3b 5d / D 0:

In each of the above equations, we must have the coefficients of t and the constants

equal to zero. Setting these equal to zero, we obtain the algebraic system

8

^^<

aCc C2 D 0 3a 5c C 4 D 0

:^^

bCd 2 c C 3b

aD0 5d D 0.

Solving the first two equations, we find a D

7 4

;

c

D

1 4

.

Substituting

these

values

of a

and

c

in

the

third and

fourth

equations, we

find b

D

3 16

and

d

D

1 16

.

Therefore,

xp D

7 4

t

C

3!
16

1 4

t

C

1 16

is a particular solution of the nonhomogeneous equation.

Now, we need the general solution of the corresponding homogeneous equation x0 D Ax. We see that D 2 and D 4 are the roots of the characteristic polynomial

1 3

1 5

 D

2

6 C 8 D 0:

The corresponding eigenvectors may be taken as

ÂÃ

ÂÃ

vN1 D

1 1

; vN2 D

1 3

:

The general solution of the nonhomogeneous system is then

c1

Âe2t e2t

Ã

C

c2

Â e4t 3e4t

Ã

C

7 4

t

C

3!
16

D

1 4

t

C

1 16

c1e2t C c2e4t c1e2t C 3c2e4t

7 4
1 4

t t

C C

3 16
1 16

!

:

160 7 Systems of first order equations
Variation of parameters. First of all, let us note that if x1; : : : ; xn are vectors that satisfy the system x0 D A.t/x , these equations can be compactly expressed as
X0 D A.t/X; where X, resp. X0, is the matrix whose columns consist of the vectors xi , resp. x0, i=1,. . . ,n.

Let A.t/ be a 2

2 matrix and let

ÂÃ

ÂÃ

xD

x1 x2

; yD

y1 y2

be solutions of the system x0 D A.t/x. Then

x0

D

Âx10 Ã x20

D

Â a11 a21

ÃÂ Ã

a12 a22

x1 x2

;

y0

D

Ây10 Ã y20

D

Â a11 a21

ÃÂ Ã a12 y1 a22 y2

which is equivalent to

8 ^^<

x10 x20

D D

a11x1 a21x1

C C

a12 x2 a22 x2

^^:yy2010

D D

a11y1 a21 y1

C C

a12y2 a22 y2 :

It is easy to see that this system can be expressed in terms of matrices as X0 D AX,

that is

Âx10 x20

y10 Ã y20

D

Â a11 a21

ÃÂ a12 x1 a22 x2

Ã

y1 y2

:

Let x1; : : : ; xn be linearly independent solutions of

x0 D Ax:

We now describe a method for finding a particular solution of the nonhomogeneous

system

x0 D Ax C fN:

Since for any constants c1; : : : ; cn, x D c1x1 C : : : C cnxn is a solution of this system, we are motivated, as in the scalar case, to try to find variable functions u1.t/; : : : ; un.t/ such that y D u1x1 C : : : C unxn is a solution of the nonhomogeneous system. To this end, we first write

y D Xu

where u is the vector whose j -th component is uj ; 1 Ä j Ä n, and X is the matrix described above, that is, its columns consist of the vectors xi ; 1 Ä i Ä n. Substituting Xu in the nonhomogeneous system, we obtain
Xu0 C X0u D AXu C fN:

7.5 Nonhomogeneous systems 161 Since, as explained above, X0 D AX, the above equation is reduced to

Xu0 D fN:

(7.15)

Since the columns of X are linearly independent, X 1 exists. Multiplying both sides

by X 1, we have

u0 D X 1fN:

(7.16)

Integrating both sides and taking the constant of integration to be zero, we obtain

Z u D X 1.t/fN.t/dt

(7.17)

and hence

Z y D Xu D X X 1.t/fN.t/dt:

(7.18)

Example 7.4.1 revisited. Let us try to solve

x0

D

Â x

0Ã

y0

D

Â

1 3

ÃÂ Ã Â

Ã

1 5

x y

C

2t 2 4t

by the method of Variation of Parameters. Recall that the general solution of the

corresponding homogeneous system is

c1

Â e e

2t 2t

Ã

C

c2

Â e4t 3e4t

Ã

:

We let

X

D

Â e

2t

e2t

e4t 3e4t

Ã

:

Then

X

1

D

1 e

2

6t Â 3e4t e2t

e4tÃ e2t

D

Â

3 2

e

2t

1 2

e

4t

1 2

e

1 2

e

2t 4t

Ã

:

Therefore, X 1fN D

3 2

e

2t

1 2

e

4t

!

1 2

e

2t

1 2

e

4t

! 2t 2
D 4t

! 5t e 2t 3e 2t
3t e 4t C e 4t :

Using (7.17),
Z uD

! 5t e 2t 3e 2t
3te 4t C e 4t dt D

!

5 2

t

e

2t

C

1 4

e

2t

3 4

t

e

4t

1 16

e

4t

:

162 7 Systems of first order equations

Therefore, !
e2t e4t y D Xu D e2t 3e4t

!

5 2

t

e

2t

C

1 4

e

2t

3 4

t

e

4t

1 16

e

4t

D

!

7 4

t

C

3 16

1 4

t

C

1 16

:

Remark 7.5.3. First of all, in order to find u it is not necessary to calculate the inverse of the matrix X. One can simply solve the system (7.10) for u0 and then integrate. In

the above example, we would have the system

X u0

D

Âe2t e2t

e4t Ã 3e4t

u0

D

fN

which is equivalent to the system

e2t u10 C e4t u02 D 2t 2 e2t u10 C 3e4tu20 D 4t:

Secondly, finding the inverse of a 2 2 matrix, when it exists, is trivial. Here is the

formula:

Â a c

Ã b d

1
D

ad

1 bd

Â d c

Ã

b a

:

7.6 Exercises

These exercises are divided in 4 parts. The first 3 deal with linear systems with con-

stant coefficients: A) when the matrix A is a 2 2 Jordan matrix J ; B) when A is a

general 2 2 constant matrix; C) when A is a 3 3 constant matrix. The last set of

exercises D) deals with general linear and/or nonlinear first order systems.

Â

Ã

A1. Solve x0 D J x where J D

1 0

0 3

:

Â

Ã

A2. Solve x0 D J x where J D

a0 0a

, with a D6 0.

Â

Ã

A3. Solve x0 D J x where J D

a1 0a

, with a D6 0.

Â

Ã

A4.

Solve x0 D J x;

JD

3 1

1 3

:

A5. Solve

Â

x0 y0

Ã

D

J

Â

x y

Ã ;

Â JD

Ã

21 12

:

Â

Ã

A6. Solve x0 D J x, where J D

13 31

.

7.6 Exercises 163

A7. Solve the Cauchy problem

Â

Ã

x0 D

10 01

x;

ÂÃ

x.0/ D

1 1

:

A8. Solve the Cauchy problem

Â

Ã

x0 D

02 20

x;

ÂÃ

x.0/ D

a 0

:

A9. Solve

² x0 D y0 D

y; x.0/ D 0 x; y.0/ D 1:

A10. Solve

² x0 D 3x C t y0 D y C 2t:

A11. Solve

² x0 D x C t2 y0 D y C 1:

A12. Solve

² x0 D y0 D

xCyC1 x C y 5:

B1. Show that the matrix

ÂÃ

AD

a c

b d

has 0 as an eigenvalue if and only if A is singular.

B2. Show that the symmetric matrix

ÂÃ

AD

a b

b c

has two distinct real eigenvalues if b 6D 0.

B3. Find the eigenvalues and the corresponding eigenvectors of the matrix

ÂÃ

AD

10 31

and write the general solution of the system x0 D Ax.

164 7 Systems of first order equations

B4. Find the general solution of the system
x0 D 2x C 6y y0 D x C 3y:

B5. Find the general solution of
x0 D 2x C 6y C et y0 D x C 3y et :

B6. Solve the initial value problem

Â x

0Ã

y0

D

Â 1 0

ÃÂ Ã

2 3

x y

;

Â Ã ÂÃ

x .0/ y.0/

D

2 3

:

B7. Solve

² x0 D x C 2y C 2t y0 D 3y C t 2:

B8. Solve

Â

x0 y0

Ã

D

Â A

x y

Ã ;

Â

AD

3 0

B9.

Â Solve

x0 y0

ÃÂ DA

x y

Ã

Â where A D

1 4

Ã

0 1

.

Ã

1 2

:

B10. Solve

x0 D Ax;

Â

Ã

AD

10 31

:

B11. Solve

² x0 D x C 3y y0 D x y:

B12. Solve the Cauchy problem
² x0 D x C y; x.0/ D 1 y0 D x y; y.0/ D 0:

B13. Solve the Cauchy problem
² x0 D x C y; x.0/ D 1 y0 D y; y.0/ D 2:

B14. Solve

² x0 D x C 3y C 2t y0 D x y C t2:

B15. Solve

² x0 D x C 2y C et y0 D x 2y et :

7.6 Exercises 165

C1. Let A; B be similar n n matrices. Show that det A D det B and that they have the same eigenvalues.

C2. Solve

0 x0 1

01 x

0 1

@ y0 A D A @ y A ; A D @ 1

z0

z

2

1 00 1 0 A:
02

0

1

100

C3. Solve x0 D Ax, where A D @ 0 2 1 A.

103

C4. Find x solving the Cauchy problem

0 1
x0 D @ 0

1

01

01

1

1 0 A x; x.0/ D @ 0 A :

0 04

1

0

1

100

C5. Solve x0 D Ax, where A D @ 0 2 1 A.

101

C6. Recall that the characteristic equation of the differential equation

x000 2x00 C 3x0 C x D 0

is m3 2m2 C 3m C 1 D 0: Change the differential equation to a system and then show that its characteristic equation as a system remains the same.

C7. Solve the Cauchy problem

8 < x0

:

y0 z0

D x Cz D yCz Dy z

x.0/ D 0 y.0/ D 1 z.0/ D 0:

C8. Find a 2 R such that the system x0 D Ax;

0

1

a00

A D @ b1 b2 0 A

b4 b5 b6

has a nontrivial solution x.t/ satisfying jx.t/j ! 0 as t ! C1 for all bi 2 R.

C9. If

0 AD@

20 02 10

1 0 1 A;
1

find a nontrivial solution of x0 D Ax such that limt!C1 jx.t/j D 0.

166 7 Systems of first order equations

C10. Find a such that all the solutions of

0 x10 1

0 a2

1

@ x20 A D @ 1 a 2

x30

00

satisfy limt!C1 jxi .t/j D 0, i D 1; 2; 3.

10 1

0

x1

0 A @ x2 A

a

x3

D1. Solve

² x0 C ty D 1; y0 C x0 D 2:

D2. Solve

² x0 C y D 3t; y0 tx0 D 0:

D3. Solve

² x0 ty D 1; y0 tx0 D 3:

D4. Solve D5. Solve D6. Solve D7. Solve

² t2x0 y D 1; y0 2x D 0:
² x0 y D 3; y0 3x0 D 2x:
² tx0 C y0 D 1; y0 C x C ex0 D 1:
² xx0 C y D 2t; y0 C 2x2 D 1:

8 Qualitative analysis of 2 2 systems and nonlinear second order equations
In this chapter we study 1. Planar hamiltonian systems. 2. Lotka­Vilterra prey-predator systems. 3. Second order equations of the form x00 D f .x/. We investigate the existence of periodic solutions, called closed trajectories, and nonperiodic solutions, called open trajectories such as homoclinic and heteroclinic solutions, and so on. Our approach is based on phase plane analysis and geometric considerations and leads to information about the qualitative behavior of solutions without explicitly solving the equations. The common feature of the problems we address is the fact that there exists a quantity that is conserved along the solutions.
First of all let us state an important property of autonomous systems. Lemma 8.0.1. If x.t/ is a solution of the autonomous system
x0 D f .x/; then x.t C h/ is also a solution, 8 h 2 R. Proof. Setting xh.t/ WD x.t C h/, one has xh0 .t/ D x0.t C h/ D f .x.t C h// D f .xh.t//, which means that xh solves x0 D f .x/.
In general, the preceding property does not hold for non-autonomous systems. For example, in the case of a single equation such as x0 D 2tx, we have that x.t/ D et2 is a solution, but xh.t/ D x.t C h/ D e.tCh/2 is not a solution for any h 6D 0. Actually xh0 .t / D 2.t C h/e.tCh/2 D 2t e.tCh/2 C he.tCh/2 D 2txh.t / C hxh.t /.
© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_8

168 8 Qualitative analysis of 2 2 systems and nonlinear second order equations
8.1 Planar hamiltonian systems

In this section we deal with an important class of autonomous systems
² x0 D Hy .x; y/ y0 D Hx.x; y/

(H S )

where H.x; y/ is a twice differentiable function defined at .x; y/ 2 R2. The function H is called hamiltonian and the system is called a hamiltonian system. Hamiltonian systems are conservative because there is a quantity that is conserved along its solutions.
In the sequel we will always assume that solutions x.t/; y.t/ of (HS ) are defined for all t 2 R.

Lemma 8.1.1. If x.t/; y.t/ is a solution of (HS ), then there exists c 2 R such that H.x.t/; y.t// D c.

Proof. Taking the derivative one finds

d dt

H.x.t/; y.t//

D

Hx.x.t/; y.t//x0 .t/

C

Hy.x.t/; y.t//y0 .t/:

Since x0.t/ D Hx.x.t/; y.t// and y0.t/ D Hy .x.t/; y.t//, we have

Hx.x.t/; y.t//Hx .x.t/; y.t// Hy .x.t/; y.t//Hx .x.t/; y.t// D 0:

Therefore H.x.t/; y.t// is constant.

Consider the set in the plane defined by
c D ¹.x; y/ 2 R2 W H.x; y/ D cº:
From the preceding Lemma it follows that any solution x.t/; y.t/ of (HS ) satisfies H.x.t/; y.t// D c for some constant c and thus .x.t/; y.t// 2 c for all t. Let x.t/; y.t/ be the (unique) solution of (HS ) satisfying the initial condition x.t0/ D x0; y.t0/ D y0. If .x0; y0/ belongs to c for some c, then c D c0 D H.x0; y0/ and .x.t/; y.t// belongs to c0 for all t. Recall that, since the system (HS ) is autonomous, if x.t/; y.t/ is a solution, then so is x.t C h/; y.t C h/, for all h 2 R. Therefore, given .x0; y0/ 2 c0 we can shift the time t and assume without loss of generality that t0 D 0, namely that x.0/ D x0; y.0/ D y0. In other words, any (nonempty) curve c singles out a unique solution of (HS ), the one such that x.0/ D x0; y.0/ D y0, with .x0; y0/ 2 c.
Remark 8.1.2. If Hx.x; y/ and Hy .x; y/ do not vanish simultaneously for .x; y/ 2 c then H.x; y/ D c is a regular curve. A proof of this claim is carried out in a particular case in Lemma 8.3.3 in Section 8.3. Notice that the points .x ; y / 2 R2 such that Hx.x ; y / D Hy .x ; y / D 0 are precisely the equilibria of the hamiltonian system (HS ).

8.1 Planar hamiltonian systems 169
Example 8.1.3. If H.x; y/ D Ax2 C Bxy C Cy2, the only equilibrium is .0; 0/. If c D6 0, the curve c is a conic. Precisely:
1. If B2 4AC < 0 and c > 0, then c is an ellipse. 2. If B D 0, A D C and c > 0, then c is a circle. 3. If B2 4AC > 0 (and c 6D 0), then c is a hyperbola.
In any case c is a regular curve. If c D 0 or B2 D 4AC the conic is degenerate and can be a pair of straight lines or it reduces to a point.
Let xc .t/; yc .t/ be the solution of (HS ) such that H.x.t/; y.t// D c. Set Pc .t/ Á .xc.t/; yc .t//.
In the sequel we are interested in the existence of periodic solutions of (HS ).
Lemma 8.1.4. If there exists T > 0 such that Pc .T / D Pc .0/, then xc.t/; yc .t/ is a T -periodic solution,

Proof. By assumption, there exists T > 0 such that Pc .T / D Pc .0/, namely xc.T / D xc.0/ and yc .T / D yc .0/. We now argue as in Example 4.2.5 in Chapter 4. Setting xQc.t/ D xc.t C T /; yQc .t/ D yc.t C T / we see that
´ xQc0 .t/ D xc0 .t C T / D Hy.xc .t C T /; yc .t C T // D Hy .xQc.t/; yQc .t//; yQc0 .t/ D yc0 .t C T / D Hx .xc.t C T /; yc.t C T // D Hx.xQc .t/; yQc .t//:
Moreover, xQc.0/ D xc.T / D x.c 0/ and yQc .0/ D yc .T / D yc .0/. By uniqueness, it follows that xQc.t/ D xc.t/ and yQc.t/ D yc.t/ for all t, that is xc.t C T / D xc.t/; yc .t C T / D yc .t/. This means that .xc.t/; yc .t// is a T -periodic solution.

We conclude this section stating, without proof, the following result.

Theorem 8.1.5. Suppose that c D6 ; is a compact curve that does not contain equilibria of (HS ). Then .xc .t/; yc .t// is a periodic solution of (HS ).

Let us point out that, according to Remark 8.1.2, c does not contain equilibria of
.HS / if and only if Hx and Hy do not vanish simultaneously on c. Moreover, using the Implicit Function Theorem, it is possible to show that if the curve c D ¹H.x; y/ D 0º ¤ ; is compact and Hx and Hy do not vanish simultaneously on c , then c is a loop (i.e. a continuous curve W OEa; b ! R2 such that .a/ D .b/)
diffeomorphic to a circle.

Example 8.1.6. Show that the solution of the ivp ² x0 D 2x C 3y; x.0/ D 0 y0 D 3x 2y; y.0/ D 1

is periodic.

Here Hy D 2x C 3y and Hx D 3x C 2y. We note that Hy D 2x C 3y implies

that H

D

2xy

C

3 2

y

2

C h.x/,

where

we

take h.x/

as

the

constant

of integration with

respect

to

y.

Therefore,

Hx

D

2y

C

h0.x/

D

3x

C

2y

yielding

h

D

3 2

x2

and

hence

H.x;

y/

D

2xy

C

3 2

y2

C

3 2

x2.

170 8 Qualitative analysis of 2 2 systems and nonlinear second order equations

y=-x

y y=x

x

Fig. 8.1. 3y2 C 4xy C 3x2 D 3

The

curve

c

has

equation

3 2

x

2

C

2xy

C

3 2

y2

D

c.

Using

the

initial

values,

we

find

c

D

3 2

.

The

curve

defined

by

3 2

x

2

C 2xy

C

3 2

y2

D

3 2

,

or

3y2

C 4xy

C 3x2

D

3, is an ellipse that does not contain the equilibrium .0; 0/, see Figure 8.1. Hence the

solution of the ivp is periodic.

Remark 8.1.7. The next examples show that the assumptions that c is compact and

does not contains equilibria cannot be eliminated.

(i) If c is unbounded the solution .xc.t/; yc .t// cannot be periodic because xc.t/

and/or yc .t/ are unbounded.

(ii) Consider

H.x; y/

D

1 2

y2 ²

1 2

x2

C

1 4

x

4

,

x0 D y;

which

corresponds

to

the

system

y0 D x x3:

For c D 0, the curve 0 D ¹H.x; y/ D 0º is compact but contains the singular point .0; 0/. In Subsection 8.4.1 we will see that the corresponding solution x0.t/; y0.t/ satisfies limt!1 x0.t/ D 0 and hence is not periodic.

8.2 A prey-predator system

In this section we will study a system arising in population dynamics in the presence

of prey (e.g. sheep) and predators (e.g. wolves).

Let x.t/ > 0 denote the number of prey at time t and y.t/ > 0 the number of

predators at time t. It is assumed that the prey has an unlimited food supply (e.g.

grass) while wolves may feed on sheep, for example. The change in the number of

prey

and

predators

is

modeled

²byxt0he

so D

called Lotka­Volterra1 ax bxy

system

y0 D cy C dxy

(LV )

1 Alfred J. Lotka (1880­1949); Vito Volterra (1860­1940).

8.2 A prey-predator system 171

where a; b; c; d are strictly positive constants which depend on the skills of the prey

and predators, the environment and the challenges for predators to kill their prey,

and so on. The meaning of this model is, roughly, the following. In the absence of predators, the prey is assumed to follow the Malthusian model x0 D ax with a > 0

and hence it grows exponentially (recall that we are supposing that the prey has an

unlimited food supply). The presence of predators reduces the increasing rate of the

prey by a factor of bxy (say, the number of encounters between the sheep and the

wolves). In other words, the larger the population of the predators, the smaller the

growth rate of the prey.

The second equation models the growth rate of the predators. In the absence of prey, the predators also follow a Malthusian model y0 D cy, but with a negative

coefficient and they will eventually go to extinction due to lack of sufficient food

supply. The presence of prey modifies the growth rate of the predators by a factor

of dxy: the larger the number of prey, the greater the food supply for predators and

hence the bigger their growth rate.

Heuristically we can guess that the number of predators and prey oscillate. Nei-

ther of the two can increase beyond a certain threshold. For example, wolves cannot

increase after a threshold because when they become too many, they have to compete

harder for their food supply. But the sheep population cannot decrease too much, be-

cause the smaller their population, the smaller the survival rate of the wolf population;

and consequently the prey can prosper.

We want to prove this claim rigorously, by studying the behavior over time of the

number of prey and predators. Roughly, we try to find a constant of motion and use

it to deduce the properties of the solutions of (LV ). First of all let us find the equilibria of the system. Putting x0 D y0 D 0 it follows

that

²

ax bxy D 0

cy C dxy D 0:

Solving this system, we see that the solutions are either the trivial solution x D y D

0 or x D c=d; y D a=b.

These equilibria correspond to two constant solutions: x.t/ Á y.t/ Á 0 and

x .t /

Á

c d

;

y.t

initial number

/

Á

a b

(recall

that

of prey is x.0/ D

a;
c
d

b; c; and

d are strictly positive). In other words, the initial number of predators is y.0/

if the

D

a b

,

then their numbers remain the same for all t > 0.

Next, let us show that .LV / possesses a one parameter family of positive periodic

solutions. Following what we did earlier, it would be useful to find the counterpart

of the energy constant, looking for a function H.x; y/ such that H.x.t/; y.t// D k,

for some k 2 R.

Let us check that such a function is given by

H.x; y/ D dx C by c ln x a ln y; x > 0; y > 0:

To this end, take the derivative of H.x.t/; y.t// (for brevity we understand the de-

pendence on t without indicating it each time)

d dt

H.x; y/

D

Hx x 0

C

Hy y0

D

d

c

Á

x0

C

Â b

x

Ã a y0: y

172 8 Qualitative analysis of 2 2 systems and nonlinear second order equations

Substituting x0 D ax bxy; y0 D cy C dxy, we deduce

d H.x; y/ D d

cÁ .ax

Â bxy/ C b

aÃ .

cy C dxy/

dt

x

y

D .ad x ac bd xy C bc y/ C . bc y C ac C bd xy ad x/ D 0;

proving that H.x; y/ D k, for some k 2 R, along the solutions of (LV ). As before, the solutions of (LV ) are defined implicitly by

H.x; y/ D dx C by c ln x a ln y D k; x > 0; y > 0;

provided, of course, that the set ¹H.x; y/ D kº is not empty. Set

ÄDH

c ; aÁ D c Ca

cÁ c ln

aÁ a ln :

db

d

b

It is possible to show that the set ¹H.x; y/ D kº is not empty and defines a compact curve, surrounding the equilibrium .c=d; a=b/ if and only if k > Ä.
To give a sketch of the proof of this claim, we need the theory of functions of two variables. The reader who is not interested in the proof, or does not have sufficient background to understand it, may skip the details given in small letters below.

Let us study the surface z D H.x; y/, x > 0; y > 0. The stationary points are the solutions of Hx D 0; Hy D 0. Since

c

Hx.x; y/ D d

; x

a Hy .x; y/ D b y

we find

d c D 0; x

b a D 0: y

Then the only stationary point is the equilibrium

c d

;

a b

. The Hessian matrix H 00 of H is given

by

Â

H 00 D

Hxx Hyx

Hxy Hyy

ÃÂ

D

cx 0

2

Ã

0 ay 2

:

Then, for all x > 0; y > 0, the eigenvalues of H 00.x; y/ are both positive and this implies that

z D H.x; y/ is a strictly convex surface. In particular,

c d

;

a b

is the unique global minimum

of H . Letting

ÄDH

c ; aÁ D c Ca

cÁ c ln

aÁ a ln

db

d

b

it follows that: .i / for k < Ä the set ¹H.x; y/ D kº is empty; .i i / for k D Ä the set ¹H.x; y/ D kº reduces to the equilibrium point; .i i i / for all k > Ä the equation H.x; y/ D k is a level curve of the surface z D H.x; y/ and hence it defines a compact curve. This latter statement is also a consequence of the fact that H.x; y/ ! C1 as x ! 0C or y ! 0C as well as x ! C1 as y ! C1.
Since, for all k > Ä, the curve ¹H.x; y/ D kº is compact and does not contain the equilibria of (LV ), see Figure 8.2, one shows as in Theorem 8.1.5 that it carries a periodic solution of (LV ).

8.2 A prey-predator system 173
y

x
Fig. 8.2. The curves H.x; y/ D k, k > Ä

If x.t/; y.t/ is a T -periodic solution of (LV ), an important quantity is their mean

value

1ZT

x WD

x .t /d t ;

T0

1ZT

y WD

y.t /d t :

T0

The following result shows that, in the mean, the number of prey and predators equal the equilibria.

Theorem 8.2.1. One has

xD

c ;

y

D

a :

(8.1)

d

b

Proof. From the first equation we infer (recall that x.t/ > 0)

Z

T

x 0.t /d t

Z D

T
.a

by.t //d t :

0 x.t /

0

Since x.T / D x.0/, then Z T x0.t/dt D ln x.T / 0 x.t /

ln x.0/ D 0:

It follows

ZT

ZT

aT

aT b y.t/dt D 0 H)

y.t/dt D

0

0

b

whence y

D

a b

.

In

a

similar

way,

using

the

second

equation

one

proves

that

x

D

c d

.

Let us consider the specific case in which a D 2; b D 1; c D 3; d D 1. The
equilibrium is the point P D .3; 2/ and the system becomes ² x0 D 2x xy y0 D 3y C xy:

174 8 Qualitative analysis of 2 2 systems and nonlinear second order equations

Moreover

H.x; y/ D x C y 3 ln x 2 ln y;

and Ä D 5 3 ln 3 2 ln 2 D 5 ln.33 22/ D 5 ln.108/ > 0. From the preceding equations it follows that we can distinguish 4 regions, see
Figure 8.3:
S C D ¹x < 3; y < 2º where x0 > 0; y0 < 0; S CC D ¹x > 3; y < 2º where x0 > 0; y0 > 0; S C D ¹x > 3; y > 2º where x0 < 0; y0 > 0; S D ¹x < 3; y > 2º where x0 < 0; y0 < 0.
Let us take the initial values to be Q D .2; 1/. Letting k D H.2; 1/ D 3 3 ln 2, the equation H.x; y/ D k defines a closed curve which carries a solution x .t/; y .t/ of the system, such that x .0/ D 2; y .0/ D 1.
Referring to Figure 8.3, we fix the points A; B; C; D on . Let xm; xM be such that B D .xM ; 2/; D D .xm; 2/ 2 and let ym; yM be such that A D .3; ym/; C D .3; yM / 2 . To find xm; xM it suffices to solve the equation H.x; 2/ D 3 3 ln 2, that is
x C 2 3 ln x 2 ln 2 D 3 3 ln 2 H) x 3 ln x D 1 ln 2:
Similarly, ym; yM are the solutions of H.3; y/ D 3 3 ln 2, namely
3 C y 3 ln 3 2 ln y D 3 3 ln 2 H) y 2 ln y D 3 ln 3 3 ln 2:
The curve is contained in the rectangle OExm; xM  OEym; yM  (the dotted box in Figure 8.3) and x .t/; y .t/ are oscillating functions with minimal amplitudes xm; ym, respectively, and maximal amplitudes xM ; yM , respectively. Notice that xm > 0 as well as ym > 0.

y C

S--

S-+

P=(3,2)

D S+-

B S++

Q=(2,1)

A x

Fig. 8.3. The curve

population size

8.2 A prey-predator system 175

t
Fig. 8.4. Plot of possible oscillations of prey x.t / (red) and predator y.t / (blue) population size
In our model, the initial value Q D .2; 1/ belongs to S C where x .t/ increases while y .t/ decreases. The point .x .t/; y .t// "moves" on in counterclock direction and at a certain time t1 it reaches A, where one has x .t1/ D 3 and y .t1/ D ym. At this time, the number of prey is enough to let the predators increase. Actually, for t > t1 one enters into the region S CC where both x .t/ and y .t/ increase, even if with different slopes. At some t D t2 the point on reaches B: the number of prey achieves its maximum xM while y .t2/ D 2. Now the number of wolves is sufficiently large to cause the sheep population to decrease: for t > t2, x .t/ decreases while y .t/ increases until the point on reaches C at a time t3 such that x .t3/ D 3 and y .t3/ D yM . But the number of predators cannot increase without any limit because their big numbers would reduce the population of the prey and thus cause a shortage of food supply. As a consequence, the number of predators decays. For a while, prey still decreases, but at a lower rate. At t D t4 where x .t4/ D xm; y .t4/ D 2, the point on is D D .xm; 2/ and the wolves are so few that the sheep population starts increasing until .x .t/; y .t// once again reaches the starting initial value Q D .2; 1/.
In the Figure 8.4 the cyclic fluctuation of preys and predators over time t, is illustrated.
8.2.1 The case of fishing
The original research of Volterra was carried out in order to understand why, after the end of the first world war, in the Adriatic sea the number of small fish, like sardines (the prey) increased while the number of big fish (the predators) decreased. The explanation was that the phenomenon was due to the fact that after the war there was increased fishing activity. Roughly, fishing kills some prey and some predators and

176 8 Qualitative analysis of 2 2 systems and nonlinear second order equations

this modifies the model as follows ² x0 D ax bxy x D .a /x bxy y0 D cy C dxy y D .c C /y C dxy:

This can be explained by noticing that the increase of fishing causes a bigger death rate of predators, namely c C , and a smaller birth rate of preys, namely a , while the parameters, b; d , describing the interaction of the two species, remain unchanged. The new equilibrium is

x D cC

c >;

dd

y Da

a <

bb

and, according to (8.1), the number of sardines and predators are, in the mean,

x >xD c; d

y < y D a: b

So, according to the Lotka­Volterra model, a small increment of fishing causes, in

the mean, a growth of the sardines and a smaller number of predators.

In Figure 8.5 we indicate the effect of an -increment of fishing. The equilibrium

PD

c d

;

a b

is transformed into the new equilibrium P

D

c d

C

d;

a b

b . A level

set H.x; y/ D k is modified into the level set of

H D dx C by .c C / ln x .a / ln y

(the red curve in Figure 8.5) which is shifted to the right with respect to x and down with respect to y. This shows that the number of prey increases while the number of predator decreases.

y

P P
x Fig. 8.5. Effect of an -increment of fishing. The black curve is the level set H D k, the red curve is the level set H D k

8.2.2 Improving .LV /

8.2 A prey-predator system 177

A more realistic version of the .LV / system is given by ´ x0 D .a hx/x bxy y0 D cy C dxy:

(LV0)

In the first equation of this system the term ax is replaced by .a hx/x, with h > 0 (if h D 0 (LV0) becomes the previous .LV /). This means that, in absence of preda-
tors, namely if y D 0, the prey species growth is more realistic, being governed by the logistic equation x0 D .a hx/x instead of x0 D ax.
The equilibria of system (LV0) are the solution of the algebraic system

´ .a hx/x bxy D 0

cy C dxy

D 0:

From the second

equation we get

y

D

0 or

x

D

c d

.

Substituting y

D

0 in the first

equation we find .a hx/x D 0 yielding two equilibria .0; 0/ and

x

D

c d

in the first equation we get

a h

;

0

. Substituting

yDa

hx D a

h

c d

D ad

hc ;

b

b

bd

which is positive provided ad

>

hc. In conclusion, if 0

<

h

<

ad c

then (LV0) has 3

equilibria in the first quadrant x 0; y 0 given by

.0; 0/;

aÁ ;0 ;
h

Â

Ã

c ad hc

;

:

d bd

As for .LV /, also here the first quadrant is divided by the two dotted straight-lines dx D c and by D a hx (see Figure 8.6) into 4 sectors: (I) where x0 < 0; y0 > 0, (II) where x0 < 0; y0 < 0, (III) where x0 > 0; y0 < 0 and (IV) where x0 > 0; y0 > 0.

But the dynamic of this modified model could be different from the one of .LV /.

First of all, let us consider the following initial value problem for the modified

Lotka-Volterra system

² x0 D .a hx/x bxy; x.0/ D  > 0;

y0 D cy C dxy;

y.0/ D 0:

(8.2)

It is immediate to check that a solution of (8.2) is .x.t/; 0/, where x.t/ is the solution of x0 D .a hx/x, such that x.0/ D . Moreover, notice that by uniqueness

this is the only solution of (8.2). Recall that, according to the discussion carried out

in Subsection

3.1.1

of

Chapter

3,

one has

that

limt !C1

x.t /

D

a .
h

In

other words, aÁ

for any initial condition .; 0/,  > 0, the solution .x.t/; 0/ (8.2) tends to as t ! C1.

;0 h

178 8 Qualitative analysis of 2 2 systems and nonlinear second order equations

y

II

I

P0

P

III

IV

x

Fig. 8.6. Possible behavior of a trajectory of (LV0). The dotted straight-lines Áhave equation,

respectively, x

D

c d

and by

D

a

hx; P0 D .x.0/; y.0//; P D

c d

;

ad hc bd

Another important difference is that, in general, we do not have periodic solu-

tions any more. A possible behavior of the solutions of (LV0) is shown in Figure 8.6,

where the trajectory .x.t/; y.t//, with initial conditions P0 ÂD .x.0/; y.0//Ã; x.0/ >

0; y.0/ > 0, tends asymptotically to the equilibrium P D

c ad ;

hc

as t !

d bd

C1, in the sense that

c

lim x.t/ D ;

t !C1

d

ad hc

lim y.t/ D

:

t !C1

bd

8.3 Phase plane analysis

In this section we study the nonlinear system

² x0 D y y0 D f .x/

(8.3)

where f 2 C 1.R/. In the sequel it will be always understood that the solutions of (8.3) are defined for all t 2 R.
The plane .x; y/ is called phase plane and the study of the system (8.3) is called phase plane analysis.

8.3 Phase plane analysis 179

System (8.3) is a hamiltonian system with hamiltonian (called here E) given by

E.x; y/ D 1 y2 F .x/; 2

where F is such that F 0.x/ D f .x/. Actually, Ey D y and Ex D f .x/. Note that, in this case, the equilibria of the hamiltonian system are the points .x0; 0/ 2 R2 such
that f .x0/ D 0, that correspond to the constant solutions x.t/ D x0, y.t/ D 0 of

(8.3).

The

hamiltonian E

is

the sum

of

the kinetic energy

1 2

y2

D

1 2

x

02

and

the

potential

energy F .x/ and is therefore the total energy of the system.

From Lemma 8.1.1 proved in Section 8.1 it follows:

Lemma 8.3.1. If .x.t/; y.y// is a solution of (8.3), then E.x.t/; y.t// is constant.

For c 2 R, let

c

WD

¹.x; y/

2

R2

W

E.x; y/

D

cº

D

¹.x; y/

2

R2

W

1 2

y2

F .x/ D cº:

Remark 8.3.2. The following properties hold:

(i) c is symmetric with respect to y: .x; y/ 2 c if and only if .x; y/ 2 c .

(ii) A point .x; 0/ belongs to c if and only if F .x/ D c.

p

(iii) A point .0; y/ belongs to c if and only if c 0. In this case one has y D 2c.

(iv)

If a point .x0; y0/ 2 c, then c D

1 2

y02

F .x0/.

The proof is left to the reader as an easy exercise.

Lemma 8.3.3. If c does not contain any equilibria of (8.3), then it is a regular curve in the phase plane, in the sense that in a neighborhood of each point .x0; y0/ 2 c , c is either a differentiable curve of equation y D .x/ or x D .y/.

Proof.

(Sketch) One has

c

D

c0

D

1 2

y02

F .x0/ and hence E.x; y/ D c0 yields

y2 D 2F .x/ C 2c0. Since .x0; y0/ is not singular, then either y0 D6 0 or y0 D 0

and f .x0/ 6D 0. In the former case there exists pa neighborhood U of x0 such that 2F .x/ C 2c0 > 0 for all x 2 U and thus y D  2F .x/ C 2c0; x 2 U , where the

sign  is the same as the sign of y0. This shows that in U the set c is a curve of

equation y D .x/.

If y0 D 0, then y2 D 2.F .x/

F .x0//,

namely F .x/

D

1 2

y2

C

F .x0/

Since

.x0; 0/ is not singular, then F 0.x0/ D f .x0/ D6 0. By continuity we infer that

F 0.x/ 6D 0 in a neighborhood V of x0. Then F is invertible in V with inverse ^, and

this yields x

D

^.

1 2

y2

C

F

.x0

//.

Hence in V

c

is a curve of equation x

D

.y/.

If E.x; y/ D x2 y2 and c D 0, 0 D ¹x2 y2 D 0º is the pair of straight lines x C y D 0 and x y D 0 and cannot be represented by any cartesian curve
in any neighborhood of .0; 0/, which is the equilibrium of the corresponding system x0 D 2y; y0 D 2x. This shows that the preceding Lemma can be false if c
contains an equilibrium.

180 8 Qualitative analysis of 2 2 systems and nonlinear second order equations
8.4 On the equation x00 D f .x/
In this section we deal with the second order equations of the form x00 D f .x/. The importance of this class of differential equations is linked e.g. to the Newton Law. Actually, x00.t/ is the acceleration of a body with unit mass of position x.t/ at time t and f .x/ is the force acting on the body, depending on its position.
Here we focus on periodic, homoclinic and heteroclinic solutions, see definitions later on. Boundary value problems such as x00 D f .x/; x.a/ D x.b/ D 0; will be discussed in Section 13.1 of Chapter 13.
Let us start by proving

Lemma 8.4.1. The second order equation

x00 D f .x/

(8.4)

is equivalent to the system

² x0 D y y0 D f .x/:

(8.5)

Moreover, the initial conditions x.0/ D x0; y.0/ D y0 for (8.5) correspond to the initial conditions x.0/ D x0; x0.0/ D y0 for (8.4).
Proof. Suppose that x, y is a solution of (8.5), with x.0/ D x0, y.0/ D y0. Then x0 D y implies x00 D y0 D f .x/ and x.0/ D x0, y.0/ D y0 imply x.0/ D x0, x0.0/ D y.0/ D y0. This shows that (8.5) implies (8.4).
Now, suppose that x00 D f .x/. Then if we let x0 D y, we obtain y0 D x00 D f .x/ and hence the system (8.5). Furthermore, the initial conditions x.0/ D x0, x0.0/ D y0 imply x.0/ D x0, y.0/ D x0.0/ D y0.

As a consequence of the preceding Lemma we can apply to x00 D f .x/ all the results of the preceding section. In particular:

1. The total energy

E.x; y/ D 1 y2 F .x/; y D x0 2

is constant along the solutions of x00 D f .x/. We let xc.t/ denote the solution of x00 D f .x/ with energy c, carried by E D c.
2. If E D c is a compact curve which does not contain any zero of f , then it carries a periodic solution of x00 D f .x/. Notice that the zeros of f are the equilibria of the system (8.5).
In the sequel we will discuss two specific examples that show the typical features of the arguments.

8.4 On the equation x00 D f .x/ 181

Fig. 8.7. 2y2 2x2 C x4 D c

8.4.1 A first example: The equation x00 D x x3

Consider the equation

x00 D x x3:

(8.6)

Here f .x/ D x x3 and hence there are 3 equilibria: 0; 1. The conservation of the energy becomes

E.x; y/ D 2y2 2x2 C x4 D c; y D x0:

(8.7)

Notice that E.x; y/ D c is symmetric with respect to x and y. Writing (8.7) as r c C 2x2 x4
yD 2

it follows that (see Figure 8.7):
(i) E.0; y/ D 2y2 D c yields c y D 0.

p 0 and y D  c=2. In particular, if c D 0, then

(ii) If y D 0, then E.x; 0/ D c becomes x4 2x2 D c. Plotting the graph of the function 2x2 x4 we see that 2x2 x4 Ä 1 and 2x2 x4 D 1 for x D 1. Then it follows that c D x4 2x2 1. Moreover, for c D 1, E.x; 0/ D 1
provided x D 1.

(iii) For all c > 0, E.x; y/ D c is a compact curve that does not contain equilibria and that crosses both x D 0 and y D 0.

(iv) For all 1 < c < 0, E.x; y/ D c is the union of two compact curves that do not contain equilibria and that do not cross x D 0.

(1) Periodic solutions. If c > 1, c 6D 0, then according to (iii­iv) the curve E.x; y/ D c is compact and does not contain equilibria and then xc.t/ is periodic. We have proved

182 8 Qualitative analysis of 2 2 systems and nonlinear second order equations
Theorem 8.4.2. If c > 1, c 6D 0, the equation x00 D x x3 has a periodic solution xc.t/ such that E.xc.t/; xc0 .t// D c.

(2) Homoclinic solutions.

Definition 8.4.3. We say x.t/ is a homoclinic to x0 (relative to the equation x00 D f .x/), if x.t/ is a solution such that limt!1 x.t/ D x0.

We are going to show that x00 D x x3 has homoclinics to 0. Let c D 0 and let x0C.t/ > 0 be the solution of (8.6) carried by the branch of

E.x; y/ D 2y2 2x2 C x4 D 0; y D x0

p

contained in without loss

the half plane x of generality, we

0. This curve crosses can assume that x0C.0/ D

tphe2x(aanxdis.xa0tCx/0.D0/

D

2 and, 0.).

Recall that x00 D x x3 is equivalent to the system

² x0 D y y0 D x x3

whose solution is denoted by x0C.t/; y0C.t/ and satisfies E.x0C.t/; y0C.t// D 0. For all t < 0, the point .x0C.t/; y0C.t// remains in the first quadrant. Then y0C.t/ > 0 for

t

<

0

and

hence

d dt

x0C.t /

D

y0C.t /

>

0.

Similarly,

d dt

x0C.t /

D

y0C.t /

<

0

for

t

>

0.

L

As as t

a consequence, ! C1 and L

x0C.t / is < x0C.0/

dDecpre2a.siMngorfeoorvter>, y00Ca.nt/d

hence converges

D

d dt

x0C.t

/

!

0.

to a limit From the

conservation of energy we deduce

E.x0C.t /; y0C.t // D 2.y0C.t //2 2.x0C.t //2 C .x0C.t //4 D 0: Passing to tphe limit as t ! C1 we infer that 0 2L2 C L4 D 0, that is L4 D 2L2. Since L < 2, it follows that L D 0, namely

lim
t !C1

x0C.t /

D

0:

Similarly, as t ! 1, one has

lim
t! 1

x0C.t /

D

0:

Moreover, x0C.t / is

E.x; y/ D the solution

0 is symmetric with respect to x and carried by the branch contained in the

y and hence half plane x

x0 Ä

.t 0.

/D The

graph of x0.t/ is reported in Figure 8.8. We have proved:

Theorem 8.4.4. Equation x00 D x x3 possesses one positive and one negative symmetric homoclinic to 0.

Notice that x0.t C h/ are also homoclinics to 0, for all h 2 R. Actually, according to Lemma 8.0.1, x0.t C h/ is a solution of x00 D x x3 and limt!1 x0.t C h/ D 0.

8.4 On the equation x00 D f .x/ 183

Fig. 8.8. Homoclinic solutions of x00 D x x3
Remark 8.4.5. In general, if x00 D f .x/ has a homoclinic to x0, then x0 is an equilibrium.

8.4.2 A second example: The equation x00 D x C x3

Consider the equation

x00 D x C x3:

(8.8)

As before, there are 3 equilibria 0; 1. The equation E.x; y/ D c becomes 2y2 C 2x2 x4 D c; y D x0:

The corresponding curves, which are symmetric with respect to x and y, are plotted in Figure 8.9. If 0 < c < 1, then E.x; y/ D c is a closed curve surrounding the origin and hence the corresponding solution is periodic.
The curve E.x; y/ D c passes through .1; 0/ provided c D 1. This gives rise to a new type of solutions, as we are going to see. Let e ¹E.x; y/ D 1º be the

y

-1

1

x

Fig. 8.9. 2y2 C 2x2 x4 D c: c D 1 (red); 0 < c < 1 (black); c > 1 (blue)

184 8 Qualitative analysis of 2 2 systems and nonlinear second order equations
x
1
t -1

Fig. 8.10. Symmetric heteroclinics of x00 D x C x3

arc contained in the upper half plane y > 0, joining the points . 1; 0/ and .1; 0/. The corresponding solution ex.t/ is strictly increasing, because y > 0. Repeating the arguments carried out in the homoclinic case, one shows that

lim ex.t/ D 1;
t! 1

lim ex.t/ D 1:
t !C1

Of course, for all h 2 R, any ex.t C h/ as well as ex.t C h/ is also a solution of x00 D x C x3 with the property that they tend to different limits as t ! 1 and t ! C1. See Figure 8.10. These solutions that join two different equilibria are
called heteroclinics.
We can state

Theorem 8.4.6. The equation x00 D x Cx3 possesses infinitely many heteroclinics.

8.5 Exercises

1. Find the equilibrium of

² x0 D x C 1 y0 D x C 3y 1:

2. Find a; b such that the equilibrium of
² x0 D x C 3y C a y0 D x y C b

is .1; 2/: 3. Find ;  such that

² x0 D x C y y0 D 2x C y

is hamiltonian.

8.5 Exercises 185

4. Discuss the family of conics x2 C Bxy C y2 D c depending on B; c. 5. Discuss the family of conics Ax2 xy C y2 D c depending on A; c.

6. Find C such that the system

² x0

DxCy

y0 D 2Cx y

has no periodic solution but the equilibrium x.t/ D y.t/ Á 0.
7. Show that if AC < 0 then all the nontrivial solutions of the system
² x0 D Bx C Cy y0 D Ax By

are not periodic.

8. Find B such that the system ² x0 D Bx C 3y y0 D 3x By

has periodic solutions.

9. Show that the solution of the system

8

^<^

x0 y0

D x Cy D 2x y

^^:

x .0/ y.0/

D1 D0

is periodic.

10. Show that the solution of the system

8 ^<^

x0 y0

D x 6y D 2x y

^:^

x .0/ y.0/

D1 D0

is unbounded.

11. Draw the phase plane portrait of the pendulum equation Lx00 C g sin x D 0

and discuss the behavior of the solutions.

12. Find the equilibria of the Lotka­Volterra system ² x0 D x xy y0 D y C xy:

13. Find the nontrivial equilibrium .x ; y / of ² x0 D 2x 7xy x y0 D y C 4xy y:

186 8 Qualitative analysis of 2 2 systems and nonlinear second order equations

14. Prove that there exists a periodic solution of the system ² x0 D 2x 2xy y0 D y C xy

such that x C 2y 4 D ln.xy2/.

15. Prove that there exists a periodic solution of the system ² x0 D x 4xy y0 D 2y C xy

such that x C 4y 4 D ln.x2y/.

16. Let x.t/; y.t/ be a T-periodic solution of the Lotka­Volterra system ² x0 D x.3 y/

y0 D y.x 5/:

Show

that

1 T

RT
0

x .t /d t

D

5

and

1 T

RT
0

y.t /d t

D

3.

p

17. Show that U.t/ D 2= cosh t is a homoclinic of the equation x00 D x x3.

18. Let x0.t/ be a homoclinic of x00 D x x3. Show that x0000.t/ ! 0 as t ! 1. Extend the result to any derivative of x0.t/.
19. Prove the preceding result for the heteroclinics of x00 D x C x3.

20. Show that the solution of x00 D

x

C

x3,

x .0/

D

0; x0.0/

D

1 2

is periodic.

21. Discuss the behavior of the solution of x00 D x C x3 such that x.0/ D 2,

x0.0/ D 0.

22. Discuss the behavior of the solutions x00 D x C x3 such that x.0/ D 0; x0.0/ D 1.

23. Show that the solution of x00 D x x3 such that x.0/ D 0; x0.0/ D 1 is periodic.

24. Show that the solution of x00 D x x3 such that x.0/ D 2; x0.0/ D 0 is periodic.

25. Show that the solution of x00 D x

x3

such

that

x .0/

D

p 1= 2;

x

0.0/

D

0

is

periodic.

26. Show that for all a 6D 0 the solution of x00 C x C 8x7 D 0, x.0/ D 0, x0.0/ D a is periodic.

27.

Discuss

the

behavior

of

the

solution

of

x00

C

x

C

1 3

x2

D 0, x.0/ D 1, x0.0/ D 0.

28. Show that the solution of x00

x

C 3x2

D

0, x.0/

D

1 2

,

x

0

.0/

D

0 is homoclinic

to x D 0.

29. Show that the solution of x00

x

C

3x2

D

0,

x .0/

D

1 4

,

x0.0/

D

0

is

periodic.

30. Discuss the behavior of the solution of x00 x C 3x2 D 0, x.0/ D 0, x0.0/ D 1.

31. Discuss the behavior of the solution of x00 x0.0/ D 0.

x C 3x2 D 0 such that x.0/ D

1 4

,

9 Sturm Liouville eigenvalue theory

In this chapter we deal with Dirichlet boundary value problems as

8 < x00.t/ C A.t/x0.t/ C B.t/x.t/ C C.t/x.t/ D 0

:

x.a/ D 0 x.b/ D 0

where a < b, is a real parameter and A; B; C are continuous functions in OEa; b.

Multiplying the

equation

by

the

integrating

factor

p .t /

D

Rt
e0

A.s/ds

one

finds

p.t/x00.t/ C p.t/A.t/x0 .t/ C p.t/B.t/x.t/ C p.t/C.t/x.t/ D 0:

Since p0 D Ap, then

OEpx00 D Apx0 C px00 D Apx0 C p. Ax0 Bx Cx/ D pBx pCx:

Hence, setting

r .t/ D p.t/B.t/; q.t/ D p.t/C.t/;

the equation becomes

Ä

d

dx

p .t /

dt

dt

C r .t/x.t/ C

q.t/x.t/ D 0:

From now on we will consider this equation where p.t/ > 0 and it is continuously differentiable. We will also assume that q.t/ Á6 0. Moreover, in the above equation, there are two terms involving x. We simplify the equation by letting r .t/ Á 0. This is equivalent to letting B.t/ Á 0.

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_9

188 9 Sturm Liouville eigenvalue theory
9.1 Eigenvalues and eigenfunctions

One of the solutions of

² .px0/0 C qx D 0 in OEa; b; x.a/ D x.b/ D 0

(9.1)

is obviously the trivial solution x.t/ Á 0.

Definition 9.1.1. We say that is an eigenvalue of the system (9.1) if it has a nontrivial solution, called an eigenfunction, corresponding to .

Remark 9.1.2. If '.t/ is an eigenfunction corresponding to an eigenvalue , so is c'.t/ for all c D6 0.

Theorem 9.1.3. If q.t/ > 0, then the eigenvalues of (9.1) are strictly positive.

Proof. Let be an eigenvalue of (9.1). Multiplying the equation by x.t/ and integrating on OEa; b we find

Zb

Zb

.p.t/x0.t//0 x.t/dt C

q.t/x2.t/dt D 0:

a

a

(9.2)

Integrating by parts, the first integral becomes
Zb .p.t/x0.t//0x.t/dt D .p.b/x0.b//x.b/ .p.a/x0.a//x.a/
a

Zb p.t/x0.t/x0.t/dt :
a

Since x.a/ D x.b/ D 0 we infer
Zb .p.t/x0.t//0x.t/dt D
a

Zb p .t /OEx 0 .t /2 d t :
a

Since that

pRa.btq/ .>t/x02a.nt/ddxt

.t / >

6Á 0.

0, this Taking

integral is strictly negative. From (9.2) again into account that q.t/ > 0 and x

it .t

follows / Á6 0 it

follows that > 0.

Theorem 9.1.4. Let 1 6D 2 be two different eigenvalues of (9.1) and denote by '1.t/; '2.t/ their corresponding eigenfunctions. Then
Zb q.t/'1.t/'2.t/dt D 0:
a

Proof. Multiplying .p'10 /0 C 1q'1 D 0 by '2 and integrating by parts from a to

b, we obtain

Zb

Zb

p'10 '20 dt D

1 '1 .t /'2 .t /q .t /d t :

a

a

9.2 Existence and properties of eigenvalues 189

Similarly, multiplying .p'20 /0 C 2q'2 D 0 by '1 and integrating by parts from a to

b, we obtain

Zb

Zb

p'10 '20 dt D

2 '1 .t /'2 .t /q .t /d t :

a

a

Therefore,

Zb

Zb

1'1.t/'2 .t/q.t/dt D

2'1.t/'2 .t/q.t/dt

a

a

which implies

Zb
'1.t/'2.t/q.t/dt D 0
a

if we assume that 1 ¤ 2.

Corollary 9.1.5. Eigenfunctions corresponding to different eigenvalues are linearly independent.

Proof. If '2 D '1 for some real number  6D 0 we would have

Zb

Zb

q.t/'1.t/'2.t/dt D  q.t/'12.t/dt D 0;

a

a

a contradiction.

9.2 Existence and properties of eigenvalues

Consider the case in which p D q Dp1. The equatipon becomes x00 C x D 0, whose general solution is x.t/ D c1 sin t C c2 cos t. Imposing the boundary

condition x.a/ D x.b/ D 0 we find the algebraic system in the unknowns c1; c2

²

p

p

c1 sin p a C c2 cos p a D 0

c1 sin b C c2 cos b D 0:

The system has the trivial solution c1 D c2 D 0. According to Kramer's rule, the

system has a nontrivial solution if and only if the determinant of the system is zero,

that is



p sin p sin

a b

p cos p cos

a b



D

p

p

sin a cos b

p

p

p

cos a sin b

D sin .a b/ D 0

p whence .a

Á2

b/ D k

, k D 1; 2; : : : Then for any

kD

k ba

, k D 1; 2; : : : ;

the problem has nontrivial solutions and hence k are the eigenvalues we were look-

ing for.

190 9 Sturm Liouville eigenvalue theory

Example 9.2.1. The eigenvalues of
² x00 C x D 0 x.0/ D x. / D 0

are k D k2, k D 1; 2; . The general solution is xk.t/ D c1 sin kt C c2 cos kt. The condition xk.0/ D 0 yields c2 D 0 and hence the eigenfunctions are 'k .t/ D C sin kt, C D6 0 a constant.

It is possible to extend the previous result to the general equation (9.1) yielding

Theorem 9.2.2. Suppose that q.t/ > 0. Then there exist infinitely many positive

eigenvalues k of (9.1) such that 0 < 1 < 2 < Moreover, k ! C1.

< k < kC1 < .

Proof. (Sketch) We outline the proof in the general case. Let xp; .t/ be the solution

of the initial value problem

8 < .p.t/x0.t//0 C q.t/x.t/ D 0

:

x.a/ D 0 x0.a/ D p:

If p 6D 0, then xp; .t/ 6Á 0. Thus if xp; .t/ has a zero at t D b, then xp; .t/ is an eigenfunction.
Notice that the solution is oscillatory. Denoting by k.p; / the k-th zero of xp; , let us solve the equation k.p; / D b. It is possible to show that, for each fixed p, k.p; / is continuous and increasing as a function of (see the graph plotted in Figure 9.1). Thus for each k D 1; 2; : : :, the equation k.p; / D b has a solution giving rise to an eigenvalue k . Moreover, one proves that 1.p; / > 2.p; / > : : : > k.p; / > : : : and this implies that 1 < 2 < .

We will always assume that q.t/ > 0 and denote by k OEq the eigenvalues of (9.1) and by 'k.t/ a corresponding eigenfunction.
The smallest eigenvalue 1OEq (also called the first or the principal eigenvalue)
has a "variational characterization" that we are going to outline. Multiplying .p'10 /0 C 1OEqq'1 D 0 by '1 and integrating by parts, one finds

Zb

Zb

p.t/'102.t/dt C 1OEq q.t/'12 .t/dt D 0:

a

a

It follows (recall that we are assuming q.t/ > 0) that

1OEq

D

Rb Rab
a

p.t q.t

/'102.t /dt /'12 .t /dt

:

Let C denote the class of functions 2 C 1.a; b/ such that .a/ D .b/ D 0.

9.2 Existence and properties of eigenvalues 191

1(.,)

 (.,) 2

k(.,)

b

a

 1 2 .... k

Fig. 9.1. Plot of k .p; / with p > 0

Theorem 9.2.3. One has

1 OEq 

Ä

Rb Rab
a

p.t q.t

/ /

02.t /dt ;
2 .t/dt

8 2 C:

Moreover,

1OEq D min

"

Rb Rab
a

p.t q.t

/ /

02.t /dt 2 .t/dt

W

# 2C :

(9.3)

The proof requires advanced topics and is omitted.

The inequality in the preceding Theorem is known as the PoincareK inequality. The

quotient

R.

/

D

Rb Rab
a

p.t q.t

/ /

02.t /dt 2 .t/dt

on the right-hand side is usually called the Rayleigh Quotient.

Example 9.2.4. If p D q D 1, a D 0; b D , the problem becomes x00 C x D 0,

x.0/ D x. / D 0 whose eigenvalues are k D k2, k D 1; 2; : : : ; see Example 9.2.1.

Thus one has

Z

Z

2.t/dt Ä

02.t/dt; 8 2 C:

0

0

Theorem 9.2.5. Let k OEqi , i D 1; 2, be the eigenvalues of .p.t/x0/0 C qi .t/x D 0, x.a/ D x.b/ D 0. If q1.t/ Ä q2.t/ for all t 2 OEa:b, then k OEq1 k OEq2 for all k D 1; 2; : : : .

192 9 Sturm Liouville eigenvalue theory

Proof. We prove the result for k D 1, using its variational characterization stated in

the preceding theorem. Since 0 < q1.t/ Ä q2.t/ on OEa; b, then for all 2 C one has

R1.

/

D

Rb Rab
a

p .t / q1.t /

02.t /dt 2 .t /d t

Rb Rab
a

p .t / q2.t /

02.t /dt 2 .t /d t

D R2.

/:

Since this inequality holds for all 2 C, the same holds for the minima of both sides, minima that are achieved, according to Theorem 9.2.3. Then we get

1OEq1 D min R1. / min R2. / D 1OEq2;

2C

2C

completing the proof.

Corollary 9.2.6. If 0 < m Ä q.t/ Ä M on OEa; b, then

2

2

M.b a/2 Ä 1OEq Ä m.b a/2 :

Proof. One has

1OEM  Ä

1OEq Ä

1OEm. Since

1OEm

D

2
m.b a/2

and

1OEM  D

2
M.b a/2 , the result follows.

Example 9.2.7. Let us show that the boundary value problem ² x00 C .x x3/ D 0 x.0/ D x. / D 0

has only the trivial solution if 0 Ä Ä 1. Multiplying the equation by x.t/, we get

xx00 D .x2 x4/ and hence

Z

Z

xx00dt D

.x2 x4/dt:

0

0

Integrating by parts the left integral and taking into account the boundary conditions

x.0/ D x. / D 0 we infer

Z

Z

x.t/x00.t/dt D

x02.t /dt

0

0

and thus, if 0, Z x02.t /dt D
0

Z .x 2 .t /
0

x4.t//dt Ä

Z x 2 .t /d t :
0

If, by contradiction, there is , with 0 < < 1, such that the boundary value problem

has a solution x.t/ 6Á 0, then

Z

Z

x02.t/dt < x2.t/dt:

0

0

9.3 An application to the heat equation 193

RB0utxt0h2.et

PoincareK inequality, /dt, a contradiction.

in

particular

Example

9.2.4,

yields

R
0

x 2 .t /d t

Ä

Finally, we state, without proof, a property concerning the zeros of eigenfunctions, that can easily be proved as an exercise in the specific case when p D q D 1.

Theorem 9.2.8. Any eigenfunction 'k.t/ of (9.1) has exactly k 1 zeros in the open interval .a; b/. In particular, '1 does not change sign in .a; b/.

Remark 9.2.9. In this chapter we have considered only the Dirichlet boundary con-

ditions x.a/ D x.b/ D 0. It is worth mentioning that one could also consider the Neumann boundary conditions x0.a/ D x0.b/ D 0, or else general mixed boundary

conditions

² 1x.a/ C 1x0.a/ D 0 2x.b/ C 2x0.b/ D 0

where the matrix

Â

Ã

1 1

2 2

is nonsingular, namely its determinant is different from zero. These cases require some changes. Some of them are proposed as exercises.

9.3 An application to the heat equation

The heat equation

@u @2u @t D @x2

(9.4)

is a partial differential equation that describes the variation of the temperature u.t; x/ at time t 0 and at a given point x of a rod of length ` D , that is for x 2 OE0; . Notice that here x is an independent variable, in contrast with the notation used before.
Given

X N f .x/ D fk sin kx D f1 sin x C f2 sin 2x C : : : C fN sin N x;
kD1

we look for u satisfying the initial condition

u.0; x/ D f .x/; x 2 OE0; ;

(9.5)

that prescribes the temperature at t D 0. Moreover, we require that the temperature is zero at the extrema of the rod, that is

u.t; 0/ D u.t; / D 0; 8 t 0:

(9.6)

194 9 Sturm Liouville eigenvalue theory

Let us point out that u is not identically zero provided f is not, which we assume throughout in the sequel.
Let us look for a solution of (9.4) by separation of the variables, namely seeking u.t; x/ as a product of a function of t and a function of x, that is in the form u.t; x/ D .t/ .x/. Since

@u D 0.t/ .x/; @t

@2u @x2 D

.t /

00 .x /

one finds

0.t/ .x/ D .t/ 00.x/; 8 t 0; 8 x 2 OE0; :

(9.7)

Since u ¤ 0 then ; ¤ 0 and we infer

0.t /

00.x/

D

; 8t

.t /

.x/

0; 8 x 2 OE0; :

Since the left hand side is a function of t only, while the right hand side is a function of x only, it follows that they are constant. Calling this constant, we find

0.t /

00.x/

D

D;

.t /

.x/

8 t 0; 8 x 2 OE0; :

Therefore (9.7) implies

0.t/ C .t/ D 0; 8 t 0

(9.8)

and

00.x/ C .x/ D 0; 8 x 2 OE0; :

(9.9)

Roughly, we

have

transformed

the heat

equation

@u @t

D

@2u @x2

into a

couple

of

ordinary

differential equations for the components .t/; .x/ of u.

Conversely, if .t/; .x/ satisfy (9.8) and (9.9) for the same constant , then

.t/ .x/ verifies (9.7). Moreover, u.t; x/ ¤ 0 whenever both .t/ ¤ 0 and .x/ ¤

0.

Next, the boundary condition (9.6) yields .0/ D . / D 0. To have a nontriv-

ial solution of (9.9) with these boundary conditions, has to be an eigenvalue of the problem 00 C D 0, .0/ D . / D 0, namely k D k2, with k D 1; 2; :::. Thus nontrivial solutions have the form k.x/ D Ak sin kx, Ak constant and k

any positive integer. For D k2 > 0 the equation 0 C k2 D 0 yields .t/ D Bke k2t , Bk constant,
and thus, setting Ck D AkBk, we find that any

uk.t; x/ D Ck e k2t sin kx;

k D 1; 2; :::

is a solution of the heat equation (9.4) satisfying the boundary conditions (9.5). Of course, any finite sum of these uk is a solution and so we can seek solutions in the

9.3 An application to the heat equation 195

form

X 1 u.t; x/ D Ck e

k2t sin kx:

kD1

We the

sfierrsitesprPoc1 keDed1

formally, k 2 Ck e

assuming this series k2t sin kx, obtained

is uniformly convergent together differentiating the series term by

with term

once w.r.t. t or twice w.r.t x.

If this is the case, we can find the constants Ck , using the initial condition u.0; x/ D f .x/, that is

X 1

X N

Ck sin kx D f .x/ D fk sin kx:

kD1

kD1

MultiplRying byPsin hx and integrating (recall that under our assumption we can exchange and ) we find

X 1 Z

X N Z

Ck sin hx sin kxdx D fk sin hx sin kxdx:

kD1

0

kD1

0

It is known that Z
sin hx sin kxdx D 0;
0

if h ¤ k;

Z

sin2 kxdx D :

0

2

TthheisseimriepsliePs t1 khDat1CCkkDe

fk for k k2t sin

kDx1r;e2d;u::c:e; sNtoanthdeCfiknDite0sfuomr alPl inN ktDeg1efr kke>

N
k2

and hence t sin kx.

This allows conclude that a

us to say solution

that the previous of (9.4) satifying

(f9o.r5m) aalndpr(o9c.6ed) uwriethisfcoDnsP istekNnDt1anfdk

we sin

can kx,

is given by

X N u.t; x/ D fk e

k2t sin kx:

kD1

For example, if f .x/ D 2 sin x 5 sin 3x we find u.t; x/ D 2e t sin x 5e 9t sin 3x. We complete this section by proving the following uniqueness result.

Theorem 9.3.1. The solution of (9.4) is uniquely determined by the boundary conditions (9.5) and the initial condition (9.6).

Proof. If u; v are two solutions of the preceding problem, then z D u

the heat equation

@z @t

D

@2z @x2

v satisfies

and the conditions ² z.0; x/
z.t; 0/

D 0; D z.t; / D 0;

8 x 2 OE0;  8 t 0:

196 9 Sturm Liouville eigenvalue theory

The theorem follows if we show that z.t; x/ Á 0. Let us set
Z I.t / D z2.t; x/dx:
0

We have

Z

Z

I 0.t / D 2 z.t; x/zt .t; x/dx D 2 z.t; x/zxx .t; x/dx:

0

0

Integrating by parts and taking into account the boundary conditions z.t; 0/ D

z.t; / D 0, we find

Z

I 0.t / D 2 zx2 .t; x/dx:
0

If, by contradiction, z Á6 0 we have I.t / > 0 and I 0.t / < 0 which implies 0 < I.t / < I.0/. Since z.0; x/ D 0 for all x 2 OE0; , then
Z I.0/ D z2.0; x/dx D 0
0

and we get a contradiction.

9.4 Exercises
1. If  > 0, find the eigenvalues of x00 C x D 0, x.0/ D x.b/ D 0. 2. If  > 0, find the eigenvalues of x00 C x D 0, x.0/ D x.b/ D 0. 3. Estimate the eigenvalues of x00 C .1 C t/x D 0, x.0/ D x.1/ D 0. 4. Estimate the first eigenvalue of x00 C et x D 0, x.0/ D x.2/ D 0. 5. Show that the first eigenvalue 1 of .t2x0/0 C x D 0, x.0/ D x. / D 0 is
smaller or equal to 2.
6. If 0 <  Ä p.t/ Ä  in OEa; b, estimate the first eigenvalue 1 of .p.t/x0/0 C x D 0, x.a/ D x.b/ D 0.
7. Estimate the first eigenvalue 1 of .p.t/x0/0 C q.t/x D 0, x.a/ D x.b/ D 0, under the assumption that 0 <  Ä p.t/ Ä  and 0 < m Ä q.t/ Ä M in OEa; b.
8. Let 1OEq, resp. e1OEq, be the first eigenvalue of .p.t/x0/0 C q.t/x D 0, resp. .ep.t/x0/0 C q.t/x D 0, with the boundary conditions x.a/ D x.b/ D 0. If p.t/ Ä ep.t/ for all t 2 OEa; b, show that 1OEq Ä e1OEq.
9. Show that the eigenvalues of x00 C x D 0, x0.a/ D x0.b/ D 0 cannot be strictly negative.
10. Find the eigenvalues of x00 C x D 0, x0.0/ D x0. / D 0. 11. Find the eigenvalues of x00 C x D 0, x.0/ D x0. / D 0.

9.4 Exercises 197

12. Let x.t/ be a solution of the nonhomogeneous problem x00 C kq.t/x D h.t/,

x.a/ D x.b/ D 0, where k eigenfunction 'k. Prove that

RDb
a

kOEq is the n-th eigenvalue h.t/'k .t/dt D 0.

with

corresponding

13.

Setting L.u/ D .p.t/u0/0 vRaub 0L//.0v. /Dueddtu.ce that if u.a/

C r .t/u, show that L.u/v D v.a/ D u.b/ D v.b/ D

0,Lth.evn/uRabDL..up/.vudvt0

D

14. Solve ut D uxx , u.0; x/ D  sin x, u.t; 0/ D u.t; / D 0.

15. Solve ut D c2uxx , u.0; x/ D  sin x, with the boundary condition u.t; 0/ D u.t; / D 0.

16. Solve ut D uxx , u.0; x/ D  sin

x L

, with the boundary condition u.t; 0/

D

u.t; L/ D 0.

10 Solutions by infinite series and Bessel functions

10.1 Solving second order equations by series

It should be clear by now that the methods for solving differential equations thus far

have been limited and applicable only to certain types of equations.

In this chapter we discuss methods of finding solutions of linear differential equa-

tions by using series x.t/ D

pPowaekrtskeriinetso.

The basic idea is to substitute, the equation and use the fact

ftohramt Pallyb,katnk

inDfinPitecpkotwk eirf

and only if bk D ck for all k 2 N. In this way, one tries to find a recursive formula

that allows us to determine the coefficients of the desired series. One assumes that

the series is absolutely convergent, that is analytic, in some interval I so that it can

be differentiated term by term. After determining the coefficients of the power series,

one tries to find its radius of convergence by some method such as the ratio test.

10.2 Brief review of power series

Recall the following properties of power series.

1. Shifting indices: one can easily verify that

Xn

nX C1

nX2

akt k D

ak 1t k 1 D

akC2t kC2:

3

4

1

Such shifting of indices is important in calculating series solutions. It is easy to remember that in order to increase (or decrease) the indices in the summation by m, we must decrease (or increase) the limits of summation by m.

2. With each power series

X 1 ak .t t0/k
kD0

(10.1)

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_10

200 10 Solutions by infinite series and Bessel functions

is associated a radius of convergence R, R 0, with the following properties:

(a) R > 0 and the power series (10.1) is absolutely convergent if jt t0j < R and it is divergent if jt t0j > R. For jt t0j D R, it can go either way

depending on the particular power series. In this case we say that the interval

of convergence is jt t0j < R.

(b) R D 0 and the power series converges only for t D t0.

(c) R D 1 and the power series converges for all t, with the interval of conver-

gence . 1; 1/. The easiest way to evaluate the radius of convergence is the

ratio test which states that

1 R

D

lim
n!1



anC1 an



;

provided the limit exists. 3. If a power series is absolutely convergent, then it is convergent. The converse is
false.

4. When a function f .t/ has a power series representation at t D t0, with a positive radius of convergence, then f .t/ is said to be analytic at t D t0. In such a case, the series can be differentiated term by term infinitely many times, with the derivatives having the same radius of convergence.

5. An analytic function has a unique power series representation, within its radius of convergence, which is given by the Taylor series

f .t / D X 1 f .k/.t0/ .t kS
kD0

t0 /k :

For example, in order to show that

1

X 1 D tk D 1 C t C t2 C ::: C tk C :::

1t

0

is valid for 1 < t < 1, instead of using the Taylor expansion, we simply use long division and, dividing 1 by 1 t, obtain

1

X 1 D tk:

1t

kD0

In order to find its interval of convergence, we use the ratio test. Thus we have

lim
k!1



t

kC1
tk



D

jt j:

This shows that the radius of convergence is R D 1 and hence

1

X 1 D tk

1t

0

10.3 Series solutions around ordinary points 201
for 1 < t < 1. Furthermore, this representation, in terms of powers of t, is unique. So, if we use the Taylor expansion for f .t/ D 1=.1 t/ around t D 0, we will get the same series. Lastly, we note that for t > 1, the above series representation does not hold. But we can find its Taylor expansion around t D 3, for example.

10.3 Series solutions around ordinary points

Consider the differential equation

a0.t /x.n/ C a1.t /x.n 1/ C ::: C an.t /x.t / D 0

where the function ai .t/; 1 Ä i Ä n; is analytic at t D t0, with convergent power series in an interval Ri t0 < t < Ri C t0.
If a0.t0/ ¤ 0, then t0 is called an ordinary point. If a0.t0/ D 0, then it is called a singular point. At an ordinary point t D t0, the above differential equation has a unique power series solution at t D t0, for any initial value problem x.t0/ D 0; :::; x.n 1/.t0/ D n 1. The radius of convergence of the solution is at least as large as the smallest of the radii of convergence of the power series of the coefficients ai , 0 Ä i Ä n.
Singular points are more of a problem. At such points there may not exist analytic
solutions. Special cases of such points will be discussed later.
The examples below demonstrate the general procedure for determining series
solutions at ordinary points.

Example 10.3.1. We know that the general solution of x0 D x is x.t/ D cet . Let us find this by using infinite power series. Setting
X x.t / D ak t k D a0 C a1t C a2t 2 C : : : C akt k C : : :
k0

we find

X x0.t / D kak t k 1 D a1 C 2a2t C : : : C kakt k 1 C : : : :
k1

The equation x0

x D 0 yields X kak t k 1
k1

X akt k D 0:
k0

Our goal now is to make the powers of t the same in both summations so that we can

factor it out and set the coefficients equal to 0. We can accomplish this in more than

one way. But let us increase the power of t in the first sum by 1, which means that

we have to shift down the starting point by 1. Then we obtain

X

X

X

.k C 1/akC1t k

ak t k D OE.k C 1/akC1 akt k D 0:

k0

k0

k0

202 10 Solutions by infinite series and Bessel functions

Now setting the coefficients equal to 0, we have .k C 1/akC1 us the recursive formula
1 akC1 D k C 1 ak; k D 0; 1; : : : :

ak D 0, which gives

Thus

a1 D a0;

11 a2 D 2 a1 D 2 a0;

a3

D

1 3 a2

D

1 3

1 2 a0

D

1 3S a0;

It is now clear that in general we have

ak

D

ak 1 k

D

ak k.k

2
1/

D

a4

D

1 4 a3

D

1 4S a0; : : :

:

D

a0

D a0 :

k.k 1/ 2 kS

Therefore the general solution to the given differential equation is

x .t /

D

a0

X 1

1 tk: kS

kD0

We note that the above sum is the Taylor expansion for et ; therefore the general solution is x.t/ D a0et , where a0 is an arbitrary constant.

Example 10.3.2. Let us use power series to solve the initial value problem

x00 D x; x.0/ D 0; x0.0/ D c:

P We set x D k

0 ak t k D a0 C a1t C a2t 2 C : : : C akt k C : : : . The condition

x.0/ D 0 implies that a0 D 0.

We may use a slightly different procedure to find the recursive formula, as follows.

We find

X

x0 D

kakt k 1 D a1 C 2a2t C 3a3t 2 C : : : C kak t k 1 C : : :

k1

X

x00 D

k.k 1/ak t k 2

k2

D 2a2 C 2 3 a3t C 3 4 a4t 2 C : : : C k.k 1/akt k 2 C : : : :

Then x00 D x, x.0/ D 0, yields a0 D 0 and

X

X

k.k 1/ak t k 2 D ak t k;

k2

k1

that is

2a2 C 2 3 a3t C 3 4 a4t 2 C : : : C k.k 1/ak t k 2 C : : : D a1t C a2t 2 C a3t 2 C : : : C ak t k C : : : :

10.3 Series solutions around ordinary points 203

This equality implies

2a2 D 0; 2 3 a3 D a1; 3 4 a4 D a2; : : : ; k.k 1/ak D ak 2

that is

a2

D

0;

a3

D

a1 23

D

a1 ; 3S

a4

D

a2 34

D

0;

a5

D

a1 ; 5S

a6

D

0; : : :

:

In general, ak D 0 if k is even, while if k is odd

ak

D

ak k.k

2D 1/ k.k

ak 4 1/.k 2/.k

D 3/

D a1 : kS

Thus, setting c D a1, we find

Â t3 t5

Ã

x.t/ D c t C C C ::: :

3S 5S

The series is absolutely convergent on all of R. This can be verified by using the ratio

test since

lim
n!1



anC1 an



D

lim
n!1

1 .2nC3/S
1 .2nC1/S

.2n C 1/S

D

lim
n!1

.2n

C

3/S

D

0:

Let

us

recall

that

t

C

t3 3S

C

t5 5S

C

:::

D

sinh

t.

In

other

words,

x .t /

D

c

sinh

t,

which

can also be found by using the methods discussed in Chapter 5.

EPx1 kaDm2pkl.ek10.31./3a.kFtiknd2,xt.hte/

D

P1
kD0

ak

equation x00

t

k
t

that solves x00 2x D 0 yields

D

t 2x. Since x00.t /

D

X 1 k.k
kD2

1/ak t k 2

X 1 ak t kC2 D 0:
kD0

Once gain, our goal is to combine the two series into one series, factor out the powers of t, and then set the coefficients equal to zero, which will give us the desired recursive formula. To this end, let us increase the power of t in the first sum by 2, which requires that we decrease the lower limit by 2, and also shift down the power of t in the second series by 2, obtaining

X 1 .k C 2/.k C 1/akC2t k
kD0

X 1 ak 2t k D 0:
kD2

Now, everything is fine except that one of the sums starts at k D 0 and the other at k D 2, which means we still cannot combine the two sums. But this problem is easy to resolve by simply writing the first two terms of the first series separately. Thus we

204 10 Solutions by infinite series and Bessel functions

have

X 1

X 1

2 1 a2 C 3 2 a3 t C .k C 2/.k C 1/akC2t k

ak 2t k D

kD2

kD2

X 1 2a2 C 6a3 t C OE.k C 2/.k C 1/akC2 ak 2 t k :

kD2

Now we set the coefficients equal to 0, obtaining a2 D a3 D 0 and .k C 2/.k C 1/akC2 ak 2 D 0, which gives us the recursive formula

akC2

D

.k

ak 2 C 2/.k

C

; 1/

k D 2; 3; : : :

which can also be written as

akC4

D

.k

ak C 4/.k

; C 3/

k 0:

Now we can compute as many terms of the series solution as we wish, which with the aid of computer technology, gives us the approximate solution to any initial value problem to a desired degree of accuracy. So, our big task in solving differential equations by series is finding the recursive formula. However, it is instructive to continue analyzing and simplifying this problem further.
Recall from above that our recursive formula is complemented by a2 D a3 D 0, while a0; a1 remain undetermined. Notice that if k D 0; 1; 2; 3, we find

a4

D

a0 4.4 1/

D

a0 43

a5

D

a1 5.5 1/

D

a1 54

a6

D

a2 6.6 1/

D

0

a7

D

a3 7.7 1/

D

0:

This suggests to distinguish four cases: 1. If k D 4n, then

a4nC4 D a4.nC1/

D

a4n .4n C 4/ .4n C 4

1/

D

a4.n 1/

4.n C 1/ OE4.n C 1/ 1 4n .4n 1/

D

D

a0

:

4.n C 1/ OE4.n C 1/ 1 4 3

10.3 Series solutions around ordinary points 205

2. If k D 4n C 1, then

a4.nC1/C1

D

a4nC1 OE4.n C 1/ C 1 4.n C 1/

D

a4.n 1/C1

OE4.n C 1/ C 1 4.n C 1/ 4.n 1/ OE4.n 1/ 1

D

D

a1

:

OE4.n C 1/ C 1 4.n C 1/ 5 4

3. If k D 4n C 2, then

a4.nC1/C2

D

a4nC2 OE4.n C 1/ C 2 OE4.n C 1/ C 1

D

D

a2

OE4.n C 1/ C 2 OE4.n C 1/ C 1

D 0:

4. If k D 4n C 3, then

a4.nC1/C3

D

a4nC3 OE4.n C 1/ C 3 OE4.n C 1/ C 2

D

D

a3

OE4.n C 1/ C 3 OE4.n C 1/ C 2

D 0:

In conclusion, the solution depends on the two constants a0; a1 and has the form

x .t /

D

X

a0
n

0 4.n C 1/

t 4n OE4.n C 1/

1

43

C

a1

X

OE4.n

C

1/

C

t 4nC1 1 4.n

C

1/

54

n0

Â

t4

t8

Ã

Â

t5

t9

Ã

D

a0

1C C

C ::

43 8743

C a1

tC C

C ::

54 9854

which is the general solution of x00 D t2x. If we were interested, for example, in a solution x.t/ satisfying the initial conditions x.0/ D 1; x0.0/ D 0, then in the last
equation we would simply let a1 D 0 and a0 D 1.

In general, one has to be careful not to generalize too quickly based only on a few terms. In the preceding example if one evaluates only the first 3 terms, one might be tempted to think that all the coefficients a2; a3; etc. are zero, which, of course, would be false.

206 10 Solutions by infinite series and Bessel functions
10.4 The Frobenius method

In this and the next section we deal with some equations containing singular points. Let us start by considering the first order linear equation

a0.t /x0 C a1.t /x D 0

in which, say, t D 0 is a singular point. Although it is obvious that this problem can be solved by the method of separation
of variables, here, by way of motivation, we demonstrate a method that will yield the solutions in terms of infinite series.
For the sake of simplicity we consider

tx0 C .3 C 4t/x D 0:

(10.2)

It can easily be verified that if we try to find series solutions for this problem by the

earlier method of letting

X 1 x D akt k

kD0

we will only obtain the trivial solution. Let us try

X 1

X 1

x.t / D t r ak t k D ak t rCk

kD0

kD0

where r is to be determined. Notice that

X 1

X 1

tx0.t / D t .r C k/ak t rCk 1 D .r C k/ak t rCk:

kD0

kD0

Substituting in (10.2) we get

X 1

X 1

.r C k/ak t rCk C .3 C 4t / akt rCk D 0

kD0

kD0

and hence

X 1

X 1

.r C k C 3/ak t rCk C 4akt rCkC1 D 0:

kD0

kD0

Shifting indices in the second series we deduce

X 1

X 1

.r C k C 3/akt rCk C 4ak 1t rCk D 0;

kD0

kD1

10.4 The Frobenius method 207

or X 1
.r C 3/a0t r C OE.r C k C 3/ak C 4ak 1t rCk D 0:
kD1
Since all the coefficients of the series have to be zero, we set

.r C 3/a0 D 0; .r C k C 3/ak C 4ak 1 D 0; for all k 1:

If a0 D 0 then the recursive formula .r C k C 3/ak D 4ak 1 yields ak D 0 for all k 2 N and hence we get the trivial solution.
If a0 ¤ 0, then we must have r D 3, which reduces the above equations to the
simple equation

kak C 4ak 1 D 0;

i:e: ak D

4 k ak 1;

k

1:

Therefore,

ak D

4 k ak

1D

42

Â

D

k.k 1/

4 k

Â

4 k 1 ak

Ã
2

D

42 k.k

1/ ak

2

Ã 4

43

k 2 ak 3 D k.k 1/.k 2/ ak 3

D ::: D .

1/k

4k kS

a0:

Then we find that the solution to (10.2) is given by

X 1 xD .

1/k

4k kS

a0

tk

3 D a0 t

X 1 3.

1/k 4k t k : kS

kD0

kD0

Since

X 1 .

1/k 4k t k D X 1 .

4/k t k D e

4t ;

kS

kS

kD0

kD0

we get

x D a0 t 3 e 4t ;

which includes, for a0 D 0, the trivial solution found above. Let us point out that, as anticipated, we can obtain the same result by integrating
the separable equation

x0 C 3 C 4t x D 0;

i:e:

x0 D

3

4;

t

xt

yielding ln jxj D 3 ln jtj 4t, whereby x D c t 3e 4t .
As an exercise, the student can repeat the preceding calculations to show that the solutions of tx0 C .q0 C q1t/x D 0 are given by x D c t q0 e q1t . Notice that if

208 10 Solutions by infinite series and Bessel functions
q0 < 0 there are infinitely many solutions passing through .0; 0/, while if q0 > 0 no solution but the trivial one is defined for t D 0. In any case, there is no solution satisfying the initial condition x.0/ D x0 ¤ 0. This can also be deduced by the fact that, setting t D 0 in the equation tx0 C.q0 Cq1t/x D 0, we get q0x.0/ D 0 whereby x.0/ D 0.

Next, we consider the second order linear equation

p0.t /x00 C p1.t /x0 C p2.t /x D 0

where the coefficient functions pi .t/ are continuous, and t D 0 is a singular point, i.e. p0.0/ D 0, and furthermore

t p1.t / ; t 2 p2.t /

p0.t /

p0.t /

are analytic at t D 0. In such a case, t D 0 is called a regular singular point. We briefly discuss a general method, due to F.G.Frobenius 1, to solve such prob-
lems by using infinite series. Precisely, extending the procedure discussed above for the first order linear equation tx0 C .3 C 4t/x D 0, we are going to show that one
can find a solution by substituting

X 1

X 1

tr

ak t k D

ak t kCr

kD0

kD0

for some number r . To be specific, let us consider the equation

t 2x00 C tP .t /x0 C Q.t /x D 0

(10.3)

under point.

tIhfewaessluomokptfioornstohlauttiPon; sQofartehepofolyrmnoxm.ita/lsD. CtleraPrlyk

t

D0 0 ak t

is
k

a rePgular D k0

singular ak t kCr ,

with r > 0, we have:

X

X

tx0 D t .k C r /akt kCr 1 D .k C r /akt kCr

k0

k0

X

X

t 2x00 D t 2 .k C r /.k C r 1/akt kCr 2 D .k C r /.k C r 1/akt kCr :

k0

k0

Thus, the equation becomes

X

X

X

.k C r /.k C r 1/akt kCr C P .t / .k C r /ak t kCr C Q.t / ak t kCr D 0;

k0

k0

k0

1 F.G. Frobenius (1849-1917).

10.4 The Frobenius method 209

whence X .k C r /.k C r
k0

1/akt kCr C P .t /.k C r /akt kCr C Q.t /ak t kCr D 0:

or

X

OE.k C r /.k C r 1/ C P .t/.k C r / C Q.t/ ak tkCr D 0;

k0

namely

OEr .r 1X / C P .t/r C Q.t/ a0tr C OE.k C r /.k C r 1/ C P .t/.k C r / C Q.t/ aktkCr D 0:
k1

To simplify calculations, let us consider the more specific case in which P .t/ D p0 and Q.t/ D q0 C q1t. It follows

OEr .r

1/ C X

p0r

C

.q0

C

q1t /

a0t r

C

C OE.k C r /.k C r 1/ C p0.k C r / C .q0 C q1t / akt kCr

k1

D OEr .r X1/ C p0r C q0 a0t r C q1a0t rC1 C C OE.k C r /.k C r 1/ C p0.k C r / C q0 ak t kCr C q1akt kCrC1 D 0:

k1

If we introduce the second order polynomial

F .r / D r .r 1/ C rp0 C q0;

the preceding equation can be written as
F .r /a0t r C q1a0t rC1 C F .r C 1/a1t rC1 C q1a1t rC2 CF .r C 2/a2t rC2 C q1a2t rC3 C : : : D 0:
All the coefficients of the power trCk have to be zero and hence we deduce

and, in general,

F .r /a0 D 0 F .r C 1/a1 C q1a0 D 0 F .r C 2/a2 C q1a1 D 0
::: :::

F .r /a0 D 0; F .r C k/ak C q1ak 1 D 0; k D 1; 2; : : : :
If F .r / 6D 0 we find that a0 D 0. Moreover, if F .r C 1/ 6D 0 then F .r C 1/a1 D 0 yields a1 D 0 and so on: if F .r C k/ D6 0 for all k 0 then all the ak are 0 and the procedure gives the trivial solution.

210 10 Solutions by infinite series and Bessel functions

The equation F .r / D 0 is called the indicial equation and is a second order algebraic equation. Its roots are called the characteristic exponents of (10.3).
Let r1 be a root of F .r / D 0. Now, if we put r D r1 in the preceding recursive formulae, a0 remains undetermined, while

a1 F .r1 C 1/ D q1a0 a2 F .r1 C 2/ D q1a1
: : : : : : :: ak F .r1 C k/ D q1ak 1:

Then for all k 1 such that F .r1 C k/ 6D 0, these equations allow us to find ak while if F .r1 C k/ D 0 for some k, the corresponding ak remains undetermined. It can be shown that the corresponding series converges uniformly on R. So, the formal procedure is consistent and
X x.t / D t r1 akt k
k0

is a solution of (10.3). For example, if F .r1 C k/ D6 0 for all k 1, one finds

a1 D

q1

F

a0 .r1 C

1/

a2 D

q1

F

a1 .r1 C

2/

D

q12 F .r1

C

a0 1/F .r1

C

2/

a3 D

q1

F

a2 .r1 C

3/

D

q13

F

.r1

C

1/F

a0 .r1 C

2/F

.r1

C

3/

:::: ::::

ak

D

.

1/k q1k

F

.r1

C

1/F

.r1

a0 C 2/

F .r1 C k/

and the solution x.t/ will depend on the constant a0.

Example 10.4.1. Find a solution of t2x00 C tx0 C .t 1/x D 0. Here p0 D 1, q0 D 1 and q1 D 1. Thus the indicial equation is
F .r / D r .r 1/ C r 1 D r 2 1

whose roots are 1. Taking r D 1 we find F .k C 1/ D .k C 1/2 which vanishes if and only if k D 0. Thus for k D 1; 2 : : : we find

ak D .

1/k 3

8

a0

:

k.k C 2/

1 D k.k C 2/

Hence a solution is

X

x.t/ D a0t

. 1/k 38

k1

tk ;
k.k C 2/

which depends upon a constant a0.

10.5 The Bessel equations 211

Finding a second solution y.t/, linearly independent of the preceding one, requires

some caution. Referring e.g. to the book by E.L. Ince (see Bibliography) for a com-

plete discussion, we limit ourselves to simply stating that if r1; r2 are the roots of the

indicial equation, one should distinguish among 3 cases:

1.

If

r1

6D

r2

and

they

do

not

differ

by

an

integer,

then

y.t /

D

t r2

P
k

0 bkt k, where

2.

bk satisfies the recursive formula bkF .r2 C k/ D If r1 6D r2 and they differ by an integer, then y.t/

q1bk D cx.t

1. / ln

t

C

t

r2

P
k

0 bkt k ,

where the constant c can be zero.

3.

If

r1

D

r2,

then

y.t /

D

x .t /

ln

t

C t r1

P
k

0 bktk where bk has to be determined.

Example 10.4.2. Consider the equation t2x00 C2tx0 `.`C1/x D 0 with ` > 0, that arises in solving the 3D Laplace equation in spherical coordinates. This is an Euler equation. Here we use the Frobenius method to find solutions. The given equation is of the form (10.3) with p0 D 2, q0 D `.` C 1/ and q1 D 0. Then we have
ak F .r1 C k/ D 0; k D 1; 2; : : : :
The indicial equation is F .r / D r .r 1/C2r `.`C1/ D 0, that is r 2Cr `.`C1/ D 0, whose roots are r1 D `; r2 D .` C 1/. Taking r D ` one finds
F .` C k/ D .` C k/.` C k 1/ C 2.` C k/ `.` C 1/ D k.4` C 3k C 1/ > 0; 8 k D 1; 2; : : : :

Thus ak D 0 for all k 1. Taking for example a0 D 1, a solution is given by x.t/ D t`. Even if the two roots may differ by an integer, in this specific case a second linearly independent solution can be found in the form y.t/ D t .`C1/. It is easy to check that the two functions t` and t .`C1/ are linearly independent and so
the general solution is x.t / D c1t ` C c2t .`C1/.

10.5 The Bessel equations

In this Section we consider the Bessel2 equations, namely t 2x00 C tx0 C .t 2 m2/x D 0:

(10.4)

The number m is called the order of the Bessel equation and could be an integer or a rational number.
Bessel equations arise in applications when solving the Laplace equation or the wave equation, in 3-dimensional space, using the method of separation of variables. For completeness, we briefly outline how it works in the case of the Laplace equation.

2 Friedrich Wilhelm Bessel (1784­1846).

212 10 Solutions by infinite series and Bessel functions

The 3-D Laplace equation uxx C uyy C uzz D 0 in cylindrical coordinates x D r cos ; y D r sin ; z can be written as

1 r .rur /r

C

1 r2

u

C uzz D 0:

Looking for solutions in the form u.r; ; z/ D R.r/^. /Z.z/ one checks that the equation

becomes

1 rR .rRr /r

C

1 r2^^

C

1 Z Zzz

D

0:

The

only term

containing

z

is

1 Z

Zzz ,

which therefore

has

to

be

constant, say

k2.

Then

1 Z

Zzz

D

k2, namely Zzz D k2Z, which yields

1

1

rR .rRr /r C r2^ ^

and, multiplying by r2, we obtain

C k2 D 0

r R .rRr /r

C

1 ^
^

C k2r2 D 0:

The only term containing

is

1 ^

^

and

hence

it

has

to

be

constant,

say

1 ^

^

D A, namely

^ D A^. Since we expect that ^ is periodic with respect to , we take A D m2 so that

we get ^ Cm2^ D 0, the equation of a harmonic oscillator. Then we can write the equation

for R.r/ as

r.rRr /r C .k2r2 m2/R D 0

that is

r2Rrr C rRr C .k2r2 m2/R D 0:

Finally, setting t D kr and x.t / D R.r=k/, we find x0.t / D k 1Rr , x00.t / D k 2Rrr . Thus rRr D krx0 D tx0, r2Rrr D r2k2x00 D t 2x00 whence

t 2x00.t / C tx0.t / C .t 2 m2/x.t / D 0;

which is the Bessel equation of order m.

Now, let us solve the Bessel equations. Even if t D 0 is a regular singular point,

we do not follow the simpler way by using

tgheenseerrailesFrPobk1eDn0iuaskmt ke.tThohdo,ubguhtinwgeepnreerfaelrthtoishmanetdhloed(1g0iv.4e)s

in a rise

to

the trivial Setting x

solP ution D ak

(i.e. ak D 0 tk, we find

for

all

k),

it

works

in

the

case

of

Bessel

equations.

X

tx0 D

kak t k D a1t C 2a2t 2 C 3a3t 3 C : : : C kakt k C : : :

k1

X

t 2x00 D

k.k 1/ak t k

k2

D 2a2t 2 C 3 2a3t 3 C 4 3t4 C : : : C k.k 1/ak t k C : : : :

10.5 The Bessel equations 213

Then x solves the Bessel equation (10.4) provided

X

X

k.k 1/ak t k C kak t k C .t 2

k2

k1

X m2/ ak t k D 0:
k0

We can write this equality in the form

X

X

X

X

k.k 1/akt k C kakt k m2 ak t k C ak t kC2 D 0:

k2

k1

k0

k0

(10.5)

In the sequel we will carry out a detailed discussion in the cases m D 0; 1. The other cases will be sketched only.

10.5.1 The Bessel equation of order 0

When m D 0 we have

t2x00 C tx0 C t2x D 0

(10.6)

which is the Bessel equation of order 0. If m D 0 the preceding equality (10.5) be-

comes

X

X

X

k.k 1/ak t k C kakt k C akt kC2 D 0:

k2

k1

k0

Since

X

X

kak t k D a1t C kakt k

k1

k2

and

X

X

akt kC2 D ak 2t k;

k0

k2

we infer

X k.k
k2

X

X

1/akt k C kakt k C ak 2t k C a1t D 0:

k2

k2

Simplifying, we have

X

X

k2ak t k C ak 2t k C a1t D 0:

k2

k2

Then a1 D 0 and, for k 2, k2ak C ak 2 D 0 H) ak D

In other words,

ak D 0 if k is odd;

ak k2

2

:

while, for k even, we find

a2 D

a0 22

;

a4

D

a2 42

D

a0 22 42

;

:

:

:

:

214 10 Solutions by infinite series and Bessel functions

In general we have, for k even,

ak D .

1/k=2 22

a0 42

k2 :

Then a first family of solutions of the Bessel equation with m D 0 is given by

Â

t2

t4

t6

Ã

x.t / D a0 1 22 C 22 42 22 42 62 C

;

where the series turns out to be uniformly convergent on all R.

If we set

J0.t/ D 1 D1

12t 22ÂCt Ã222t

4
42 1

t6 Â t22Ã442

62 C 1

Â t Ã6

2 2 C 22 2

.2 3/2 2 C

X.

1/k

Â t

Ã2k

D

.kS/2 2

k0

we have that all the functions x.t/ D cJ0.t/ solve the Bessel equation of order 0. The function J0 is analytic, even and J0.0/ D 1. Moreover, it is possible to show
that J0 has the following properties (as for the first two, see also Theorem 10.5.4):

1. It has infinitely many zeros.

2. It decays to zero at infinity.

3.

It

is

integrable

on

all

RC

and

R C1
0

J0 .t

/d t

D 1.

The graph of J0.t/ is shown in Figure 10.1. The function J0 is called the Bessel function of order 0, of first type, to distinguish it from another solution that we are going to find.

x

t
Fig. 10.1. Graph of J0.t /

10.5 The Bessel equations 215

To find a second solution Y0.t/ of (10.4) linearly independent of J0 we can use
the method of reduction of order discussed in Chapter 5, Section 5.3. We let Y0.t/ D v.t /J0.t /. Then Y00 D v0J0 C vJ00 and Y000 D v00J0 C 2v0J00 C vJ000. Substituting into (10.4) we find

t 2.v00J0 C 2v0J0 C vJ000/ C t .v0J0 C vJ00 / C t 2vJ0 D 0:

Rearranging,

v.t 2J000 C tJ00 C t 2J0/ C tJ0.t v00 C v0/ D 0:

Since J0 solves (10.4) it follows that

tJ0.t v00 C v0/ D 0:

Solving tv00 C v0 D 0 we find either v D const: or, setting z D v0, tz0 D z which

is separable.

Integrating we

find

z

D

1 t

and

hence

v

D

ln t,

t

>

0. Then

we

have

found

Y0.t/ D ln t J0.t/; t > 0:

Similar to J0, Y0 also has infinitely many zeros (the same as J0), but unlike J0, Y0 has a singularity at t D 0. It is named a Bessel function of order 0 of the second kind. The graph of Y0 is shown below in Figure 10.2.
Since J0 and Y0 are linearly independent, the general solution of the Bessel equation of order 0 is given by
x.t / D c1J0.t / C c2Y0.t / D c1J0.t / C c2 ln t J0.t /:
Example 10.5.1. Find a solution of t2x00 C tx0 C t2x D 0 such that x.0/ D 2. In the preceding formula of the general solution of the Bessel equation of order
0, the function Y0.t/ ! 1 as t ! 0C. Then the condition x.0/ D 2 implies that c2 D 0. Moreover, since J0.0/ D 1, then c1 D 2. Thus x.t/ D 2J0.t/.

Y0(t) t

Fig. 10.2. Graph of Y0.t /

216 10 Solutions by infinite series and Bessel functions
10.5.2 The Bessel equation of order 1

When m D 1 we have the Bessel equation of order 1, namely

t 2x00 C tx0 C .t 2 1/x D 0:

(10.7)

As before, we first look for solutions of the form x.t/ D P aktk . Now the general

equality (10.5) becomes

X

X

X

X

k.k 1/ak t k C kak t k

akt k C akt kC2 D 0:

k2

k1

k0

k0

If in all the infinite sums we take k 2 we find

Xh

i

k.k 1/ak t k C kak t k akt k C ak 2t k C a1t a0 a1t D 0:

k2

Simplifying, we have X k2ak
k2

ak C ak 2 t k

a0 D 0:

Then a0 D 0 and ak satisfy the recurrence formula

k2ak

ak C ak 2 D 0 H) ak D

ak k2

2; 1

k

2:

Thus if k is even we find

a2 D

a0 D 0; 3

a4 D

a2 35

D 0;

:::

ak

D 0:

If k 3 is odd, the coefficients can be found in terms of a1. For what follows it is

convenient

to

set

a1

D

c 2

.

With

this

notation one

has

a3 D a5 D a7 D

a1 D 8

a1 23

D

c 2S 23 ;

a3 D 24 24

c 2S

23 D 2S

c 3S

25 ;

a5 D 48

c 48 2S 3S 25 D

c 3S 4S 27 ;

::: D :::

in general we find

a2kC1 D .

1/k

c

kS.k C 1/S

; 22kC1

k D 0; 1; 2; ::: :

In conclusion, Â
x.t/ D c t 2

t3

t5

2S 23 C 2S 3S 25

t7

Ã

3S 4S 27 C ::: ;

the series being uniformly convergent on all of R.

10.5 The Bessel equations 217

If we set

ÂÃ t

1

Â t

Ã3

1 Â t Ã5

J1.t/ D 2

C

C :::

2S 2

2S 3S 2

X D

. 1/k

Â t Ã2kC1

kS.k C 1/S 2

k0

we can say that x.t/ D cJ1.t/ solve (10.6). Notice that J1 is an odd function with J1.0/ D 0, J10 .0/ D 1. It has infinitely many zeros and decays to zero at infinity, like J0. It is named Bessel function of order 1, of the first kind. The graph of J1 is
reported in Figure 10.3.
An interesting fact is that between two consecutive zeros of J0 there is a zero of
J1, see Figure 10.4.

Fig. 10.3. Plot of J1
x

O

t

Fig. 10.4. J0 (red) vs. J1 (black)

218 10 Solutions by infinite series and Bessel functions
x

Y1 (t)

O

t

Fig. 10.5. Graph of Y1.t /

This property and the oscillatory character of J0; J1 hold in general for all Jm and will be discussed in the next section, see Theorems 10.5.3 and 10.5.4.
As before, a solution of the Bessel equation of order 1, linearly independent of J1, is given by
Y1.t/ D ln t J1.t/; t > 0;

which is called Bessel function of order 1, of the second kind, see Figure 10.5. As Y0, also Y1 has infinitely many zeros and possesses a singularity at t D 0. It follows that the general solution is

c1J1.t / C c2Y1.t /:
Example 10.5.2. Find a solution of t2x00 C tx0 C .t2 1/x D 0 such that x.0/ D 0, x0.0/ D 2. Since x.0/ D 0, then c2 D 0 because Y1.t/ ! 1 as t ! 0C. Thus x.t/ D c1J1.t/. From x0.0/ D c1J 0.0/, and J10 .0/ D 1, it follows that c1 D 2 and the solution of the initial value problem is x.t/ D 2J1.t/.

10.5.3 Bessel equations of order m

If m is an integer, the Bessel functions of order m, of first kind can be defined as

X . 1/k Â t Ã2kCm

Jm.t/ D kS.k C m/S 2

:

The functions Jm are solutions of the Bessel equation of order m. If m is an even

integer, then Jm.t/ is an even function, while if m is odd, then Jm.t/ is an odd func-

tion.

Although for negative m the Bessel equation remains unaffected, it is customary

to set

J m.t / D . 1/mJm.t /:

10.5 The Bessel equations 219
It would be possible to define Bessel functions for any real number m. The expression of Jm.t/ is formally equal to the preceding one, giving an appropriate definition of .m C k/S, which can be done by means of the Gamma function . But this is beyond the scope of this book.

10.5.4 Some properties of the Bessel functions

One can check that the following recurrence formula holds

JmC1.t /

D

2m t Jm.t/

Jm 1.t /:

For example,

J2.t /

D

2 t J1.t/

J0 .t /:

The function Jm.t/ is analytic and has infinitely many zeros. Furthermore, Jm.0/ D 0 for all m D6 0 and Jm0 .0/ D 0 for all m 6D 1.
Moreover, the following identity holds

d dt

.t mJm.t //

D

t mJm

1.t /:

(10.8)

As an exercise, let us prove (10.8) for m D 1. We know that

J1.t /

D

X

. kS.k

1/k C 1/S

Â t Ã2kC1 2

k0

so that

X . 1/k

Â t Ã2kC2

tJ1.t/ D

2 kS.k C 1/S 2

:

k0

Recall that the above series is uniformly convergent and hence the derivative of tJ1.t/

equals the series obtained by differentiating each term. Thus, taking the derivative one

finds

.tJ1.t //0

D

X . 1/k 2
kS.k C 1/S

d Â t Ã2kC2 dt 2

k0

X D

. 1/k

.2k C 2/ Â t Ã2kC1

kS.k C 1/S

2

k0

X . 1/k

Â t Ã2kC1

D

2.k C 1/

kS.k C 1/S

2

k0

D

X.

1/k 2

Â t Ã2kC1 :

kS kS 2

k0

220 10 Solutions by infinite series and Bessel functions
x
O

Fig. 10.6. Plots of J0 (black), J1 (blue), J2 (red) and J3 (green)

Since

tJ0 .t /

D

X

. 1/k .kS/2

2

Â t Ã2kC1 2

k0

the conclusion follows.

Another useful relationship is

Â

Ã

d dt

Jm.t / tm

D

JmC1.t tm

/

:

One can use (10.8) and (10.9) to prove

(10.9)

Theorem 10.5.3. Between two consecutive, positive (or negative), zeros of Jm.t/ there is one and only one zero of JmC1.t/. See Figure 10.6.

Proof. Let 1 < 2 be two consecutive, positive, zeros of Jm. Clearly, they are

also OE1;

consecutive zeros of 2 implies that there

Jm .t tm

/

.

The

Rolle

theorem

applied

to

Jm .t tm

exists  21; 2OE such that the function

/Jmtom.nt /tÁh0evianntiesrhveasl

at . By (10.9),  is a zero of JmC1.

Similarly, let 1 < 2 be two consecutive, positive, zeros of JmC1. Applying the Rolle theorem to tmC1JmC1.t/ on the interval OE1; 2, we find  2 .1; 2/ such that .t mC1JmC1.t//0 vanishes at . Using (10.8) we deduce that mC1Jm./ D 0,

namely that  is a zero of Jm.

10.5 The Bessel equations 221

Similar results can be given for the Bessel functions of second kind. For example, one has

2m YmC1.t / D t Ym.t / Ym 1.t /;

Y m.t / D . 1/mYm.t /;

d dt

.t mYm.t

//

D

t

mYm

1.t /;

Â

Ã

d dt

Ym.t / tm

D

YmC1.t tm

/

:

Each Ym.t/ is singular at t D 0 and has infinitely many zeros that alternate between each other. See Figure 10.7.
As a further application, let us look for > 0 such that the problem

s yR.s/ C y.s/ D 0; y.0/ D 0; yP.1/ D 0

(10.10)

has

a

nontrivial solution. Here

yP

D

d ds

and

yR

D

d2y ds2

.

p

First of all, let us show that the change of variable t D 2 s and y.s/ D tx.t/

transforms the equation into a Bessel equation of order 1. Actually, one has

r

yP D dy D d.tx.t// dt D x.t/ C tx0.t/

ds

dt ds

Â

s

Ã

D 2 x.t/ C tx0.t/ D 2 x.t/ C x0.t/

t

t

and

yR .s /

D

4

2

Â x00.t /

C

x0.t /

t

t

Ã x .t / t2 :

x

O

t

Fig. 10.7. Plots of Y0 (black), Y1 (blue), Y2 (red) and Y3 (green)

222 10 Solutions by infinite series and Bessel functions

Recalling that 4 s D t2, we find

t2 s yR.s/ D

4

2

Â x00.t /

C

x0.t /

4t

t

Ã x .t / t2 D

t

Â x00.t /

C

x0.t /

t

Ã x .t / t2 :

Thus syR.s/ C y.s/ D 0 becomes

t

Â x00.t / C

x0.t /

t

Ã

x .t / t2

C tx.t/ D 0:

Dividing by > 0 we get

tx00.t/ C x0.t/ x.t/ C tx.t/ D 0 t
or t 2x00.t/ C tx0.t/ C .t2 1/x.t/ D 0

which is the Bessel equation of order 1. A family of solutions is x.t/ D cJ1.t/, c a

constant, whence

p

p

y.s/ D 2c s J1.2 s/:

For s D 0 we have y.0/ D 0. Moreover

p

p

yP.s/ D c

p 2s

J1.2

s/ C

! p J10 .2 s/ :

Recall that by (10.8), one has J10 .t/ D J0.t/

1 t

J1.t

/

and

hence

for

t

D

p 2

s

p

p

p

p

p 2s

J1.2

s/ C J10 .2

s/ D J0.2

s/:

p

p

Then yP.s/ D c J0.2 s/ and the condition yP.1/ D 0 yields J0.2 / D 0.

In conclusion, if 0 < 1 < 2 < n < denote the zeros of J0, then for

eacph

nD

n
p2

2, the problem (10.10) has nontrivial solutions given by yn.s/

D

2c nsJ1.2 ns/.

We conclude this section by stating, without proof, the following result:

Theorem 10.5.4. Jm decays to zero at infinity, changing sign infinitely many times.

10.6 Exercises 223

10.6 Exercises

1. Find x.t/ D P ak tk such that tx00 D x.

2.

P Find x.t/ D k

0 akt k such that tx00 D x0.

3.

P Find x.t/ D k

0 aktk such that x00 D tx C 1 and x.0/ D 0; x0.0/ D 1.

4. Solve x00 C tx0 C x D 0, x.0/ D 1; x0.0/ D 0.

5. Using the Frobenius method, solve 4t2x00 C 4tx0 x D 0, t > 0.

6. Using the Frobenius method, solve t2x00 C 3tx0 D 0, t > 0.

7. Using the Frobenius method, solve t2x00 3tx0 C .4 t/x D 0.

8. Using the Frobenius method, solve t2x00 C tx0 C .t 1/x D 0.

9. Find the solution xa of the Bessel equation t2x00 C tx0 C t2x D 0 such that xa.0/ D a.
10. Find the solution xa of the Bessel equation t2x00 C tx0 C .t2 1/x D 0 such that xa0 .0/ D a.
11. Find the positive integers m such that t2x00Ctx0C.t2 m2/x D 0 has a nontrivial solution such that x.0/ D 0.

12. Prove that .t2J2.t//0 D t2J1.t/.

13. Show that J0.t/ has a maximum at t D 0.

14. Let  be a positive zero of J0.t/. Show that if J1./ > 0 then J00 ./ < 0.

15. Setting Z.t/ D J0.t/ tJ1.t/, show that if  is a zero of J0.t/ then Z0./ D J00 ./.

16.

Using the power expansions of J0; J1; J2, prove that J2.t/

D

2 t

J1

.t

/

J0 .t /.

17. Prove that Jm0 .t/ D Jm 1.t/

m t

Jm.t /,

m

an

integer.

18. Prove if 1 is the first positive zero of J0.t/, then J1.1/ > 0 and J2.1/ > 0.

19. Let 1 denote the first positive zero of J0. Show that the only solution of t2x00 C tx0 C .t2 1/x D 0 such that x.0/ D x.1/ D 0 is x.t/ Á 0.

20. Find > 0 such that the problem

d 2y s ds2 C y.s/ D 0; y.0/ D 0; y.1/ D 0;
p has a nontrivial solution. [Hint: use the change of variable t D 2 s to transform the equation into the Bessel equation of order 1.]

21. Find the positive integer such that t2x00 C tx0 C t2x D x has a nontrivial solution satisfying x.0/ D 0, x0.0/ D 1.

11 Laplace transform

In this chapter we study some basic properties of the Laplace Transform, (or L-Transform for short), which plays an important role not only in mathematics but also in the sciences and engineering. This is a deep subject and a rigorous and thorough treatment of it would be beyond the scope of this book. So we will not venture too far beyond some of its basic properties. In particular, we will discuss its application in solving initial value problems for linear differential equations with constant coefficients. This powerful method essentially consists of converting an initial value problem to an algebraic equation involving the Laplace Transform X of the solution x to the differential equation, and then recovering the solution x by taking the inverse of X.

11.1 Definition and preliminary examples

Given a real valued function f .t/ defined on OE0; C1/, the L-transform of f , denoted by L¹f .t/º.s/, or F .s/, is the function of s defined by

Z C1

L¹f .t/º.s/ D

e st f .t /dt;

0

provided the integral makes sense, that is

Zr

lim

e st f .t /dt

r !C1 0

exists and is finite. The set of s 2 R where this is true is called the region (or domain) of convergence of L¹f .t/º.s/. Often we will write L¹f .t/º or simply L¹f º instead of L¹f .t/º.s/.
We notice that one could define the L-transform of a complex valued function of the complex variable s D C i !. But for our purposes it is sufficient to limit our study to the real case.

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_11

226 11 Laplace transform

The L-transform is well defined for a broad class of functions. Recall that f has a jump discontinuity at t D a if both one-sided limits

lim f .t/;
t !aC

lim f .t/
t !a

exist but are not equal to each other. For example, the function

²

f .t/ D

0; if t < 0 t C 1; if t 0

has a jump discontinuity at t D 0 because limt!0 f .t/ D 0 while limt!0C f .t/ D

limt!0C.t C 1/ D 1. On the other hand, the function

²

g.t/ D

0; if t Ä 0

1 t

;

if t > 0

has a discontinuity at t D 0 which is not a jump discontinuity.

We say that f is piecewise continuous on its domain D if there exists a numerable

set S such that f is continuous on D n S and has a jump discontinuity at each point

of S. If S is empty, then f is just continuous. For example, the preceding function

f is piecewise continuous, while g is not.

A function f .t/ is said to be of exponential order if there exist constants M and 

such that

jf .t/j Ä Met :

(11.1)

For example, any bounded piecewise continuous function, any polynomial P .t/ D a0 C a1t C : : : C antn, in general any function such that f .t/ D O.tn/ as jtj ! C1 (i.e. for some number A, jf .t/j Ä Atn for t large enough), all satisfy (11.1) for s > 0 (hence L¹f º.s/ exists for s > 0). However, f .t/ D et2 does not satisfy (11.1): since et2e t Ä M , is obviously false.
Theorem 11.1.1. Suppose that f is piecewise continuous on RC and satisfies (11.1). Then L¹f º.s/ exists for s > .

Proof. One has

e st f .t / dt Ä e st M et D M e. s/t :

We

recall

from

Calculus

that

if

R1
0

jf

.t

/jd

t

exists,

then

R1
0

f

.t

/d

t

also

exists.

Therefore e st f .t/ is integrable on RC. Moreover

Z C1 e st f .t /dt
0

exists and is finite, provided s > , which means that L¹f º.s/ exists for all s > .

In the sequel, even if not explicitly stated, it will be assumed that the functions we treat satisfy (11.1).

11.1 Definition and preliminary examples 227

Next we consider some examples of L-transform.

Example 11.1.2. Consider f .t/ D et which obviously satisfies (11.1) . Moreover

one has

Z

r
e

Z st etdt D

r
e.

s/t dt D e.

s/r

0

0

s

1 :
s

For s >  one has that e. s/r ! 0 as r ! C1 and hence

Zr

L¹et º D lim

e. s/t dt D

1 ;

r !C1 0

s

s > :

(11.2)

In particular, if  D 0 then f .t/ D e0 D 1 and

L¹1º

D

1 ;

s

s > 0:

(11.3)

Example 11.1.3. Consider the Heaviside function (or step function)

²

H.t/ D

0; if t < 0 1; if t 0

and let, for a 0,

²

Ha.t/ WD H.t

a/ D

0; if t < a 1; if t a:

Notice that Ha is bounded and piecewise continuous, with S D ¹aº and hence The-

orem 11.1.1 applies with  D 0. Taking into account the definition of Ha, we get for

s>0

Zr

Zr

e st Ha.t /dt D e st dt D

0

a

e sr e as

C:

s

s

Thus

Z C1 e stdt D

lim

Â

e sr e as Ã e as

C

D:

a

r !C1

s

s

s

Hence

L¹Haº

D

e

as
s

;

s > 0:

(11.4)

Of course, if a D 0 then H.t/ D 1 for all t 0 and we find that L¹H º.s/ D L¹1º D 1=s, in agreement with (11.3).

Example 11.1.4. Consider the characteristic function

8 < 0; if t < a

OEa;b.t /

D

:

1; 0;

if a Ä t Ä b if t > b

228 11 Laplace transform

over OEa; b, 0 Ä a < b. We note that OEa;b is bounded and piecewise continuous, with S D ¹a; bº and hence it possesses the L-transform defined for all s > 0. Performing
calculations as in the previous example, we find that, for r > b,

Zr

Zb

e st OEa;b.t /dt D e st dt D

0

a

e bs C e as

s

s

and hence

L¹

OEa;bº D e

as e s

bs
;

In particular, if a D 0 we find

s > 0:

(11.5)

1 e bs

L¹ OE0;bº D

; s

s > 0:

It is worth pointing out that from the definition it immediately follows that if f; g are piecewise continuous, satisfy (11.1) and differ on a numerable set, then

L¹f º.s/ D L¹gº.s/

(11.6)

for all s on their common region of convergence.

11.2 Properties of the Laplace transform

The following Proposition shows that the Laplace transform is a linear operator. Proposition 11.2.1. L is linear, that is
L¹af .t/ C bg.t/º.s/ D aL¹f º.s/ C bL¹gº.s/;

for each s such that the right-hand side makes sense.

Proof. It follows immediately from the linearity of the integrals that:

Z C1

L¹af .t/ C bg.t/º D

e st OEaf .t/ C bg.t/dt

0Z C1

Z C1

Da

e st f .t /dt C b

e st g.t /dt

0

0

D aL¹f º C bL¹gº:

For example,

L¹kº D L¹k

1º D kL¹1º D k

1

D

k ;

ss

s > 0:

11.2 Properties of the Laplace transform 229 As another example, let us note that OEa:b.t/ D Ha.t/ Hb.t/. Thus, using (11.4),

L¹ OEa:bº D L¹Haº

L¹Hb º

D

e

as
s

e bs D e as e bs

s

s

according to (11.5).

The L-transform has a smoothing effect.

Theorem 11.2.2. Suppose that f satisfies (11.1). In its region of convergence, F .s/ D L¹f º is differentiable infinitely many times at each point. Precisely, one has
F .n/.s/ D . 1/nL¹t nf .t /º.s/

for any n D 1; 2; : : : .

The following result is important for applications in differential equations.

Theorem 11.2.3. Suppose that f is differentiable for t 0 and satisfies (11.1). If L¹f 0º exists then
L¹f 0º.s/ D sL¹f º.s/ f .0/:

Proof. By definition

Z C1

L¹f 0º D

e st f 0.t /dt:

0

Integrating by parts we find
Zr e st f 0.t /dt D e sr f .r /
0

Zr f .0/ C s e st f .t/dt:
0

If we pass to the limit as r ! C1, (11.1) implies that e sr f .r / ! 0. Then it follows that L¹f 0º is equal to sL¹f º f .0/.

Now, it follows that
L¹f 00º D sL¹f 0º f 0.0/ D sOEsL¹f º f .0/ f 0.0/ D s2L¹f º sf .0/ f 0.0/;
provided L¹f 0º and L¹f 00º exist. By using Mathematical Induction one can find the L-transform of f .n/, see (P4)
below.

230 11 Laplace transform

Below we collect some properties of the L-transform. The domains of convergence can be determined in each case:

.P 1/ .P 2/
.P 3/ .P 4/ .P 5/

L¹et f .t/º D L¹f º.s /I

L¹e t e t º D

 I

.s C /.s C /

²Z t L f.

/d

³ D L¹f º I

0

s

L¹f .n/º D snL¹f º sn 1f .0/ sn 2f 0.0/ : : : f .n 1/.0/I

L¹tnf .t/º D .

1/n

dn dsn

L¹f

º

(see Theorem 11.2.2):

Properties .P1 P 5/ can be used to find other L-transforms. For example if

f .t/ D 1, .P 5/ yields

L¹tnº D .

1/n

dn dsn

L¹1º

D

.

1/n

dn dsn

ÂÃ 1 s

D

nS snC1 :

(11.7)

Let us use .P 4/ to find F .s/ D L¹sin !tº. Recall that since f .t/ WD sin !t is
smooth and bounded, then F .s/ exists for all s > 0. One has that f 0.t/ D ! cos !t and f 00.t/ D !2 sin !t, that is f 00 D !2f . Moreover, f .0/ D sin 0 D 0 and f 0.0/ D ! cos 0 D !. Now we take the L-transform yielding

L¹f 00.t/º D !2L¹f º D !2F .s/:

Property .P 4/ implies L¹f 00.t/º D s2F .s/ sf .0/ f 0.0/ D s2F .s/ !:

Then it follows that

s2F .s/ ! D !2F .s/ H) .s2 C !2/F .s/ D !:

Hence, F .s/ D !=.s2 C !2/, that is

L¹sin !tº

D

s2

! C

!2

:

(11.8)

For the reader's convenience, let us find the L-transform of sin !t directly, using

the definition. First, integrating by parts, we evaluate

Zr e st sin !t dt D

cos !r e

sr C

1

0

!

!

s

Z

r
e

st cos !t dt:

!0

Another integration by parts yields

Z

r
e

st cos !t dt D sin !r e

sr C

s

Z

r
e

st sin !t dt:

0

!

!0

11.2 Properties of the Laplace transform 231

Passing to the limit as r ! C1 in the previous two equations we find

Z

C1
e

st sin !t dt D

1

0

!

s

Z

C1
e

st cos !t dt

!0

(11.9)

and

Z

C1
e

st cos !t dt D

s

Z

C1
e

st sin !t dt:

0

!0

Substituting the latter integral in (11.9) we get

Z

C1
e

st sin !t dt D

1

0

!

s2 Z C1 !2 0 e

st sin !t dt:

Thus

Â 1

C

s2 !2

Ã

Z C1
0

e

st sin !t dt D 1 !

that is

!2 C s2 Z C1

!2

e
0

st sin !t dt D 1 !

and finally

Z L¹sin !tº D

C1
e

st sin !t dt D

1

0

!

!2

!

!2 C s2 D !2 C s2

according to (11.8).

Similarly, with minor changes one finds

L¹cos !tº

D

!2

s C

s2 :

(11.10)

As a further application, let us consider the Bessel function of order 0, J0.t/, which satisfies

tJ000.t / C J00 .t / C tJ0.t / D 0; J0.0/ D 1; J 0.0/ D 0:

(11.11)

For the properties of J0.t/ we refer to Section 10.5.1 of the previous chapter. In particular, J0.t/ is smooth and bounded and hence its L-transform X.s/ WD L¹J0.t/º.s/ exists for all s > 0. Moreover, since J0.t/ is integrable on OE0; C1/ and
Z C1 J0.t/dt D J0.0/ D 1;
0

then

Z C1

X.s/ D

e st J0.t /dt;

0

232 11 Laplace transform

which is a priori defined for s > 0, can be extended to s D 0 and one has

Z C1

X.0/ D

J0.t/dt D 1:

0

We want to show that

L¹J0 .t /º

D

p1 : 1 C s2

We start taking the L-transform of (11.11):

L¹tJ000.t / C J00 .t / C tJ0.t /º D 0:

Using the linearity of L we infer

L¹tJ000.t /º C L¹J00 .t /º C L¹tJ0º D 0:

Then .P 4/ .P 5/ yield

L¹tJ000.t /º D .s2X.s/ J0.0/s J00 .0//0 D .s2X.s/ s/0 D 2sX.s/ s2X0.s/ C 1;
L¹J00 .t/º D sX.s/ J0.0/ D sX.s/ 1; L¹tJ0º D X0.s/:

(11.12) (11.13)

Substituting into (11.13) we find 2sX.s/ s2X0.s/ C 1 C sX.s/ 1 X0.s/ D 0;

or .1 C s2/X0.s/ C sX.s/ D 0:

This is a separable equation. One finds X 0 .s / D X.s/

s 1 C s2 :

Integrating we have

ln

jX.s/j jX.0/j

D

1 ln.1 C s2/: 2

Taking into account that X.0/ D 1 we get

ln jX.s/j D ln.1 C s2/

1 2

whence

X.s/ D .1 C s2/

1 2

D

p

1

1 C s2

proving (11.12). Notice that in this case it would be more complicated to evaluate L¹J0º directly.

11.3 Inverse Laplace transform 233

Table 11.1. L-transforms

f .t / F .s/ D L¹f º

f .t /

F .s/ D L¹f º

1 tn sin !t sinh !t e at sin !t

1 s
nS snC1
! s2 C!2
! s2 !2
! .sCa/2 C!2

Ha.t /
Zt f . /d
0

e as s
F .s/ s

t eat cos !t cosh !t e at cos !t

1 s2
1 sa
s s2 C!2
s s2 !2
sCa .sCa /2 C! 2

OEa;b.t / J0.t /

e as e bs s
p1 1 C s2

Table 11.1 summarizes the L-transforms for some of the functions that we have discussed. The domain of convergence can be determined in each case.

11.3 Inverse Laplace transform

We start with an example dealing with the RC circuits discussed in Section 1.3.2.

Example 11.3.1. We have seen that an RC electric circuit gives rise to a first order differential equation as RCx0 C x D 0, x.0/ D x0. We will use this example to

motivate the introduction of the inverse L-transform.

To keep the notation consistent with that used in this chapter, here we write the

ivp as

x0.t/ C x.t/ D 0; x.0/ D x0;

where we take RC D 1 in order to simplify notation. Let us assume for the moment that x.t/ satisfies (11.1). We will see later that this is indeed the case. Taking the Ltransform of both sides, and recalling the linearity of L, we find

L¹x0 C xº D L¹x0º C L¹xº D 0:

Using property .P 5/, and recalling that x.0/ D x0, we infer sX.s/ x0 C X.s/ D 0; X.s/ WD L¹xº:

234 11 Laplace transform

Then

X.s/

D

x0 1C

s

and x.t/ is the function such that its L-transform is X.s/. We will say that x.t/ is the

inverse L-transform of X.s/. In this specific case, it is easy to find x.t/. Actually, in Example 11.1.2 we have shown that L¹et º D 1=.s /. If we take  D 1 we find

L¹x0e

t º D x0L¹e

tº

D

s

x0 C1

and hence x.t/ D x0e t , in accordance with what we have found in Section 1.3.2.

In the rest of this section we will discuss the inverse L-transform. Let us begin by stating a preliminary result on the injectivity of the L-transform, which is nothing but the converse of (11.6).

Proposition 11.3.2. Let f; g be piecewise continuous on OE0; C1/ and satisfy (11.1). If L¹f º D L¹gº on their common region of convergence, then f .t/ D g.t/, for all t 0, up to a numerable set of points. If f; g are continuous, then f .t/ D g.t/ for all t 0.

Definition 11.3.3. Let F .s/ be given. If there exists a function f .t/ such that L¹f º.s/
exists and L¹f º.s/ D F .s/, we say that F has an inverse L-transform given by f .t/. In this case we write f .t/ D L 1¹F .s/º.t/.

In other words, the idea of the inverse of L-transform is nothing new:

L¹f .t/º.s/ D F .s/ if and only if f .t/ D L 1¹F º.s/ (assuming that the in-

verse exists). For example, for f .t/

D

t, L¹tº

D

1 s2

implies the equivalent rela-

tion t

D

L

1

¹

1 s2

º.

Often

we

will

write

L

1¹F .s/º

or simply L

1¹F º instead of

L 1¹F .s/º.t/:

Proposition 11.3.2 shows that if f .t/ is piecewise continuous on t 0 and sat-

isfies (11.1), then it is uniquely determined by F .s/, up to the numerable set S, and

hence the preceding definition makes sense.

For example, (11.4) yields L¹Haº D e as=s and hence

L

1

²

e

as
s

³

D

Ha .t /:

(11.14)

The following proposition says that L 1 is linear like L.

Proposition 11.3.4. Suppose that F .s/; G.s/ have inverse L-transforms. Then for all a; b 2 R, aF .s/ C bG.s/ has inverse L-transform and
L 1¹aF .s/ C bG.s/º D aL 1¹F .s/º C bL 1¹G.s/º:
Proof. Let f .t/ D L 1¹F .s/º and g.t/ D L 1¹G.s/º. Then F .s/ D L¹f .t/º and G.s/ D L¹g.t/º. Moreover, using the linearity of L, it follows that

L¹af .t/ C bg.t/º D aL¹f .t/º C bL¹g.t/º D aF .s/ C bG.s/:

11.3 Inverse Laplace transform 235 Taking the inverse L-transform of both sides we infer that
L 1¹aF .s/ C bG.s/º D af .t/ C bg.t/ D aL 1¹F .s/º C bL 1¹G.s/º; as required.

Example 11.3.5. Using the linearity property and our familiarity with the Laplace

transforms of sin t and cos t, we have

²

³

´



L1

2s 7 s2 C 3

D 2L 1

s

s2

C

p2 . 3/

´p 

7 p

L

1

3

3

s2

C

p2 . 3/

p D 2 cos 3 t

p7

p sin 3 t:

3

Example 11.3.6. Using partial fractions, we see that

²

³

²

L1

1 .s C 1/.2s C 3/

DL 1

1 sC1

²³

²

³

L1

1 sC1

L1

1 s C 3=2

De t

³ 2 2s C 3 D e. 3=2/ t :

In general, if

X m R.s/ D

ki

s
1

i

then X m
L 1 ¹R.s/º D ki e i t :
1

For example, if

R.s/ D

1

.s /.s

Ä

D1

1

/   s 

1 s

we

have

k1

D

1 

,

k2

D

²

L1

1

.s /.s



1 

,

1 D  and

2 D . Thus we find

³

et

D

et

et et

D

:

/      

Similarly, if

R.s/ D

s

.s /.s

Ä

D1



/   s 

 s

we

have

k1

D

 

,

k2

D



 

,

1 D  and

2 D  and we find

² L1

s

³ D  et

 et D et

et :

.s /.s /  





(11.15) (11.16) (11.17)

236 11 Laplace transform

Now, let us state without proof a result on the inverse L-transform of rational functions.

Theorem 11.3.7. Let P .s/; Q.s/ be two polynomials with degree n < m, respec-

tively. If Q has m simple roots 1; : : : ; m, then

L

1

²³ P .s/ Q.s/

D

X m
1

P. Q0.

i/ e i/

it:

(11.18)

As a simple exercise, the student can establish (11.16) and (11.17) using the preceding theorem.

The counterpart of properties .P1/ and .P 3/ can be found immediately. Below we set F .s/ D L¹f º.
From .P1/ and .P 3/ it follows that

.P10/ L 1¹F .s /º D et f .t/;

.P 30/

L

² ³Z 1 F .s/ D

t
f.

/d

:

s

0

One can also show that

s > I

.P100/ L 1¹e sF .s/º D H.t /f .t /:

The following list of inverse L-transforms can be deduced from the table of Ltransforms. See Table 11.2.

F .s/

Table 11.2. inverse L-transforms

L 1¹F º

F .s/

L 1¹F º

1 s
nS snC1
! s2 C! 2
! s2 !2
! .sCa/2 C!2
e as s
F .s/ s

1 tn sin !t sinh !t e at sin !t

Ha.t /

Rt
0

f

.

/d

1 s2
1 sa
s s2 C! 2
s s2 !2
sCa .sCa/2 C!2
e as e bs s
p1 1Cs2

t eat cos !t cosh !t e at cos !t OEa;b.t / J0.t /

11.3.1 Convolution

11.3 Inverse Laplace transform 237

Let f .t/; g.t/ be two piecewise continuous functions on t 0.

Definition 11.3.8. The convolution of f .t/ and g.t/, denoted by f

defined by setting

Zt

.f g/.t/ D f .t Â/g.Â/dÂ:

0

g, is the function

The reader general, 1

should g D6 g.

exercise caution when This is the case for g.t

/dDealsiningtw, bitehcacuosnev1olustiinont.DFoRr0texsianmÂpdleÂ,

in D

1 cos t.

The following proposition is important in the sequel because it allows us to eval-

uate the inverse L-transform of a product.

Proposition 11.3.9. Let f; g be piecewise continuous of exponential order, which means that they satisfy (11.1). Setting F .s/ D L¹f º and G.s/ D L¹gº, one has

L¹f gº D F .s/ G.s/

(11.19)

and hence

L 1¹F .s/G.s/º D .f g/.t/:

(11.20)

As an application let us evaluate the inverse L-transform of

e as e bs

.s/ D

:

s.s C 1/

Using (11.20) with F .s/ D 1=.s C 1/ and G.s/ D .e as e bs/=s, one finds

L 1¹ .s/º D .f g/.t/

where (see (11.2))

²³

f .t/ D L 1

1 sC1

De t

and (see (11.5))

´



g.t/ D L 1

e as e bs s

D OEa;b.t /

and hence

´



L1

e as e bs s.s C 1/

De t

OEa;b.t /:

(11.21)

Proposition 11.3.9 can also be used to solve integral equations as
Zt x.t/ D k.t/ C f .t Â/x.Â/dÂ D k.t/ C .f x/.t/:
0

(11.22)

238 11 Laplace transform
It suffices to take the L-transform yielding (with obvious meaning of notation) X.s/ D L¹kº.s/ C L¹f xº.s/ D K.s/ C F .s/ X.s/. If we know K and F , solving with respect to X we find x.t/ D L 1¹Xº.

Example 11.3.10. Solve
Zt x.t / D et C et Â x.Â /dÂ D et C et
0

x .t /:

One

has

X

D

1 s1

C

1 s1

X and hence .1

xDL

1¹

s

1 2

º

D

e2t

.

s

1 1

/X

D

s

1 1

,

namely

X

D

s

1 2

.

Then

11.4 Laplace transform and differential equations

The Laplace transform is useful in solving linear differential equations. Let us start with a general linear second order equation with constant coefficients

x00.t/ C ax0.t/ C bx.t/ D g.t/; x.0/ D x0; x0.0/ D x1:

Let us assume that the L-transform of G.s/ D L¹g.t/º.s/ exists for s > 0. If we take the L-transform of both sides and use .P 4/ we find

s2X.s/ sx0 x1 C a.sX.s/ x0/ C bX.s/ D G.s/

where X.s/ D L¹x.t/º.s/. As for X.s/, we proceed formally, assuming that it makes sense for s > 0. At the end we shall verify that this is indeed the case.
Solving for X.s/, we get

X.s/

D

sx0

C x1 C ax0 C s2 C as C b

G.s/ :

Notice that x.t/ D L 1¹Xº. Thus, taking the inverse L-transform, we find

²

³

x.t/ D L 1

sx0 C x1 C ax0 C G.s/ s2 C as C b

which can be found explicitly using the properties of the inverse L-transform. Let us illustrate the procedure with an example.

Example 11.4.1. Consider the problem x00.t/ C x.t/ D g.t/;

x.0/ D 0; x0.0/ D k

and assume that the inverse L-transform G.s/ of g.t/ exists for s > 0. Then k C G.s/
X.s/ D s2 C 1

11.4 Laplace transform and differential equations 239

so that X.s/ has an inverse L-transform and

²

³

²

³

x.t/ D L 1

k s2 C 1

CL 1

G.s/ s2 C 1

:

Using (11.8)

²

³

x.t/ D k sin t C L 1

G.s/ s2 C 1

:

From (11.20), with F .s/ D 1=.s2 C 1/, we deduce

x.t/ D k sin t C sin t

Zt g.t/ D k sin t C sin.t
0

Â /g.Â /d Â ;

which is the solution of our ivp for any L-transformable g.t/.

The preceding discussion highlights the procedure one follows in the general case
of x.n/ C a1x.n 1/ C : : : C an 1x0 C anx D g.t /

together with initial conditions x.0/ D x0; x0.0/ D x1; : : : ; x.n 1/.0/ D xn 1:
One takes the L-transform of the equation and uses .P 4/ yielding snX.s/ sn 1x0 sn 2x1 : : : xn 1 C : : : C anX.s/ D G.s/:

This allows us to find

P .s/X.s/ Q.s/ D G.s/

where

P .s/ D sn C a1sn 1 C : : : C an 2s2 C an 1s C an

and Q.s/ D sn 1x0 C sn 2x1 C : : : C an 2.sx0 C x1/ C an 1x0:
Then X.s/ D .G.s/ C Q.s//=P .s/ has an inverse L-transform x.t/ which solves the ivp.

Other equations that can be solved by means of the L-transform are linear equations with coefficients depending on time. Once again, we discuss some specific examples.
Consider the ivp
x00 C tx D 0; x.0/ D 0; x0.0/ D b:
Taking the L-transform and using .P 4/ we get
s2X.s/ b C L¹tx.t/º D 0:

240 11 Laplace transform
From .P 5/ we infer that L¹tx.t/º D X0.s/ and hence we deduce s2X.s/ b X0.s/ D 0 that is
X0.s/ s2X.s/ D b:

This is a linear first order equation that can be solved by the integrating factor method. Once X.s/ is found, the solution we are looking for is given by x.t/ D L 1¹X.s/º.
As a further example let us consider the system
² x0 D x C y y0 D x y

with the initial conditions x.0/ D 1 and y.0/ D 0. Taking the L-transform and

setting X.s/ D L¹xº; Y .s/ D L¹yº we deduce

² L¹x0º D sX.s/ 1 D X.s/ C Y .s/

L¹y0º D sY .s/

D X.s/ Y .s/

whence

² .s 1/X.s/ Y .s/ D 1 X.s/ C .s C 1/Y .s/ D 0:

Finding X.s/ D .s C 1/Y .s/ from the second equation and substituting into the first one we find
.s 1/.s C 1/Y .s/ Y .s/ D 1

and hence

Y .s/ D

1 s2

: 2

Taking the inverse L-transform, see Table 11.2, we find

y.t/ D L

² 11
s2

³ D
2

p1

p sinh 2 t :

2

Moreover,

X.s/

D

.s

C 1/Y .s/

D

sC1 s2 2

D

s s2

2 C s2 1

2

and thus we get

x .t /

D

cosh

p 2

t

C

p1

p sinh 2 t :

2

11.5 Generalized solutions

The L-transform allows us to handle linear differential equations with a forcing term which may be discontinuous.
As an example, let us consider the first order equation

x0.t/ C x.t/ D OE0;b.t/; x.0/ D 0; .b > 0/;

(11.23)

11.5 Generalized solutions 241

where OE0;b is the step function introduced in Example 11.1.4. This problem models the voltage of an RC circuit when an initial step impulse is given at the capacitor.
Taking the L-transform of both sides, we find

L¹x0º C L¹xº D L¹ OE0;bº D 1

e bs :
s

Using property .P 4/ with n D 1 and setting X.s/ D L¹xº we infer

Solving for X.s/, we get

1 e bs

sX.s/ C X.s/ D

:

s

1 e bs

X.s/ D

:

s.s C 1/

Let us evaluate the inverse L-transform on the right-hand side. We use (11.21)

with a D 0, obtaining

´



L1

1 e bs s.s C 1/

De t

Zt OE0;b.t / D e tCÂ OE0;b.Â /dÂ:
0

To evaluate the integral, we distinguish between 0 Ä t Ä b and t > b. In the former

case, 0 Ä Â Ä t Ä b and we find

Zt

Zt

e tCÂ OE0;b.Â /dÂ D e tCÂ dÂ D 1 e t .0 Ä t Ä b/:

0

0

For t > b we have

Zt

Zb

Zt

e tCÂ OE0;b.Â /dÂ D

e tCÂ OE0;b.Â /dÂ C e tCÂ OE0;b.Â /dÂ

0

Z0b

b

D

e tCÂ dÂ D e tCb e t :

0

We have shown that

L

´

´

1

1 e bs s.s C 1/

D

1 e

e t; tCb e

t;

if 0 Ä t < b if t b:

Therefore, x.t/ D L 1¹X.s/º exists and is given by

´ 1

e t;

if 0 Ä t Ä b

x.t/ D

e tCb e t ; if t b:

Let us check this result working directly on the equation. For 0 Ä t Ä b one has OE0;b.t/ D 1 and the ivp becomes x0 C x D 1; x.0/ D 0. Solving this, we find

242 11 Laplace transform

x.t/ D 1 e t , 0 Ä t Ä b and x.b/ D 1 e b. For t b one has OE0;b.t/ D 0 and hence we are lead to solve the ivp

x0 C x D 0; x.b/ D 1 e b; .t b/

which can be solved easily: the general solution of x0 C x D 0 is x.t/ D ce t . To

find c we impose the initial condition x.b/ D 1 e b yielding ce b D 1 e b and

thus c D .1 e b/=e b D eb 1. In conclusion,

´ 1

e t;

if 0 Ä t < b

x.t/ D

e t .eb 1/; if t b

as before. The solution is increasing for 0 < t Ä b and then decays to 0 for t > b. See
Figure 11.1. It is worth pointing out that x.t/ here is continuous (it suffices to check this at t D b) but is not differentiable at t D b because the left derivative at t D b is e b while the right derivative at the same point is e b 1. In this case x.t/ is a "generalized" solution of our equation, in the sense that it solves the differential equation for all t 0, except at t D b. This could have been expected because the right-hand side of the equation has a discontinuity at t D b.
More generally, consider the differential equation
x.n/ C a1x.n 1/ C : : : C an 1x0 C anx D g.t /

where g is continuous with possibly the exception of a finite number of points S D ¹a1; : : : ; anº. We say that a continuous x.t/ is a generalized solution of the equation if it is continuously differentiable on R nS and satisfies the equation for all t 2 R nS. We could consider more general classes of generalized solutions, but this is out of
the scope of this book.

x

O

b

t

Fig. 11.1. Graph of x.t / D e t OE0;b.t /

11.6 Appendix: The Dirac delta

11.6 Appendix: The Dirac delta 243

A rigorous treatment of the Dirac1 delta would require more advanced topics such as

the Theory of Distribution and cannot be carried out here. However, its importance

in applications makes it worthwhile to give at least a heuristic sketch of this topic.

The reader should be aware that the exposition below is only an outline, not a very

rigorous and complete, treatment of the Dirac delta.

Let us define a sequence of functions fn W R 7! R by setting

8 < n;

if

jt j

Ä

1 2n

fn.t/ D : 0;

if

jt j

>

1 2n

:

For every fixed t D6 0 we have that fn.t/ ! 0 as n ! C1. Of course, this is not true for t D 0. Indeed, since fn.0/ D n we have that fn.0/ ! C1 as n ! C1. So, if we denote by i.t/ the pointwise limit of fn.t/, this i.t/, called the Dirac delta or i-function, is not a function as we are used to dealing with, but rather a "generalized"

function or distribution.

Notice that

Z C1

Z1 2n

fn.t/dt D

ndt D 1;

1

1 2n

8n 2 N:

If we "pass to the limit" under the integral, in an appropriate "generalized" sense, we

find

Z C1

i.t/dt D 1:

(11.24)

1

Another important characteristic property of i is that
Z C1 i.t/ .t/dt D .0/
1

(11.25)

for any smooth function W R ! 7 R. In order to show that i has the L-transform and to find it, we evaluate
Z C1 e st i.t /dt:
0

Since i.t/ D 0 for all t < 0, and using (11.25) with .t/ D e st , we infer

Z C1

Z C1

e st i.t /dt D

i.t /e st dt D e0 D 1:

0

1

Hence we can say that i has an L-transform given by

1 Paul Dirac (1902­1984).

L¹i.t/º D 1:

(11.26)

244 11 Laplace transform

More generally, we can consider a shifted delta function by considering i.t a/ which has the following properties

i.t a/ D 0 8 t 6D a
Z C1 i.t a/dt D 1
1
Z C1 i.t a/ .t/dt D .a/
1

(11.27) (11.28) (11.29)

for all smooth functions . It is interesting to evaluate the convolution of i.t a/ with a piecewise continuous
function g.t/. One has
Zt i.t a/ g.t/ D i.Â a/g.t Â/dÂ:
0

Let a

0. Since i.Â

a/ D 0 for Â Ä t < a, we get
Zt i.Â a/g.t Â/dÂ D 0:
0

On the other hand, for t a we can use (11.29) to infer

Zt

Z C1

i.Â a/g.t Â/dÂ D

i.Â a/g.t Â/dÂ D g.t a/:

0

1

In conclusion, we can say that
Zt i.Â a/g.t
0

²

Â/dÂ D

0 g.t

if 0 Ä t < a a/ if t a

that is

i.t a/ g.t/ D Ha.t/g.t a/:

(11.30)

Next let us find the L-transform of i.t a/, a

(11.29) to yield

Z C1 e st i.t
0

Z C1

a/dt D

i.t

1

0. We argue as before and use a/e st dt D e as

hence we can say that

L¹i.t a/º D e as:

(11.31)

We now want to show that the shifted Heaviside function Ha.t/ has the "derivative

in a generalized sense" given by i.t a/. To have a heuristic idea of this fact, one

first observes that

Zt

i.t a/dt D 0; 8 t < a;

0

11.6 Appendix: The Dirac delta 245

while for t

a, (11.28) yields

Zt
i.t
0

Z C1

a/dt D

i.t

1

a/dt D 1;

8 t a:

In other words,

Zt
i.t
0

²

a/dt D

0 1

if t < a if t a

D Ha.t/:

So Ha.t/ is a kind of antiderivative of i.t a/ and this gives rise, in a "generalized" sense, to Ha0 .t/ D i.t a/.
It is worth pointing out that this agrees with the result we find by taking the L-
transform. Actually, we know that

L¹Ha.t /º

D

e

as
: s

Then

L¹Ha0 .t /º D sL¹Ha.t /º D e as

which is exactly the L-transform of i.t a/. As for the inverse L-transforms, (11.31) implies

L 1¹e asº D i.t a/:

In Physics, ki.t a/ corresponds to a sudden force impulse of intensity k acting at the unique instant t D a. To illustrate its applications to differential equations, we will solve a couple of problems.

Example 11.6.1. For a 0 solve the problem (arising in an RC circuit) x0 C x D ki.t a/; x.0/ D 0; t 0:

Taking the L-transform we find sX.s/ C X.s/ D ke as:

Hence

X.s/

D

ke as :
sC1

Then, using the convolution property (11.20) of the inverse L-transform, we infer ²³
x.t/ D L 1¹X.s/º D kL 1¹e sº L 1 1 D ki.t a/ e t : s C1

Then, by (11.30),

8

<0

if 0 Ä t < a

x.t / D kHa.t /e .t a/ D : ke .t a/ if t a.

246 11 Laplace transform
This function solves our problem in a "generalized" sense (slightly different from the one introduced before). It has a jump discontinuity at t D a. Moreover, for 0 Ä t < a, x.t/ Á 0 and hence it solves x0 C x D 0, x.0/ D 0, while for t a, x.t/ solves x0 C x D 0 with initial condition x.a/ D k, see Figure 11.2a. If a D 0 we find x.t/ D ke t which solves x0 C x D 0 with initial condition x.0/ D k, see Figure 11.2b.
In applications to an RC circuit, there is no circulating current in the circuit for t Ä a because the capacitor is discharged, corresponding to the initial condition x.0/ D 0. For t > a, the sudden instantaneous impulse of intensity k generates a current as if the initial capacitor voltage is k. For t > a the RC circuit works as usual and the voltage decays exponentially to zero as t ! C1.
x

(a,k)

a

t

(a)
k

O

t

Fig. 11.2. (a) Solution of x0 C x D ki.t x D ki.t /, x.0/ D 0, k > 0

(b) a/, x.0/ D 0, k > 0, a > 0; (b) Solution of x0 C

11.6 Appendix: The Dirac delta 247
x

O

a

t

Fig. 11.3. Graph of x.t / D kHa.t / sin.t a/ with a > 0

Example 11.6.2. For a 0 let us consider the problem x00.t/ C x.t/ D ki.t a/; x.0/ D 0; x0.0/ D 0; t 0

which models a harmonic oscillator with the forcing term ki.t a/. As before, we take the L-transform and find
s2X.s/ C X.s/ D ke as:

Then

X.s/

D

ke as s2 C 1

and hence (11.20) yields

²

³

x

D L 1¹Xº D kL 1¹e sº ²

L1

1 s2 C 1

D ki.t

a/ sin t

D kHa.t/ sin.t

a/ D

0 k sin.t

if 0 Ä t < a a/ if t a.

In other words, if a > 0 the solution is 0 until t D a. After this time the impulse ki.t a/ yields the (nontrivial) solution of the equation x00 C x D 0 satisfying the initial conditions x.a/ D 0; x0.a/ D k. See Figure 11.3. Moreover, notice that
x.t/ D kHa.t/ sin.t a/ is not differentiable at t D a and hence the name "solution"
has once again to be understood in a "generalized" sense. If a D 0 we find merely x.t/ D k sin t, t 0, which solves x00 C x D 0 with the new initial conditions x.0/ D 0; x0.0/ D k.

248 11 Laplace transform

11.7 Exercises

1.

Find the L-transform of sinh !t

D

1 2

.e

!t

e

!t / and cosh !t

D

1 2

.e

!

t

C

e

!t /.

2. Find the L-transform of t sin !t and t cos !t.

3. Find the L-transform of t sinh !t and t cosh !t.

4. Find the L-transform of et sin !t and et cos !t.

5. Find L¹f º where f .t/ D 1, if 0 Ä t Ä 1, f .t/ D 2, if 3 Ä t Ä 4 and f .t/ D 0 otherwise.

6. Find the L-transform of t et .

7. Find the L-transform of t2 eat .

8. Let f be a piecewise continuous T -periodic function. Show that L¹f º exists

and

F .s/ D L¹f º D 1

1 e sT

ZT e st f .t /dt:
0

9. Find the L-transform of the 2-periodic square wave function f .t/ D 1; if 0 Ä t < 1; f .t/ D 0; if 1 Ä t < 2;
and f .t C 2/ D f .t/ for all t 2.

10. Find the L-transform of the saw-tooth T-periodic function f .t/ D t; if 0 Ä t < T ; f .t C T / D f .t/; 8 t T:

11. Let F .s/ D L¹f º.s/ be defined for s > 0. Suppose that jf .t/j Ä C for all t 0. Show that lims!C1 F .s/ D 0.

12. Let F .s/ D L¹f º.s/ be defined for s > 0. Suppose that f .t/ t 0. Show that lims!0C F .s/ D C1.

13.

Find the inverse L-transform of

2 s2 4

and

s s2

4.

14.

Find the inverse L-transform of s2

1 2sC2

and

s2

s

1 2sC2

.

°

±

15. Find L 1

1 s2 3sC2

.

°±

16. Find L 1

s2 s3 s

.

°±

17. Find L 1

1 s4 1

.

°

±

18. Find L 1

s2 C3sC1 s2 Cs

.

C > 0 for all

19. Let F .s/ D L¹f º. Show that if f .t/ > 0 then F is decreasing and concave upward.

11.7 Exercises 249

20.

Prove property .P 3/ of the L-transform: if g.t/

D

Rt
0

f

.

/d

then L¹gº.s/ D

L¹f s

º.t

/

.

21. Use .P 3/ to show that L¹tº D s 2.

22. Use .P 4/ to find the L-transform of et .

23. Let J0.t/ be the Bessel function of order 0 satisfying tx00 C x0 C tx D 0, such that J0.0/ D 1. Find X.s/ D L¹J0º such that X.0/ D 1.

24. Solve x0 C x D et ; x.0/ D 0 using the L-transform.

25. Solve x0 C x D t; x.0/ D 1 using the L-transform.

26. Solve x00 2x0 C x D 0; x.0/ D x0.0/ D 1 using the L-transform.

27. Solve x00 4x0 C 3x D 1; x.0/ D x0.0/ D 0 using the L-transform.

28. Solve x0000 C x00 D 0; x.0/ D 0; x0.0/ D 1; x00.0/ D x000.0/ D 0 using the L-transform.

29. Find the "generalized solution" of x0 x D Ha.t/; x.0/ D 0.

30. Find the "generalized solution" of x0 C x D Ha.t/; x.0/ D 0.

31. Find the "generalized solution" of x0 x D ki; x.0/ D a, t 0:

32. Find the "generalized solution" of x00 C x D g.t/ ; x.0/ D x0.0/ D 0, where g is any piecewise continuous function with L-transform G.s/ defined for s > 0. In particular, solve in the case that g.t/ D OE0;1.t/.

33. Find the "generalized solution" of x00 D i.t a/, x.0/ D 1; x0.0/ D 0, where a > 0.

34. Solve x.t/ D 1 C e2t x.t/.

35. Solve x.t/ D t3 C sin t x.

36. Solve x0 k x D 1, x.0/ D 0, k > 0 a constant.

37. Solve x0 C .k2/ x D 1, x.0/ D 1, k D6 0.

38. Solve the system

² x0 D 2x C y; y0 D x 4y;

x.0/ D 0 y.0/ D 1.

39. Solve the system

² x0 D x C y; y0 D x C y;

x.0/ D 1 y.0/ D 0.

40. Solve the system

² x0 D x C y; y0 D y C i;

x.0/ D 0 y.0/ D 0.

12 Stability theory

In this chapter we present an introduction to the theory of stability. Since this is a very broad area which includes not only many topics but also various notions of stability, we mainly focus on Liapunov stability of equilibrium points and leave out topics such as the Poincaré­Bendixon theory, stability of periodic solutions, limit cycles, etc. Some of the proofs are omitted or carried out in special simple cases. For a more complete treatment the reader may consult sources such as the books by J. La Salle & S. Lefschetz, or by H. Amann, see References.

12.1 Definition of stability

Given x D .x1:x2; : : : ; xn/ 2 Rn; f D .f1; : : : ; fn/ 2 C 1.Rn; Rn/ and p D .p1; : : : ; pn/ 2 Rn (in this chapter we display the components of vectors horizon-

tally instead of vertically, as was done earlier), let x.t; p/ be the (unique) solution of

the system

x0 D f .x/; x.0/ D p

(12.1)

or equivalently

² xi0

D fi .x1; ; xn/

xi .0/ D pi :

.i D 1; 2; : : : ; n/:

We will suppose that the solution x.t; p/ is defined for all t 0 and for all p 2 Rn.

It is possible to show that the solution x.t; p/ depends continuously on the initial

condition p:

Theorem 12.1.1. Suppose that f is continuously differentiable on Rn. Given p 2 Rn, for each > 0 and T > 0 there exists r > 0 such that jx.t; p/ x.t; q/j < ,
for all t 2 OE0; T  and all jp qj < r.

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_12

252 12 Stability theory
In other words, for q close to p, x.t; q/ remains close to x.t; p/ in any finite interval, that is, solutions that are close to each other initially remain close to each other for some finite time. However, stability deals with the behavior of x.t; p/ for all t 0, that is, if they are initially close to each other then they remain close to each other for all time t 0.
Notation. Tr .y/ D ¹x 2 Rn W jx yj < r º denotes the ball of radius r > 0 centered aPt yxi22. Rn. Recall that jxj is the euclidean norm in Rn, namely jxj2 D .x j x/ D
Definition 12.1.2. Let x 2 Rn be such that f .x / D 0 so that x is an equilibrium point of (12.1):
1. x is stable if for every r > 0 there exists a neighborhood U of x such that p 2 U H) x.t; p/ 2 Tr .x / for all t 0.
2. x is asymptotically stable if there is a neighborhood U 0 of x such that limt!C1 x.t; p/ D x for all p 2 U 0.
3. x is unstable if it is not stable.
Of course, asymptotic stability implies stability. But there could be stable equilibria which are not asymptotically stable such as a Poincaré "center" ­ an equilibrium point surrounded by circular trajectories.

12.2 Liapunov direct method

At the beginning of the 1900's, the Russian mathematician Aleksandr Liapunov developed what is called the Liapunov Direct Method for determining the stability of an equilibrium point. We will describe this method and illustrate its applications.

Definition 12.2.1. Let x 2 Rn be an equilibrium point of (12.1). Let Â Rn be an open set containing x . A real valued function V 2 C 1. ; R/ is called a Liapunov function for (12.1) if
.V 1/ V .x/ > V .x / for all x 2 , x 6D x . .V 2/ VP .x/ dDef .rV .x/ j f .x// Ä 0, for all x 2 .

Recall that .x j y/ denotes the euclidean scalar product of the vectors x; y, see Nota-
tions. Moreover, rV D .Vx1 ; ; Vxn / denotes the gradient of V and the subscripts denote partial derivatives.
Note that, since x0.t/ D f .x.t//; we have that

VP .x.t// D Vx1 .x.t//f1 .x.t// C Vx2 .x.t//f2 .x.t// : : : C Vxn .x.t//fn .x.t//

D

Vx1

.x.t

//x

01.t

/

C

Vx2

.x.t

//x

0 2

.t

/

C

:

:

:

C

Vxn

.x

.t

//x

0 n

.t

/

D .rV .x.t// j x0.t// D d OEV .x.t//: dt

12.2 Liapunov direct method 253

In other words, VP .x.t//

D

dV .x.t // dt

is nothing but the derivative of V

along the

trajectories x.t/. Therefore (V2) implies that V .x.t// is non-increasing along the

trajectories x.t/.

Theorem 12.2.2 (Liapunov stabilty theorem).
(i) If (12.1) has a Liapunov function, then x is stable. (ii) If in .V 2/ one has that VP .x/ < 0, for all x ¤ x , then x is asymptotically
stable.

Proof. We will prove only the statement .i /. By the change of variable y D x x , the autonomous system x0 D f .x/ becomes y0 D f .y C x / which has y D 0 as equilibrium. Thus, without loss of generality, we can assume that x D 0. Moreover, still up to a translation, we can assume without loss of generality that V .x / D 0. Finally, for simplicity, we will assume that D Rn. The general case requires only
minor changes. Set
'p.t/ D V .x.t; p//:

The function 'p.t/ is defined for all t 0 and all p 2 Rn. Moreover 'p.t/ is differentiable and one has

'p0 .t / D Vx1 x10 C C Vxn xn0 D .rV .x.t; p/ j x0.t; p// D VP .x.t; p//:

By .V 2/ it follows that 'p0 .t/ Ä 0 for all t 0. Hence 'p.t/ is non-increasing and

thus

0 Ä V .x.t; p// Ä V .x.0; p// D V .p/; 8 t 0:

(12.2)

Given any ball Tr centered at x D 0 with radius r > 0, let Sr denote its boundary. From .V 1/ it follows that
m D m.r / D min¹V .y/ W y 2 Sr º > 0:
Let U D ¹p 2 Tr ; V .p/ < mº. From .V 1/ one has that U is a neighborhood of x D 0. Moreover, by (12.2) it follows that V .x.t; p// < m for all t 0 and all p 2 U . Since m is the minimum of V in Sr , the solution x.t; p/ has to remain in Tr , provided p 2 U , namely p 2 U H) x.t; p/ 2 Tr and this proves that x D 0 is stable.

Roughly, the Liapunov function V is a kind of potential well with the property that the solution with initial value p in the well remain confined therein for all t 0.
Remark 12.2.3. If VP D 0 for all t 0, then V .x.t; p// is constant, namely V .x.t; p// D V .x.0; p// D V .p/ for all t 0. Then x.t; p/ cannot tend to x as t ! C1. As a consequence, x is stable but not asymptotically stable.

Example 12.2.4. As a first application we want to study the stability of the nontrivial

equilibrium x

D

c d

;

y

D

a b

of the ² x0

Lotka­Volterra D ax bxy

system

y0 D cy C dxy:

254 12 Stability theory
Recall (see Section 8.2) that letting H.x; y/ D dx C by c ln x a ln y, x > 0; y > 0, one has that H is constant along the solutions of the system. Let us take V D H . Then VP D HP D 0 and hence .V 2/ holds with equality. Moreover we know that H has a strict local minimum at .x ; y / and thus .V 1/ is satisfied. It follows that H is a Liapunov function and one deduces that .x ; y / is stable (but not asymptotically stable, see Remark 12.2.3). We will see later on that the trivial equilibrium .0; 0/ is unstable.
Theorem 12.2.2 is countered with the following instability result
Theorem 12.2.5. Suppose that there exists a scalar function W 2 C 1. ; R/ such that W .x / D 0 and that WP .x/ WD .rW .x/ j f .x// is either positive or negative for all x 6D x . Moreover, we assume that there exists a sequence xk 2 , with xk ! x such that W .xk/WP .xk/ > 0. Then x is unstable.

12.3 Stability of linear systems and n-th order linear equations

In this section we will apply the previous theorems to study the stability of the linear

system

x0 D Ax; x D .x1; : : : ; xn/ 2 Rn:

We start with linear 2 2 autonomous systems. Recall that these systems have been discussed in Chapter 7, but here they are studied from the point of view of stability.

12.3.1 Stability of 2 2 systems

Changing notation, we call .x; y/ 2 R2 the variable and write the system in the form

² x0 D a11x C a12y y0 D a21x C a22y

(12.3)

where the coefficients aij are real numbers. Letting u D .x; y/ and

Â

Ã

AD

a11 a12 a21 a22

the system can be written as u0 D Au. If A is nonsingular, which we always assume,

the only equilibrium is .x; y/ D .0; 0/. We are going to study the qualitative proper-

ties of the solutions of (12.3), in particular their asymptotic behavior, as t ! C1.

Referring to Chapter 7 for some more details, let us recall that the Jordan normal

form of a nonsingular matrix A is a nonsingular matrix J with the property that there

exists an invertible matrix B such that BA D JB. The Jordan matrix J exists and

has the same eigenvalues 1; 2 as A. Moreover, if 1; 2 are real numbers, then

Â

Ã

1 6D 2 H) J D

1
0

0
2

:

(J1)

12.3 Stability of linear systems and n-th order linear equations 255

If 1 D 2 then either

Â

JD

1
0

Ã 0
1

(J2.1)

or

Â

Ã

JD

1
0

1
1

:

(J2.2)

If the eigenvalues are complex, D   i, then

Â

Ã

JD

 

 

:

(J3)

Lemma 12.3.1. The change of variable z D B 1u transforms the solutions u.t/ of u0 D Au into the solutions z.t/ of z0 D J z. Therefore, .0; 0/ is stable or unstable relative to u0 D Au if and only if it is the same relative to y0 D J z.

Proof. The first part of the lemma has been proved in Chapter 7 (with slightly different notation): from z0 D B 1u0 D B 1Au D JBu it follows that z0 D J z. If we set z D .z1; z2/ this shows that the change of variable B 1 transforms a solution curve u.t/ D .x.t/; y.t// of u0 D Au in the plane .x; y/ into a solution curve z.t/ D .z1.t/; z2.t// of z0 D J z in the plane .z1; z2/. Thus the qualitative properties
of .x.t/; y.t// are the same as those of .z1.t/; z2.t//. In particular, .x.t/; y.t// !
.0; 0/ as t ! 1 if and only if .z1.t/; z2.t// does the same, and hence the point .0; 0/ is stable or unstable relative to u0 D Au if and only if it is the same relative to z0 D J z.

By the lemma, it suffices to study the system u0 D J u:

Consider first the case when the eigenvalues are real and distinct. According to (J1)

the system u0 D J u becomes

² x0 D 1x

y0 D 2y

which is decoupled. Its solutions are given by x.t/ D c1e 1t and y.t/ D c2e 2t , where c1 D x.0/; c2 D y.0/ 2 R. If 1 < 0, resp. 2 < 0, then x.t/ ! 0, resp. y.t/ ! 0, as t ! C1. Therefore,

if both the eigenvalues are real and negative, the equilibrium .0; 0/ is asymptotically stable, while if one of the eigenvalues is positive, .0; 0/ is unstable.

We can write the solutions in the form y D y.x/. Precisely, if c1 D 0 then x.t/ Á 0. If c1 6D 0 we solve x.t/ D c1e 1t for t, obtaining

tD

1
1

ln



x c1



D

ln



x c1



1 1

:

256 12 Stability theory

Substituting into y.t/ we get

y.t/ D c2e

2t

" D c2 exp

2

ln



x c1



1 1

#

D

c2

exp

2 4ln



x c1



3

2

15

D

c2 c10

x

2 1

2
where c10 D c1 1 . The behavior of these functions depends on the sign of the eigen-
values and on their ratio. If 1 < 2 < 0, then the exponent of x is positive and

greater that 1, see Figure 12.1a. If 2 < 1 < 0, then the exponent of x is posi-

tive and smaller than 1. In any case the origin is asymptotically stable and is called a

stable node, see Figure 12.1b.

If 1 and 2 are positive, we have an unstable node. The graphs are plotted in

Figures 12.2a­12.2b.

If 1 2 < 0, the functions y.x/ are hyperbolas. The origin is unstable and is

called a saddle, see Figure 12.3.

We now consider the case when 1 D 2 WD and is real. If .J 2:1/ holds, then

the system becomes

² x0 D x y0 D y:

Thus x.t/ D c1e t ; y.t/ D c2e t and .0; 0/ is asymptotically stable provided < 0, otherwise .0; 0/ is unstable. It is still called a stable or unstable node. Here y.x/ D cx, with c D c2=c1, see Figures 12.4a­12.4b.
If .J 2:2/ holds, then the system becomes ² x0 D x C y y0 D y:
The solution of the second equation is y.t/ D c2e t . Substituting into the first one, we find x0 D x C c2e t which is a linear first order non-autonomous equation. The solution is x.t/ D .c1 C c2t/e t . Once again, if < 0 we have asymptotic stability. Otherwise, if > 0 we have instability. The origin is still a node.

(a)

(b)

Fig. 12.1. Stable node. (a) 1 < 2 < 0; (b) 2 < 1 < 0

12.3 Stability of linear systems and n-th order linear equations 257

(a)

(b)

Fig. 12.2. Unstable node. (a) 0 < 1 < 2; (b) 0 < 2 < 1

Fig. 12.3. Saddle, with 1 < 0 < 2

(a)

(b)

Fig. 12.4. Case .J 2:1/. (a) Stable node, with 1 D 2 < 0; (b) unstable node, with 1D 2>0

258 12 Stability theory

If c2 D 0 we find y.t/ Á 0. If c2 6D 0, we have

ÂÃ

e tD y

1 H) t D ln

y

:

c2

c2

Thus from x D .c1 C c2t/e t we infer

Ä

ÂÃ

1 yy

x D c1 C c2 ln c2

; c2

.c2 6D 0/:

The graphs are shown in Figures 12.5a­12.5b.
We finally consider the case in which the eigenvalues are complex. From .J 3/ it
follows that the system becomes ² x0 D x y y0 D x C y:

Using polar coordinates x.t/ D r .t/ cos Â.t/, y.t/ D r .t/ sin Â.t/, we find x0 D r 0 cos Â r Â 0 sin Â; y D r 0 sin Â C r Â 0 cos Â

whereby

² r 0 cos Â r Â 0 sin Â D .r cos Â / .r sin Â / r 0 sin Â C r Â 0 cos Â D .r cos Â / C .r sin Â /

Adding the first equation multiplied by cos Â to the second equation multiplied by sin Â we get r 0 D r . Similarly, subtracting the first equation multiplied by sin Â from the second equation multiplied by cos Â we get Â 0 D . In other words, the system in the unknowns r; Â is simply
² r0 D r Â0 D 
whose solutions are r .t/ D c1et ; Â.t/ D t C c2. Thus
x.t / D c1et cos.t C c2/; y.t / D c1et sin.t C c2/:

(a)

(b)

Fig. 12.5. Case .J 2:2/. (a) Stable node, with 1 D 2 < 0; (b) unstable node, with 1D 2>0

12.3 Stability of linear systems and n-th order linear equations 259

y

y

O

x

O x

(a)

(b)

Fig. 12.6. Case .J 3/, with  6D 0. (a)  < 0: stable focus; (b)  > 0: unstable focus

Thus stability depends only on . Precisely, one has:
if 1;2 D   i and  < 0, then the origin is asymptotically stable, while if  > 0, the origin is unstable.
If  6D 0, the equilibrium is called a focus, see Figures 12.6a­12.6b. The curves are spirals.
If 1;2 D   i and  D 0 we find that r .t/ is a constant. Thus the solution curves are circles r D c > 0, namely x2 C y2 D c, centered at the origin, see Figure 12.7. Hence
if 1;2 D   i and  D 0, the origin is stable, but not asymptotically stable.
The equilibrium is called a center.

y x2+y2=c>0

O

x

Fig. 12.7. Center: case (J3) with  D 0

260 12 Stability theory

Table 12.1. Stability of equilibria of u0 D Au; 1;2 are the eigenvalues of the 2 2 nonsingular matrix A

Eigenvalues

Equilibrium

1;2 2 R; 1; 2 < 0 1;2 2 R; 1; 2 > 0 1;2 2 R; 1 2 < 0 1;2 D   i;  < 0 1;2 D   i;  > 0
1;2 D i;

asymptotically stable node unstable node unstable saddle
asymptotically stable focus unstable focus stable center

Remark 12.3.2. To complete the discussion, consider some cases in which one eigen-

value of AÂis zero. Ã

If A D

b0 00

with b ¤ 0, the system is ² x0 D bx

y0 D 0

whose solutions are x.t/ D c1ebt , yÂ.t/ D cÃ2 which, in the .x; y/ - plane are half

lines parallel to the x axis. If A D

00 0b

; we find x.t/ D c1, y.t/ D c2ebt ,

namely a family of half lines parallel to the y axis. We have stability if b < 0 and

instability Âif b > 0.Ã

If A D

0b 00

the system is ² x0 D by

y0 D 0

whereby y.t/ D c2 and x.t/ D cÂ1 C c2bÃt which is a family of straight lines parallel

to the x axis. Similarly, if A D

00 b0

, then x D c1; y D c2 C c1bt. In both of

these two last cases we have instability for any b ¤ 0.

Table 12.1 summarizes the nature of the equilibrium .0; 0/ when A is nonsingular.

12.3.2 Stability of n n linear systems

Extending the previous results, we state the following theorem dealing with the linear autonomous n n system x0 D Ax, where x D .x1; : : : ; xn/ 2 Rn.
Theorem 12.3.3. Suppose that A is a constant n n nonsingular matrix. (i) If all the eigenvalues of A have negative real part, then x D 0 is asymptotically
stable. More precisely, for all p 2 Rn one has that x.t; p/ ! 0 as t ! C1. (ii) If one eigenvalue of A has positive real part, then x D 0 is unstable.
In the above statement, if an eigenvalue is real, its real part is the eigenvalue itself.

12.3 Stability of linear systems and n-th order linear equations 261

In the case that

0

10

A D BBBB@

0 :::

2 ::: ::: :::

0

0

1

0

::: 0

CCCAC

n

where the eigenvalues i are real (notice that we do not require that i 6D j for i D6 j ), the systems x0 D Ax splits into n independent equations xi0 D i xi . These equations yield xi .t/ D ci e i t . This immediately implies the asymptotic stability of 0N provided all i < 0. Moreover, if one of the i is positive, then xi .t/ D ci e it does not tend to 0 as t ! C1 and we have instability.

If A is not diagonal, the proof of .i / is based on finding a Liapunov function for x0 D Ax and on applying the Liapunov Stability Theorem 12.2.2. To avoid cum-

bersome calculations, we carry out the details in two specific examples in 3D. The

general case follows from similar arguments.

Let x D .x; y; z/ 2 R3, and consider the following two cases:

0

1

10

1. A D @ 0

0 A:

00

0

1

0

2. A D @   0A :

00

We

claim

that

V .x/

D

1 2

.x2

C

y2

C

z2/

is

a

Liapunov

function.

Clearly, V .x/ > 0 for all x 6D .0; 0; 0/ and hence .V 1/ holds. As for .V 2/, we

consider separately the two cases.

1. Since Ax D . x C y; y; z/ one infers VP D .rV j Ax/ D OEx2 C xy C y2 C z2:

Notice that

x2 C xy C y2 D x2 C xy C y2 C 3x2 D

4

4

x

Á2 Cy C

3x2

>

0;

8.x; y/

6D

.0; 0/:

2

4

Thus, if ; < 0 it follows that VP < 0 for all .x; y; z/ D6 .0; 0; 0/ and hence .V 2/ holds (with strict inequality).

2. Here the eigenvalues of A are   i and 2 R. We have that Ax D .x C y; x C y; z/ and hence
VP D .rV j Ax/ D OEx2 C y2 C z2:

Thus .V 2/ holds (with strict inequality) provided  and are both negative.

262 12 Stability theory
In each of the above cases, we can apply (ii) of the Liapunov Stability Theorem 12.2.2 to infer that x D .0; 0; 0/ is asymptotically stable provided all the eigenvalues of A have negative real parts.

12.3.3 Stability of n-th order linear equations
Recall that the linear n-th order equation in the real variable x

d nx

dn 1x

dx

dt n C an 1 dt n 1 C C a1 dt C a0x D 0

is equivalent to the system

8 <^^

x10 x20

D D

:^^ xn0 D

x2 x3
an 1xn

a1x2 C a0x1:

(12.4) (12.5)

The stability of the trivial solution of (12.4) is the same as the stability of the point with coordinates x1 D x2 D D xn D 0 for the equivalent system (12.5). In particular, the asymptotic stability of x D 0 means that for all p 2 R near x D 0 one has

lim x.t; p/ D lim dx.t; p/ D

t !C1

t!C1 dt

D

lim
t !C1

d n 1x.t; dtn 1

p/

D

0:

One can check that the roots of the characteristic equation

n C an 1 n 1 C C a1 C a0 D 0

of (12.4) coincide with the eigenvalues of the system (12.5). Let us show this claim in the case of the second order equation x00 C ax0 C bx D 0, equivalent to the system

² x10 D x2 x20 D ax2

bx1:

The eigenvalues are the solutions of

 b

1 a

 D 2 C a C b D 0;

which is the same as the characteristic equation of x00 C ax0 C bx D 0.

12.4 Hamiltonian systems 263
Using the preceding remark about the roots of the characteristic equation, we can use Theorem 12.3.3 to infer
Theorem 12.3.4. The trivial solution x D 0 is asymptotically stable if all the roots of the characteristic equation have negative real parts, while it is unstable if at least one root of the characteristic equation a has positive real part.
On the other hand, we might also work directly on the equation. Actually, the general solution of (12.4) is the superposition of terms tme t or tmet .sin t C cos t/, where or   i are roots of the characteristic equation. These terms, together with their derivatives, tend to zero as t ! C1 if and only if < 0, or  < 0.

12.4 Hamiltonian systems

Let H W Rn Rn 7! R be continuously differentiable and consider the hamiltonian

system

² xi0 D Hyi .x1; : : : ; xn; y1; : : : ; yn/ yi0 D Hxi .x1; : : : ; xn; y1; : : : ; yn/

i D 1; 2; n;

or, in a compact form

² x0 D ry H.x; y/ y0 D rx H.x; y/

(HS)

where rx H D .Hx1 ; ; Hxn/ and ry H D .Hy1 ; ; Hyn /. Planar hamiltonian systems have been discussed in Section 1 of Chapter 8. The
following Lemma is the counterpart of Lemma 8.1.1 therein.

Lemma 12.4.1. If .x.t/; y.t// is a solution of .HS /, then H.x.t/; y.t// is constant.

Proof. One has

d dt

H.x.t/; y.t//

D .rx H.

/ j x0/ C .ry H.

/ j y0/

where . / D .x.t/; y.t//. Since .x.t/; y.t// satisfies .HS / it follows

d H. / D dt

.rx H. / j ry H. // C .ry H. / j rx H. // D 0

and thus H.x.t/; y.t// is constant.

Theorem 12.4.2. Let H.0; 0/ D 0 and suppose that .0; 0/ is a local strict minimum

of H , namely that there exists a neighborhood

Rn Rn of .0; 0/ such that

H.x; y/ > 0 for all .x; y/ 2 , .x; y/ 6D .0; 0/. Then .0; 0/ is stable (but not

asymptotically stable).

Proof. We claim that the restriction of H to is a Liapunov function for .HS /. First of all, by assumption, .V 1/ holds. Moreover, Lemma 12.4.1 implies that HP D 0

264 12 Stability theory
y

x H=c

Fig. 12.8. Typical phase plane portrait of a hamiltonian system in 2D

and hence .V 2/ holds. From Theorem 12.2.2 it follows that .0; 0/ is stable. More precisely, since HP D 0 then, according to Remark 12.2.3, .0; 0/ is stable but not asymptotically stable. If n D 1 the equilibrium is like a stable center for linear systems. See
Figure 12.8.

Remark 12.4.3. To show the stability of the nontrivial equilibrium of the Lotka­ Volterra system (see Example 12.2.4), we could also use the preceding theorem.

If

H.x; y/ D 1 jyj2 C F .x/;

F 2 C 1.Rn; R/

2

the hamiltonian system .HS / becomes

² xi0 D

yi

yi0 D Fxi .x/

which is equivalent to the second order gradient system

x00 C rF .x/ D 0;

(12.6) (12.7)

namely

xi00 C Fxi .x1; : : : ; xn/ D 0;

i D 1; : : : ; n:

Let us point out that an equilibrium x of a system such as (12.7) corresponds to
the equilibrium .x ; 0/ of the equivalent first order system (12.6). Stability of x for
(12.7) has to be understood as the stability of .x ; 0/ for (12.6). For example, the asymptotic stability of x means that x.t; p/ ! x and x0.t; p/ ! 0 as t ! C1, for all p close to x .

12.5 Stability of equilibria via linearization 265

The following theorem is known as the Dirichlet­Lagrange stability criterion.

Theorem 12.4.4. Let F .x / D 0 and suppose that x is a local strict minimum of F . Then the equilibrium x is stable with respect to (12.7).

Proof.

It suffices

to remark that

H.x; y/

D

1 2

jy

j2

CF

.x

/

has

a

strict local

minimum

at .x ; 0/ and apply Theorem 12.4.2.

12.5 Stability of equilibria via linearization

Given a system x0 D f .x/ with equilibrium x D 0, its linearization at x D 0 is the linear system x0 D Ax, where A D rf .0/.
Developing f in Taylor's expansion we find f .x/ D Ax C o.jxj/. Then the linearized system is x0 D Ax. We have seen that a sufficient condition for the asymptotic stability of x D 0 for x0 D Ax is that all the real parts of the eigenvalues of A
be negative, whilst if at least one eigenvalue is positive, or has positive real part, then x D 0 is unstable. This result is extended to the nonlinear case in the next theorem,
whose proof is omitted.

Theorem 12.5.1. Suppose that all the eigenvalues of rf .0/ have negative real parts.
Then the equilibrium x D 0 is asymptotically stable with respect to the system x0 D rf .0/x C o.jxj/.
If at least one eigenvalue of rf .0/ has positive real part, then the equilibrium
x D 0 is unstable.

Example 12.5.2. Consider the Van der Pol system
² x0 D y y0 D x 2 .x2 1/y

with j j < 1. Here the eigenvalues of

Â

Ã

A D rf .0; 0/ D

01 12

p are 1 D C 2 1, 2 D

p 2 1. If 0 < < 1, both the eigenvalues

have positive real part and the equilibrium .0; 0/ is unstable. On the other hand, if

1 < < 0, both the eigenvalues have negative real part and the equilibrium .0; 0/

is asymptotically stable.

Example 12.5.3. We have seen in Example 12.2.4 that the nontrivial equilibrium of

a Lotka­Volterra system

² x0 D ax bxy y0 D cy C dxy

266 12 Stability theory

is stable. On the contrary, let us show that .0; 0/ is unstable. Here

Â

ÃÂ

Ã

f .x; y/ D

f1.x; y/ f2.x; y/

D

ax bxy cy C dxy

:

Thus

Â

rf .x; y/ D

a by dy

Ã bx c C dx

and hence

Â

Ã

A D rf .0; 0/ D

a 0

0 c

whose eigenvalues are a > 0; c < 0. It follows that .0; 0/ is unstable.
Consider the one-dimensional case of a single equation x0 D f .x/, where f is continuously differentiable and f .0/ D 0. The linearized equation is x0 D f 0.0/x for which the stability of x D 0 is determined by the sign of f 0.0/. Then the previous theorem yields that the equilibrium x D 0 is asymptotically stable if f 0.0/ < 0 and unstable if f 0.0/ > 0.
Example 12.5.4. If f .x/ D x x3, x D 0 is an equilibrium of x0 D f .x/. Since f 0.0/ D , it is asymptotically stable if < 0 and unstable if > 0. When becomes positive there is a change of stability and a papir of nontrivial equilibria branch off from D 0. These new equilibria are x D  . Since f 0.x / D 3x2 D
2 < 0 for > 0, it follows that x are asymptotically stable. This phenomenon is called a pitchfork bifurcation. See Figure 12.9.
The same bifuprcation arises in the case of x0 D x C x3. Here the nontrivial equilibria x D  . /, < 0, are unstable and the branch is downward directed.

stable O

stable x

unstable



-x  stable

Fig. 12.9. Pitchfork bifurcation for x0 D x x3

12.5 Stability of equilibria via linearization 267
The following example shows that if the matrix rf .0/ has a pair of conjugate eigenvalues with zero real parts, the stability of x D 0 cannot be deduced by the previous theorems, but depends on the higher order term in the Taylor's expansion of f .x/.

Example 12.5.5. Consider the system
² x0 D y C x.x2 C y2/ y0 D x C y.x2 C y2/

(12.8)

whose linear part has eigenvalues i . Letting V .x; y/ D x2 C y2, let us evaluate VP D 2.xx0 C yy0/:

Multiplying the first equation by x and the second by y and summing up, we get xx0 C yy0 D .x2 C y2/2:

Therefore

VP D 2 .x2 C y2/2;

whose sign depends on . The equilibrium .0; 0/ is asymptotically stable if < 0, whilst it is unstable if > 0. If D 0, then VP D 0 and hence we have stability. As an exercise, the reader can transform (12.8) using polar coordinates x D cos Â; y D
sin Â, and show that for D6 0 the trajectories are spirals, with a behavior like the
one plotted in Figures 12.6a­12.6b.

12.5.1 Stable and unstable manifolds
The results below describe the behavior of the solutions near an unstable equilibrium in more detail.
Consider the linear system x0 D Ax. The equilibrium x D 0 is called hyperbolic if the matrix A has no eigenvalues with zero real part.
Theorem 12.5.6. Suppose that x D 0 is a hyperbolic equilibrium: A has k eigenvalues 1; : : : ; k with negative real parts and n k eigenvalues kC1; : : : ; n with positive real parts. Let ei , i D 1; ; n, denote an orthogonal system of eigenvectors corresponding to i and let
Ls D Lks D span¹e1; ; ekº; Lu D Lnu k D span¹ekC1; ; enº:
Then: (i) Ls and Lu are invariant, that is if p 2 Ls, resp. p 2 Lu, then x.t; p/ 2 Ls,
resp. x.t; p/ 2 Lu, for all t. (ii) p 2 Ls if and only if limt!C1 x.t; p/ D 0. (iii) p 2 Lu if and only if limt! 1 x.t; p/ D 0.

268 12 Stability theory
y

O

x

Fig. 12.10. Phase plane portrait of x0 D Ax, x D .x; y/, with A D diag¹ 1; 2º, 1 < 0 < 2

Proof. We prove the theorem in the simple case in which A D diag¹ 1; ; nº,

where 1 Ä

Ä k < 0 < kC1 Ä

Ä n. The system x0 D Ax is

decoupled into n independent equations xi0 D i xi . If p D .p1; ; pn/, one

finds that x.t; p/ D .p1e 1t ; ; pne nt /. Then limt!C1 x.t; p/ D 0 if and

only if pkC1 D D pn D 0. This implies that Ls D span¹e1; ; ekº. Sim-

ilarly, limt! 1 x.t; p/ D 0 if and only if p1 D D pk D 0 and hence

Lu D span¹ekC1; ; enº.

If n D 2 and A D diag¹ 1; 2º we find the saddle plotted in Figure 12.10.

Example 12.5.7. Consider the system
² x0 D x C y y0 D y

ÂThe originÃ.0; 0/ is unstable because the eiÂgenvaÃlues of the coefficient matrix A D

11 01

are 1 D 1; 2 D 1. If ei D

ai bi

are two eigenvectors correspond-

ing to i , i D 1; 2, the stable, resp. unstable, manifold is the linear space spanned by

e1, resp. e2, namely the straight lines

x D ai t;

y D bi t;

or else

y D bi x: ai

Solving Aei D i ei , namely ²

ai C bi D i ai bi D i bi

12.5 Stability of equilibria via linearization 269
y
x

Fig. 12.11. The hyperbolas 2xy D 2c1c2 C y2 with asymptotes y D 0 (stable manifold) and y D 2x (unstable manifold)

we can take

ÂÃ

e1 D

1 0

;

ÂÃ

e2 D

1 2

:

It follows that the stable manifold is y D 0, while the unstable manifold is y D 2x.

The reader should notice that the solutions of the given system are x D c1e t C

1 2

c2et

,

y

D

c2et .

From

the

last

equation

we

get

et

D

y=c2.

Substituting into

the

first

equation it follows

x D c1c2 C y y2

which yields the family of hyperbolas 2xy D 2c1c2 C y2:
The stable and unstable manifolds are exactly the asymptotes of these hyperbolas. See Figure 12.11.
The previous result can be extended to the nonlinear system x0 D rf .0/x C o.jxj/.

Theorem 12.5.8. Let f be smooth and suppose that the matrix A D rf .0/ has k

eigenvalues with negative and n k eigenvalues with positive real parts. Then there

are smooth surfaces M s spectively, with M s [ M

uDDM¹k0s ºa, nddefiMneud

D in

Mnu k , of dimension a neighborhood of x

k and D 0,

nk which

reare

tangent to Ls, resp. Lu, such that:

(i) M s and M u are invariant, that is, if p 2 M s, resp. p 2 M u, then x.t; p/ 2 M s, resp. x.t; p/ 2 M u, for all t.
(ii) p 2 M s if and only if limt!C1 x.t; p/ D 0. (iii) p 2 M u if and only if limt! 1 x.t; p/ D 0.

270 12 Stability theory

Ls

Ms

y

Lu

O

Mu

Lu Mu
x Ms Ls

Fig. 12.12. Stable and unstable manifolds
The surface M s is called the stable manifold of the system, whilst M u is called the unstable manifold, see Figure 12.12. If f .x/ D Ax the stable and unstable manifolds are the linear spaces Ls; Lu. If all the eigenvalues have negative, resp. positive, real parts then M u D ;, resp. M s D ;.
Remark 12.5.9. If M s; M u are defined globally on Rn, it is possible to prove that if p 2 Rn n M s, then x.t; p/ approaches M u asymptotically as t ! C1.
12.6 Exercises
1. Show that .0; 0/ is asymptotically stable for the linear system ² x0 D 2x C y y0 D 7x 4y:
2. Show that .0; 0/ is asymptotically stable for the linear system ² x0 D x y y0 D 4x y:
3. Show that .0; 0/ is stable for the linear system ² x0 D x y y0 D 3x y:
4. Study the stability of .0; 0/ for the system ² x0 D 2ax y y0 D .9 C a2/x
depending on the parameter a.

12.6 Exercises 271

5. Show that .0; 0/ is unstable for the system ² x0 D x C 4y y0 D 3x 5y

and find the stable and unstable manifold.
6. Study the stability of the trivial solution of the equation x00 C 2x0 x D 0. 7. Study the stability of the trivial solution of the equation x00 C 2x0 C x D 0. 8. Study the stability of the trivial solution of the equation x00 C 2hx0 C k2x D 0,
h; k 6D 0.

9. Show that the equilibrium of the system

8

< x10 D

:

x20 x30

D D

2x1 C x2 C x3 2x2 C x3 x2 2x3

is asymptotically stable.

10. Study the stability of the equilibrium of the system

8 <

x10

D

:

x20 x30

D D

ax1 C 5x3 x2 2x3 3x3

depending on a 6D 0.

11. Show that the equilibrium of the system

8

< x10 D

:

x20 x30

D D

x1 C x2 C x3 x1 2x2 x3 x2 x3

is unstable.

12. Find a such that the equilibrium of the system

8 <

x10

D

:

x20 x30

D D

ax1 ax2 C x3 x2 C ax3

is asymptotically stable.

13. Study the stability of the equilibrium of the system

8 ^^<

x10 x20

D D

:^^

x30 x40

D D

x2 C x4 x2 C x3
x2 C x3 x1 x4:

14. Consider the third order equation x000 C ax00 C bx0 C cx D 0 and prove that the roots of the characteristic equation 3 C a 2 C b C c D 0 coincide with the

272 12 Stability theory

eigenvalues of the equivalent first order system

8 <

x10

D

x2

:

x20 x30

D D

x3 ax3

bx2

cx1:

15. Study the stability of the trivial solution x D 0 for the equations x000 C x D 0 and x000 x D 0.
16. Study the stability of the trivial solution of x000 C 5x00 C 9x0 C 5x D 0. 17. Prove that the trivial solution of x0000 C x000 x0 x D 0 is unstable. 18. Prove that x D 0 is stable for x0000 C 8x000 C 23x00 C 28x0 C 12 D 0.

19. Prove that the equilibrium of the system

² x00 D y00 D

x0 2y 3x C 2y0

is unstable.
20. Show that the equilibrium of the system ² x00 2y0 D ax C 3y y00 C 2x0 D 3x C ay

is unstable provided jaj < 3. 21. Show that x0 D x x5 has a pitchfork bifurcation.

22. Show that x0 D x x3 x5 has a pitchfork bifurcation.

23. Show that x0 D x x3 x2kC1 has a pitchfork bifurcation provided that k > 1.

24. Show that .0; 0; 0/ is unstable for the linear system

8 <

x10

D

x1

:

x20 x30

D D

2x2 x3

and find the stable and unstable manifold.

25. Determine the stability of .0; 0/ of
² x0 D y0 D

x C y C y2 2y x2:

26.

Show that V .x; y/ D

1 4

.x

4

C y4/ is a Liapunov function for the system,

² x0 D x3

y0 D y3

and deduce the stability of .0; 0/.

12.6 Exercises 273

27.

Show that V .x; y/ D

1 2

.x

2

C y2/ is a Liapunov function for the system,

² x0 D y x3

y0 D x y3

and deduce the stability of .0; 0/.
28. Show that .0; 0/ is unstable for ² x0 D y C x3 y0 D x C y3:

29. Consider the system

² x0 D y y0 D x.x C a/ y

where a > 0. Show that .0; 0/ is asymptotically stable.

30. For the same system, show that . a; 0/ is unstable.

31. Study the stability of the equilibrium of gradient system ² x00 C 4x.x2 C y2/ D 0 y00 C 4y.x2 C y2/ D 0.

32. Study the stability of the equilibrium of the equation x00 C f .x0/ C g.x/ D 0 under the assumption that f .0/ D g.0/ D 0 and yf .y/ 0 and xg.x/ > 0 for all x 6D 0.

33. Study the stability of the equilibrium of gradient system

² x00 C 2.x 1/ C 2xy2 D 0

y00 C 2x2y

D 0.

13 Boundary value problems

In this chapter we discuss boundary value problems for second order nonlinear equations. The linear case has been discussed in Chapter 9.
We first deal with autonomous and then with the non-autonomous equations.

13.1 Boundary value problems for autonomous equations

In this first section we consider the autonomous nonlinear boundary value problem

² x00 D f .x/ x.0/ D x.b/ D 0

(13.1)

by using the phase plane analysis. We assume the student is familiar with this topic

discussed in Section 8.3 of Chapter 8.

F

Consider .x/ D c,

twheheprheasFe.pxl/anDe .xR;0xyf/,.ys/Dds

x .

0, and the We will

curve c of assume that

the c

equation

1 2

6D ; and

y2 does

not contain any singular points. Thus c is a regular curve that carries a solution of

x00 D f .x/ with energy c. Furthermore, suppose that c is a closed curve and let c

be the arc of c , contained in the half plane x 0, with endpoints .0; Yc/; .0; Yc/,

for some Yc > 0 (recall that c is symmetric with respect to y), see Figure13.1a.

Without loss of generality, we can assume that the solution xc .t/, with energy c, is

such that xc.0/ D 0 and yc.0/ D Yc.

Let x D Xc > 0 be such that .Xc ; 0/ is the point where c crosses the x axis

and let tc > 0 be such that xc .tc / D Xc and yc .tc / D 0, see Figure 13.1a. To eval-

uate

tc

we

use

the

enerpgy

relationship

1 2

y2

F .x/ D c which yields F .x/

c

and y pD y.x/ D  2F .x/ C 2c. Since y.x/ > 0 for 0 < x < Xc, we get

y D C 2F .x/ C 2c.

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_13

276 13 Boundary value problems

(a)

(b)

Fig. 13.1. (a) The arc c; (b) The solution xc .t /, 0 Ä t Ä 2tc

From x0

Dy

it follows that dt

D

dx x0

D

dx y

.

Moreover, as t

ranges

from 0 to tc ,

x ranges from 0 to Xc . Therefore,

Z tc

Z Xc dx

tc D dt D

0

0

D y

Z Xc

dx

1 Z Xc

dx

D

p

Dp

p

:

(13.2)

0 2F .x/ C 2c

2 0 F .x/ C c

Lemma 13.1.1. If Xc is not a singular point, then tc < C1.

Proof. Since F .Xc / C c D 0, its Taylor expansion is F .x/ C c D F 0.Xc /.x Xc / C o.jx Xc j/ D f .Xc /.x Xc / C o.jx

Thus

p

p

p

F .x/ C c D f .Xc / x

Xc C o.jx

Xc j1=2/:

Xc j/:

By c/

a1s=s2uims ipnttieognr,aXblceiisnntohteainsitnergvuallarOE0p;oXinct,annadmheelnyceR0fXc.X.Fc

/ 6D 0. Therefore, .F .x/ C .x/ C c/ 1=2dx is finite.

The reader should notice the difference with the homoclinic and heteroclinic case, discussed in Chapter 8, where we have shown that if Xc is a singular point, then tc D C1.

Let c be the time needed by the point .xc.t/; yc .t// 2 c to go from .Xc ; 0/

to .0; R Yc /. By symmetry, onpe has that c D tc. Let us check this fact. As before,

cD

c
0

dt.

But

now

y

D

2F .x/ C 2c. Moreover, as t ranges from 0 to c , x

ranges downwards from Xc to 0. Therefore,

Zc

Z 0 dx

1 Z0

cD
0

dt D

Dp

Xc y

2 Xc

1 Z Xc

dx

Dp

p

D tc:

2 0 F .x/ C c

p dx F .x/ C c

13.1 Boundary value problems for autonomous equations 277

The function xc.t/ has the following properties:

1. xc .0/ D 0; xc0 .0/ D Yc > 0. 2. xc .tc / D Xc ; xc0 .tc / D 0. 3. xc .2tc/ D 0; xc0 .2tc / D Yc < 0.

It follows that if c is such that 2tc D b, the corresponding xc.t/ solves the boundary

value problem (13.1),

is positive and

its maximum

is Xc ,

achieved at

t

D

tc

D

b 2

.

See Figure 13.1b.

Theorem 13.1.2. Let c be such that c 6D ; is a closed curve that does not contain any singular points. If c satisfies

p Z Xc

dx

bD 2

p

;

0 F .x/ C c

(13.3)

then the function xc.t/ is a solution of the boundary value problem (13.1) such that xc.t/ > 0 for all a < t < b.
Proof. We have seen that a solution xc.t/ corresponds to a c such that b D 2tc. Since tc is given by (13.2), we obtain (13.3), proving the theorem.

Remark 13.1.3. (i) More generally, if the equation b D 2ktc has a solution c D ck, k D 1; 2; : : :, (see Figure 13.2), we find a solution xck .t/ that changes sign k 1 times. Note that, in any case, xc0 k .0/.D Yck / > 0. For example, if k D 2, the solution xc2.t/, corresponding to the closed curve c2 , is positive for 0 < t < 2tc2, negative for 2tc2 < t < 4tc2 and such that xc0 2.0/ > 0.

(c) b/k2

ck

c

Fig. 13.2. Solutions

of ^.c/

D

pb k2

278 13 Boundary value problems
(ii) By a similar argument, one can show that the boundary value problem ² x00 D f .x/ x.a/ D x.b/ D 0

has a solution that changes sign k 1 times in .a; b/ provided the equation

p Z Xc

dx

b a D 2k

p

0 F .x/ C c

has a solution c D ck.

13.1.1 Examples

Below we demonstrate a couple of specific examples that show how to solve equation (13.3) in order to find solutions of the boundary value problems.

Proposition 13.1.4. The problem ² x00 C 4x3 D 0 x.0/ D x.b/ D 0

(13.4)

has infinitely many solutions.

Proof.

In

this

case

c

has

equation

1 2

y2

C

x4

D

c.

For

all

c

>

0,

c

is

nonempty

and is a closed curve that does not contain the (unique) singular point .0; 0/. By The-

orem 13.1.2 and Remark 13.1.3, if the equation

p Z Xc dx

b D 2k

p

; k D 1; 2; : : : ;

0

c x4

has a solution c D ck, then (13.4) has a solution that changes sign k

.a; b/. Setting

^.c/ D Z Xc p dx

0

c x4

1 times in

the preceding equation becomes ^.c/

D

pb 2

k

.

Notice

that

in

this

case

Xc

is the

positive solution of x4 D c, that is Xc D c1=4. Thus

Z c1=4

dx

^.c/ D

p

:

0

c x4

Notice that c x4 0 for 0 Ä x Ä Xc D c1=4. Moreover, according to (13.2) and Lemma 13.1.1, the integral is finite. Let us study the function ^.c/.

13.1 Boundary value problems for autonomous equations 279

The change of variable x D c1=4z yields dx D c1=4dz and hence, for c > 0 one

finds

^.c/ D Z 1 pc1=4dz

Dc

Z
1=4

1 p dx

:

0 c cz4

0 1 z4

Thus ^.c/ is positive, decreasing and satisfies limc!0C ^.c/ D C1 and

limc!C1

^.c/

D

0. It follows that for every k

D

1; 2; : : :, the equation ^.c/

D

pb k2

has a solution ck > 0 that gives rise to a solution of (13.4).

Proposition 13.1.5. If k is an integer such that 1 < k2 <

problem

² x00 C .x x3/ D 0

x.0/ D x. / D 0

< .k C 1/2, then the (13.5)

has k pairs of nontrivial solutions xj .t/, 1 Ä j Ä k, with j 1 zeros in the open interval .0; /. If Ä 1, there is only the trivial solution.

Proof.

Here

the

curve

c

is

defined

by

the

equation

1 2

y2

C

.

1 2

x

2

1 4

x4/

D

c,

that is y2 C .x2

1 2

x4/

D

2c.

For

0

<

2c

<

the curve c is not empty, closed,

symmetric with respect to x and y, and does not contain the singular points .0; 0/

and .1; 0/. According to Theorem 13.1.2, setting Xc D > 0, we have to solve

the equation

Z
D 2k q 0 2c

dx

:

.x2

1 2

x

4/

The change of variable x D z yields
Z1 D 2k q
0 2c

dz . 2z2

:

1 2

4z4/

Since

satisfies 2c D . 2

1 2

4/, we have

Z1

D 2k q

0

.2

1 2

4/

dz . 2z2

1 2

4z4/

and, factoring

> 0 in the denominator and then canceling it, we obtain

2k Z 1

Dp

q

01

dz :

12 2

z2

C

1 2

2z4

Let us study the behavior of the function . /, defined for 0, by setting

. / dDef p2

Z1 q

01

dz :

12 2

z2

C

1 2

2z4

(13.6)

280 13 Boundary value problems

If D 0, one has

.0/ D p2 Z 1 p dz D p : 0 1 z2

Since

@q @1

1

1

D

12 2

z2

C

1 2

2z4

2 .1

12 2

C z4

z2

C

1 2

D 2z4/3=2

D1 2 .1

.1 z4/

12 2

z2

C

1 2

; 2z4/3=2

then differentiating the quantity under the integral (13.6), we obtain

0. / D p1 Z 1 0 .1

.1 z4/dz

12 2

z2

C

1 2

> 0: 2 z 4 /3=2

Moreover,

0

1

l i m !1 B@ q 1

1

CA D q

12 2

z2

C

1 2

2z4

1 2

1 D

z2

C

1 2

z

4

p D 2p
1

p

p

1

Dp 2 D

2z2 C z4

.1 z2/2 1

2 z2 :

Fig. 13.3. Solutions of . / D k , with 1 < k2 < < .k C 1/2

13.2 The Green function 281

Thus

l i m !1

.

/

D

p 2p 2

Z1
0

1

dz z2

D C1:

The graph of . / is shown in Figure 13.3.
Recall that we have to solve D k. /, namely . / D k . From the graph of . / it follows that the equation . / D k has a solution if and only if k > p , namely whenever > k2. Precisely, if 1 Ä k2 < < .k C 1/2 the equation
. / D k has k solutions 1; k and hence (13.5) has k nontrivial solutions xj .t/, 1 Ä j Ä k. Notice that Theorem 13.1.2, resp. Remark 13.1.3, imply that x1.t/ > 0 in .a; b/, resp. xj has j 1 zeros in .0; / and xj0 .0/ > 0. Notice also that the solutions of (13.5) arise in pairs because if x.t/ is a solution, so is x.t/. Finally, if < 1
then k < for all k D 1; 2 : : : and hence the equation . / D k has no solution. Thus, in this case, problem (13.5) has only the trivial solution.

Remark 13.1.6. The fact that (13.5) has only the trivial solution for < 1 could also be proved using the Poincaré inequality as in Example 9.2.7. The reader could carry out the details as an exercise.

13.2 The Green function

To solve boundary value problems with a time dependent nonlinearity, it is useful to introduce the Green function. This is what we are going to do in this section.
Let p; r be functions satisfying:

1. p.t/ > 0 and is continuously differentiable on the interval OEa; b. 2. r .t/ 0 and is continuous on the interval OEa; b.

These assumptions will be assumed throughout the rest of this chapter.

Define the differential operator L by setting

Â

Ã

LOEx dDef d

dx p .t /

r .t/x:

dt

dt

The operator L is linear, that is

LOEc1x C c2y D c1LOEx C c2LOEy:

The reader will notice that L is the differential operator used in Chapter 9 with q D 1 and r x instead of r x (the choice of r is made for convenience, only: recall that no assumption on the sign of r was made there). In particular, from Theorem 9.2.2 of Chapter 9 (with q.t/ D 1) it follows that the eigenvalue problem
² LOEx C x D 0; t 2 OEa; b x.a/ D x.b/ D 0

has a sequence i , with 0 < 1 < 2 < : : : ; of eigenvalues.

282 13 Boundary value problems

Let '; be the solutions of the Cauchy problems

² LOE' D 0; t 2 OEa; b

² LOE  D 0; t 2 OEa; b

'.a/ D 0; '0.a/ D  D6 0

.b/ D 0; 0.b/ D  6D 0:

Notice that .a/ D6 0, otherwise would satisfy LOE  D 0 and .a/ D .b/ D 0 and this means that is an eigenfunction of L with eigenvalue D 0, which is not possible. Of course, for the same reason we also have '.b/ D6 0. Consider their Wronskian W .t/ D '.t/ 0.t/ '0.t/ .t/ and recall that, by the Abel theorem, W .t/ Á const, say W .t/ D C .
From the definition of '; it follows that
C D W .a/ D '0.a/ .a/ D W .b/ D '.b/ 0.b/ 6D 0:

In other words, ' and are linearly independent.

The Green function of L (with boundary conditions x.a/ D x.b/ D 0) is the

function G.t; s/ defined on the square Q D OEa; b OEa; b by setting

8 <

1 p.t /C

'.t /

.s/;

G.t; s/ D :

1 p.t /C

'.s/

.t /;

if t 2 OEa; s if t 2 OEs; b:

The function G is continuous on Q and

G.a; s/ D '.a/ .s/ D 0; p.a/C

G.b; s/ D '.s/ .b/ D 0: p.b/C

(13.7)

Moreover, G is differentiable at .t; s/ 2 Q, s D6 t. In addition, for each s, setting

Gt .s ; s/ D limt!s

d dt

G.t

;

s

/

and

Gt .sC; s/

D

limt !sC

d dt

G.t

;

s

/,

it

is

easy

to

check that Gt .s ; s/ Gt .sC; s/ D Cp.s/.

Example 13.2.1. Let us calculate the Green function of LOEx D x00 x in the inter-

val OE0; 1. Here p D r D 1 and OEa; b D OE0; 1. The general solution of x00 x D 0

is x D c1et C c2e t . If x.0/ D c1 C c2 D 0 and x0.0/ D c1 c2 D 1, we find

c1

D

1 2

;

c2

D

1 2

and we can take '

D

1 2

.et

e

t/

D

sinh t. If x.1/

D

c1e

C

c2 e

D

0

and x0.1/ D c1e

c2 e

D

1, we find c1 D

1 2e

;

c2

D

e 2

and we can take

D

1 2e

e

t

e 2

e

t

D

1 et 2e

ee t D

1 2

et

1

e .t 1/ D

sinh.t 1/. Clearly

'; are linearly independent and

1 e 1 e2

C D .0/ D

D

<0

2e 2 2e

and hence

8

<

2e e2 1

sinh t

sinh.s

1/;

G.t; s/ D : 2e
e2 1

sinh s

sinh.t

1/;

if t 2 OE0; s if t 2 OEs; 1

is the Green function we are looking for.

13.2 The Green function 283

The Green function of L can be used to transform a boundary value problem into an integral equation.

Theorem 13.2.2. For any continuous function h.t/, the nonhomogeneous problem

² LOEx C h.t/ D 0; t 2 OEa; b x.a/ D x.b/ D 0

(13.8)

has a unique solution given by the function
Zb x.t/ D G.t; s/h.s/ds:
a

RPdRaterbbsoGdiorsef..,dao;bnTsoe/ouhhns.adsism/adrpyslicfDoyntd0hietaionnndostax. tF.iboun/rt,hDweremRtaobarkGee,.sbpp;lsiÁt/thin.1sg./tdUhsesiiDnngte0(g1,r3as.lo7R)ta,hbwadtesxfiinsntadotisRxfiat.eads/sthCDe

Zt

Zb

x.t/ D G.t; s/h.s/ds C G.t; s/h.s/ds:

a

t

Since

for

a

Ä

s

Ä

t

one has

that G.t; s/

D

1 C

.'.s

/

.t//, while for t Ä s Ä b one

has

that

G.t; s/

D

1 C

.'.t /

.s//, it follows that

x.t/ D

Z .t /

t

'.s/h.s/ ds

Z C '.t/

b

.s/h.s/ ds:

aC

t

C

Then x.t/ is differentiable and, using the fundamental theorem of Calculus, we get

x0.t/ D D

Z 0.t /

t

'.s/h.s/ ds C

1 '.t /

.t /h.t /

a

C Zb

C '0.t/

C .s/h.s/
ds

1 .t /'.t /h.t /

Z 0.t /

t

t
'.s/h.s/

C ds

C

'0.t

/

C Zb

.s/h.s/ ds:

aC

t

C

Therefore x0 is also differentiable and one has

x00.t / D D

Z 00.t /

t

'.s/h.s/ ds C

1

0 .t /'.t /h.t /

a

C Zb

C '00.t /

C .s/h.s/
ds

1 '0.t/ .t/h.t/

Z 00.t /

t

t
'.s/h.s/

C ds

C

'00.t

/

C Z

b

.s/h.s/ ds

aC

t

C

C 1 0.t/'.t/ '0.t/ .t/ h.t/: C

284 13 Boundary value problems

Notice that '0.t/ .t/ 0.t/'.t/ D W .t/ D C . Thus

LOEx D x00.t/

rx D

Z 00.t /

t

Z '.s/h.s/ ds C '00.t/

b

.s/h.s/ ds

h.t /

rx:

aC

t

C

Since LOE' D '00 r ' D 0 and LOE  D 00 r D 0, we find

LOEx

D

r

Z .t /

t

Z '.s/h.s/ ds C r '.t/

b

.s/h.s/ ds

h

rx

aC

t

C

"

Z t '.s/h.s/

Z b .s/h.s/ #

D r .t/

ds C '.t/

ds h rx

aC

t

C

D

"Z t '.s/ r

.t /h.s / ds

Z C

b

'.t /

# .s/h.s/
ds

h

rx

a

C

t

C

Zb
D r G.t; s/h.s/ds h r x D r x h r x D h:
a

This proves the existence of a solution of (13.8). To prove the uniqueness, let x1; x2 be two solutions of (13.8). Then, setting z D x1 x2, one has LOEz D LOEx1 LOEx2 D 0 and z.a/ D z.b/ D 0. Since D 0 is not an eigenvalue of L with zero boundary conditions, it follows that z.t/ Á 0, that is x1.t/ D x2.t/ for all t 2 OEa; b.

Corollary 13.2.3. If f .t; x/ is continuous, then Zb
x.t/ D G.t; s/f .s; x.s//ds
a
is a solution of LOEx C f .t; x/ D 0, x.a/ D x.b/ D 0.

13.3 Sub- and supersolutions

In this section we study the nonlinear boundary value problem ² x00 D f .t; x/; t 2 OEa; b x.a/ D x.b/ D 0

(13.9)

where f .t; x/ is a continuous real valued function defined on OEa; b R. Notice that the equation can also be written as x00 C f .t; x/ D 0, in which the differential operator x00 has the form LOEx introduced in the previous section, with p D 1 and r D 0. In particular, according to Corollary 13.2.3, to find a solution of the preceding problem it suffices to find x.t/ solving the integral equation
Zb x.t/ D G.t; s/f .s; x.s//ds
a
where G is the Green function of x00 with boundary conditions x.a/ D x.b/ D 0.

13.3 Sub- and supersolutions 285

Definition 13.3.1. A function v 2 C 2.OEa; b/ is a subsolution of (13.9) if

8 <

v00 Ä f .t; v/;

t 2 OEa; b

:

v.a/ v.b/

Ä0 Ä 0:

A function w 2 C 2.OEa; b/ is a supersolution of (13.9) if

8 <

w00

f .t; w/;

t 2 OEa; b

:

w.a/ w.b/

0 0:

Example 13.3.2. A negative constant c is a subsolution provided f .t; c/ 0. Similarly, a positive constant c is a supersolution provided f .t; c/ Ä 0.

The following Lemma is a sort of a "maximum principle". Since its interest goes
beyond the topics discussed in this chapter, we prefer to consider a general differential operator LOEx D .p.t/x0/0 r .t/x, where p.t/ > 0 is continuously differentiable and r .t/ 0 is continuous, even if we use the simpler operator x00 mx, m 0, a
constant.

Lemma 13.3.3. If w is such that LOEw 0, w.a/ 0; w.b/ 0, then w.t/ 0 for all t 2 OEa; b.

Proof. Let 1 be the first eigenvalue of LOEx C x D 0, x.a/ D x.b/ D 0 and let 1 be an associated eigenfunction, that can be taken strictly positive in .a; b/. Set w D w C 1. Since > 0 and 1 > 0 in OEa; b, then

LOEwe D LOEw LOE 1 D LOEw C 1 1 > 0; 8 t 2 .a; b/ : (13.10)

Moreover

w .a/ D w.a/ 0; w .b/ D w.b/ 0:

Let t be the point where w .t/ achieves its minimum in OEa; b. If, by contradiction, w.t / < 0, then a < t < b and thus w0.t / D 0. Furthermore, since w0 .t / D 0 we find
LOEw .t / D p0.t /w0 .t / C p.t /w00.t / C r .t /w .t / D p.t /w00.t / C r .t /w .t /:

From (13.10), it follows that
p.t /w00.t / C r .t /w .t / > 0 H) p.t /w00.t / < r .t /w .t /:
Since p.t / > 0; r .t / 0; w .t / < 0, it follows that w00.t / < 0. This is a contradiction to the fact that t is a minimum point of w , proving the theorem.

The next Theorem is a rather general existence result in the presence of ordered sub- and supersolutions.

286 13 Boundary value problems

Theorem 13.3.4. Suppose that f is continuous on OEa; b R and

9 m > 0; such that the function mx C f .t; x/ is increasing for all t 2 OEa; b. (*)

If (13.9) has a subsolution v and a supersolution w such that v.t/ Ä w.t/ for all t 2 OEa; b, then (13.9) has a solution x with v.t/ Ä x.t/ Ä w.t/ for all t 2 OEa; b.

Proof. A solution of x00 C f .t; x/ D 0; x.a/ D x.b/ D 0 will be found by
an iteration procedure that we are going to describe. First of all, setting fm.t; x/ dDef mx Cf .t; x/, the equation x00Cf .t; x/ D 0 is equivalent to x00 mx Cfm.t; x/ D 0.
Let LmOEx dDef x00 mx:

Then the equation can be written in the form

LmOEx C fm.t; x/ D 0:

Notice that Theorem 13.2.2 holds for Lm. In particular, a solution of (13.9) can be found solving the integral equation

x D SOEx;

S OEx.t/

dDef

Z

b
Gm.t; s/fm.s; x.s//ds

a

(13.11)

where Gm denotes the Green function of Lm. Let v1 D v and, for k D 2; 3 : : : ; we let vk be the solution of

LmOEvk D fm.t; vk 1/ D mvk 1 C f .t; vk 1/; vk.a/ D vk.b/ D 0;
which exists and is unique in view of Theorem 13.2.2, with L D Lm and h D fm.t; vk 1/. Using the notation introduced above we can say that

vk D S OEvk 1: By induction, one shows that for all k D 1; 2 : : : one has

v.t/ Ä vk.t/ Ä w.t/; 8 t 2 OEa; b:

(13.12)

Since v1 D v Ä w, (13.12) holds for k D 1. Suppose that (13.12) holds for k and set z D vkC1 v. Then LmOEz D LmOEvkC1 C LmOEv D mvk C f .t; vk/ C LmOEv. Since LOEv Ä f .t; v/ we get LmOEv Ä mv C f .t; v/, and hence

LmOEz mvk C f .t; vk/ mv f .t; v/ D fm.t; vk/ fm.t; v/:

By the inductive assumption, vk v. This and the fact that fm. ; x/ is increasing yield LmOEz 0. Moreover, z.a/ D vkC1.a/ v.a/ 0 because vkC1.a/ D 0 and v.a/ Ä 0. Similarly z.b/ 0. Applying the Maximum Principle, Lemma 13.3.3
(with p Á 1 and r Á m), it follows that z.t/ 0, namely vkC1.t/ v.t/ in OEa; b. In the same way, using the fact that w is a supersolution, one finds LOEw vkC1 0

13.3 Sub- and supersolutions 287

and w.a/ vkC1.a/ 0, w.b/ vkC1.b/ 0 which implies that w.t/ vkC1.t/ in OEa; b. This proves (13.12).
To prove that vk converges, up to a subsequence, uniformly in OEa; b to a continuous function, we use the Ascoli Compactness Theorem which says:

If a sequence of continuous functions fk defined in an interval OEa; b is bounded uniformly with respect to k, and is continuous uniformly with respect to k, then there exists a subsequence converging uniformly in OEa; b to a continuous function.

We have:

.i/ vk are bounded, uniformly with respect to k. From (13.12) it follows that

min v.t/ Ä vk.t/ Ä max w.t/; 8 k:

t 2OEa;b

t 2OEa;b

.ii/ vk are continuous uniformly with respect to k. Let us use vk D S vk 1 to infer

that

Zb

jvk.t / vk.t 0/j Ä

jGm.t; s/ Gm.t0; s/j jfm.s; vk 1.s//jds

aZ b Ä c jGm.t; s/ Gm.t0; s/jds:

a

Since Gm is uniformly continuous in the square Q D OEa; b OEa; b it follows that the sequence vk is continuous uniformly with respect to k. In view of these two properties we can use the Ascoli compactness theorem to infer that, up to a subsequence,
vk.t/ converges to a continuous function x.t/, uniformly in OEa; b. This allows us to pass to the limit in vk D S OEvk 1, yielding x D S OEx, namely
Zb x.t/ D G.t; s/f .s; y.s//ds:
a

Thus, by Corollary 13.2.3, x.t/ solves (13.9).

Remark 13.3.5. Examples show that, in general, the condition v Ä w cannot be eliminated.

The next two theorems are applications of the preceding general result.

Theorem 13.3.6. Let f .t; x/ be continuously differentiable on OEa; b R. Moreover, suppose

9 ;  0 W f .t; / 0; f .t; / Ä 0; 8 t 2 OEa; b:

(13.13)

Then

² x00 D f .t; x/ x.a/ D x.b/ D 0

(13.14)

has a solution x.t/ such that  Ä x.t/ Ä  .

288 13 Boundary value problems

f(.,-)

f(.,x)



x

-

O

f(.,)

Fig. 13.4. Plot of fQ.t; x/

Proof. As mentioned before, v.t/ Á  < 0 is a subsolution and w.t/ Á  > 0 is

a supersolution. To apply Theorem 13.3.4 we should have that f satisfies . /. This

difficulty is overcome by using a truncation, which we are going to discuss. Define a truncated function fQ.t; x/ by setting (see Figure 13.4)

8

< f .t; / if x Ä 

fQ.t ;

x/

D

:

f .t; f .t;

x/ /

if a Ä x Ä  if x :

Lemma 13.3.7. The function x.t/ solves
² x00 D fQ.t; x/ x.a/ D x.b/ D 0

(13.15)

if and only if it solves (13.14).

Proof. Let x be a solution of (13.15) and let ; 0 be such that

x. / D min x.t/;
t 2OEa;b

x. 0/ D max x.t/:
t 2OEa;b

We claim that x. / . Otherwise, if x. / <  Ä 0, then a < < b and fQ. ; x. // D f . ; / > 0, by definition. Thus x00. / D fQ. ; x. // > 0,
which is a contradiction because is the minimum of x. In the same way one proves that x. 0/ Ä . As a consequence, we have that  Ä x.t/ Ä  and hence fQ.t; x.t// D f .t; x.t// so that x solves (13.14). The converse is trivial.

Proof of Theorem 13.3.6 completed. Since fx0.t; x/ is bounded in the rectangle OEa; b OE ; , then the function fQ satisfies . /. Furthermore, since f D fQ for  Ä x Ä , then v D , resp. w D , is a subsolution, resp. a supersolution, not only of

13.4 A nonlinear eigenvalue problem 289 x00 D f .t; x/ but also of x00 D fQ.t; x/. In addition one has that v Ä w. We can now apply Theorem 13.3.4 finding a solution x.t/ such that  Ä x.t/ Ä .
From the preceding Theorem we can deduce:
Theorem 13.3.8. If limx! 1 f .t; x/ > 0 and limx!C1 f .t; x/ < 0, uniformly with respect to t 2 OEa; b, then the problem (13.14) has a solution.
Proof. From the assumptions on the limits, it follows that (13.13) holds.
Corollary 13.3.9. Let f .t; x/ D x C g.t; x/, with g bounded. Then the problem (13.14) has a solution.
Proof. One has limx! 1 f .t; x/ D C1 and limx!C1 f .t; x/ D 1.

13.4 A nonlinear eigenvalue problem

Consider the nonlinear eigenvalue problem ² x00 D x g.t; x/ x.a/ D x.b/ D 0

(13.16)

where is a real parameter and g.t; 0/ Á 0. Problem (13.16) has the trivial solution x Á 0 for all . The existence of a positive solution is established in the following theorem. By a positive solution, resp. sub/supersolution, of (13.16) we mean a solution, resp. sub/supersolution, x.t/ such that x.t/ > 0 for all a < t < b.

Theorem 13.4.1. Let g.t; x/ be continuous on OEa; b R and such that g.t; 0/ D 0 for all t 2 OEa; b. Furthermore, suppose that

g.t; x/

lim

D 0; uniformly w.r.t. t 2 OEa; b

(g1)

x!0 x

g.t; x/

lim

D C1; uniformly w.r.t. t 2 OEa; b:

(g2)

x!C1 x

Then (13.16) has a solution x.t/ > 0 in .a; b/, provided > 1 D b a , where 1 is the first eigenvalue of the linear problem x00 C x D 0, x.a/ D x.b/ D 0.

Proof. Fix > b a . The function f .t; x/ dDef x g.t; x/ is such that f .t; 0/ D 0 and, by (g2), limx!C1 f .t; x/ D 1. It follows that there exists M > 0 such that f .t; M / < 0. Clearly w D M is a supersolution of (13.16). Actually w00 D 0 >

f .t; M / D f .t; w /.

Finding a positive subsolution is slightly more involved. Let 1 > 0 be such that

00 1

C

1

1 D 0,

1.a/ D

1.b/ D 0. Taking

> 0, let us show that v .t/ D

1.t /

290 13 Boundary value problems

is a positive subsolution for > 0 sufficiently small. To prove this, we evaluate

v00 D

00 1

D

1 1 D 1v :

From .g1/ it follows that

g.t ; lim

1.t// D 0;

8 t 2 OEa; b:

!0

1.t /

Then, if

> 1 one infers that there exists 0 > 0 such that

g.t; 1.t// Ä 1.t /

1; 8 0 < < 0; 8 t 2 OEa; b:

Recalling that v D 1, it follows that

g.t; v / Ä . 1/v ; 8 0 < < 0; 8 t 2 OEa; b;

namely 1v Ä v g.t; v /. Furthermore,

1.t/ Ä max 1.t/
t 2OEa;b

and hence, taking > 0, possibly smaller, one has that v .t/ Ä M in OEa; b.

As in the proof of Theorem 13.3.6, we can replace f by a truncated function like

8

< h.x/

fQ

.t ;

x/

D

fQ.t ;

x/

D

:

f f

.t; x/ .t; M

D /

x

g.t; x/

if x Ä 0 if 0 Ä x Ä M if x M

where h.x/ is any smooth function such that h.0/ D 0, h0 is bounded and h.x/ > 0 for x < 0. Of course, fQ satisfies . /. Moreover, from 0 Ä v Ä M it follows that fQ.t; v / D f .t; v /. Thus x00 D fQ.t; x/; x.a/ D x.b/ D 0, possesses a positive super solution M and a positive subsolution v , with v Ä M . According to Theorem 13.3.4, the truncated problem has a solution such that v .t/ Ä x.t/ Ä M in OEa; b. Then f .t; x.t// D fQ.t; x.t// and hence x.t/ solves (13.16). Finally, from x.t/ v .t/ it follows that x.t/ > 0 in .a; b/.

Remark 13.4.2. As in Proposition 13.1.5 or Example 9.2.7, one can show that if < 1 the problem x00 D x x3, x.a/ D x.b/ D 0 has only the trivial solution. This
shows that, in general, the condition < 1 cannot be removed.

13.5 Exercises 291

13.5 Exercises

1. Show that the boundary value problem ² x00 x3 D 0 x.0/ D x.b/ D 0

has only the trivial solution x.t/ Á 0.

2. Let a < b. Prove that the boundary value problem ² x00 C 4x3 D 0 x.a/ D x.b/ D 0

has infinitely many solutions.

3. Show that the boundary value problem ² x00 C 6x5 D 0 x.0/ D x.b/ D 0

has infinitely many solutions.

4. Show that for all k

0 the boundary value problem ² x00 C .2p C 2/x2pC1 D 0 x.0/ D x.b/ D 0

has infinitely many solutions.

5. Show that for < the boundary value problem ² x00 C x x3 D 0 x.0/ D x.1/ D 0

has only the trivial solution.

6. Show that the following boundary value problems

.a/

²

x00 C 4x3 D 0 x.0/ D 0; x.b/ D 1

.b/

²

x00 C 4x3 D 0 x0.0/ D 0; x.b/ D 0

have a positive solution.

7. Prove that the preceding problems (a) and (b) have infinitely many solutions.

8. Find b > 0 such that the boundary value problem ² x00 C 4x3 D 0 x.0/ D 0; x.b/ D 1; x0.b/ D 0

has positive solutions.
9. Find the Green function of LOEx D x00 on OE0; 1 and solve the boundary value problem x00 D 1; x.0/ D x.1/ D 0:

292 13 Boundary value problems
10. Find the Green function of LOEx D x00 on OE 1; 1. 11. Find the Green function of LOEx D x00 k2x on OE0; 1 where k 6D 0. 12. Show that x00 D 1 x x2; x.a/ D x.b/ D 0 has a solution x.t/ such that
0 Ä x.t/ Ä 1. 13. Show that x00 C x D e x; x.a/ D x.b/ D 0 has a solution such that 0 Ä
x.t/ Ä 1. 14. Let g.x/ be continuous and such that g.0/ > 0, g.1/ < 1. Show that x00 C x D
g.x/; x.a/ D x.b/ D 0 has a solution. 15. Show that x00 C x D e x2 ; x.a/ D x.b/ D 0 has a positive solution.
16. Let g.x/ be continuous and such that 0 < g.x/ Ä M for all x. Show that x00 D g.x/ x; x.a/ D x.b/ D 0 has a positive solution.
17. Show that x00 D .1 C x2/ 1=2 x; x.a/ D x.b/ D 0; has a positive solution. 18. Show that x00 C x D min¹ex; 1º; x.a/ D x.b/ D 0; has a positive solution. 19. Prove that x00 D 2x x2; x.0/ D x. / D 0; has a positive solution. 20. Show that if b > , the problem x00 D arctan x; x.0/ D x.b/ D 0; has a
positive solution.

Appendix A Numerical methods

Many differential equations cannot be solved analytically; however, sometimes a numerical approximation to the solution is sufficient to serve one's need. Here we discuss some elementary algorithms that may be used to compute such approximations.
Let us consider the problem of approximating a solution to the initial problem

x0 D f .t; x/; x.t0/ D x0:

(A.1)

The unknown x D x.t/ could be a vector valued function so that (A.1) would be a system of first order ODEs. However, we will restrict ourselves to the scalar case in this text. With respect to (A.1), we assume that a unique solution exists, but that analytical attempts to construct it have failed.
In the Figure A.1, the blue curve is the graph of x.t/ and we want to find some approximation points connecting by red segments.

x

x0

t0

t

Fig. A.1. Exact solution curve (blue) and its approximation (red)
© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3_A

294 Appendix A Numerical methods
In this chapter, we will discuss a very elementary method; namely, Euler's method and its improved version as well as a bit more advanced method ­ Runge­Kutta's method.

A.1 First order approximation: Euler's method

The basic idea is as follows: As we know,

x0.t/ D lim x.t C h/

x .t / :

h!0

h

For sufficiently small h the above suggests that

x0.t /

x.t C h/ x.t/ ;

h

and we can approximate x.t C h/ by x.t C h/ x.t/ C hx0.t/. But as x.t/ satisfies the equation (A.1), x0.t/ D f .t; x.t//, we then have

x.t C h/ x.t/ C hf .t; x.t//:

Now, assume that we are already `happy' with some approximate value X for x.t/, then the above would be a natural (and naive) approximation for x.t C h/:

XN D X C hf .t; X/:

(A.2)

Repeating the process, we then come up with the following procedure (Euler's method).
a. Set X0 D x0 and pick a positive step size h > 0. b. For each integer i D 0; 1; 2; : : :, define

XiC1 D Xi C hf .ti ; Xi /; tiC1 D ti C h:

(A.3)

Since a computer cannot calculate indefinitely, we can only approximate the solution x.t/ of (A.1) in a finite interval OEt0; t0 C L of length L > 0, which is determined by the physics of the phenomenon under consideration. Suppose that we want to have n approximation points x1; : : : ; xn, then the step size h is given by L=n. See Figure A.2.
A generic algorithm for the Euler method is given by:

Step 1. Step 2. Step 3. Step 4. Step 5. Step 6.

Set the number n of points we wish to compute. Set the time step size h D L=n. Set X D x0 and t D t0. Set a counter k D 1. Compute B D X and C D hf .t; X/. Compute xk D B C C .

X1 x(t0+h)
X0

A.1 First order approximation: Euler's method 295
x(t)

t0

t +h
0

t

Fig. A.2. First approximation point: given a sufficiently small h > 0, we can start with the initial point X0 D x0 and t0, dictated by the initial condition in (A.1), to construct the first approximation value X1 D X0 C hf .t0; X0/ for the true value x.t0 C h/
Step 7. Set X D xk and t D t C h. Step 8. Increase the counter k by 1. Step 9. If k < n then repeat steps 5­8. Otherwise, stop.
The following simple Maple code can be used to realize the above algorithm:
x WD x0I t WD t0I XOE0 WD Initial value for i from 1 by 1 to N do Loop to compute xi x WD x C h f .t; x/I t WD t C hI Compute the new value and time XOEi  WD xI Record the value end do;
Let us apply the above algorithm to approximate the solution to
x0 D x2 C t 2; x.0/ D 1:
If we want to approximate the solution in the interval OE0; 0:8 by 8 points, then the step size h D 0:8=8 D 0:1 and the Euler algorithm gives rise to the following Table A.1.
In Figure A.3 these values are plotted against the graph of the solution. Note that in all the following figures the scale for the t and x axes is based on a ratio of 1 to 10.
A.1.1 Improved Euler's method
In the standard Euler method, we advance along the tangent of the solution curve to obtain the next point, a predicted one. We can possibly improve this by correcting

296 Appendix A Numerical methods

Table A.1. Euler method for x0 D x2 C t 2; x.0/ D 1. Step size h D 0:1

k

tk

Xk

XkC1 D Xk C h.Xk2 C tk2/

0

0

1

1 0.1

1.1

2 0.2

1.222

3 0.3

1.3753284

4 0.4 1.573481221

5 0.5 1.837065536

6 0.6 2.199546514

7 0.7 2.719347001

8 0.8 3.507831812

1.1 1.222 1.3753284 1.573481221 1.837065536 2.199546514 2.719347001 3.507831812 STOP

Fig. A.3. Approximation values against solution

the predicted. To this end, we can first compute the predicted value as before (see

(A.2))

xkC1 D xk C hf .tk ; xk/;

(A.4)

then correct it by

xkC1

D

xk

C

f h

.tk ;

xk /

C

f .tkC1; 2

xkC1/ :

(A.5)

This simply means that we advance along the line between the tangents at the previous point .tk ; xk/ and the predicted point by Euler's method in order to obtain the

A.1 First order approximation: Euler's method 297

Fig. A.4. Plotting these values against the graph of the solution and the previous result obtained from the Euler method, we can see a great improvement

next point. See Figure A.4. In some cases, this seems to be a better approximation as we will see by applying this improved version to the previous example.
We apply the formulas (A.4) and (A.5) to obtain Table A.2. An important note should be made here before we move on to the next section discussing more advanced numerical methods. There is no doubt that powerful computers can assist us to do tedious computation and, in many cases, provide almost what we practically need in applications. However, computers don't think! Yet efficiently

Table A.2. Improved Euler method for x0 D x2 C t 2; x.0/ D 1. Step size h D 0:1. Here, f .t; x/ D x2 C t 2

k tk

Xk

XkC1 D Xk C hf .Xk; tk/

XkC1

D

Xk

C

h

f

.Xk;tk

/Cf .XkC1;tkC1 2

/

00

1

1 0.1 1.111000000

2 0.2 1.251530674

3 0.3 1.436057424

4 0.4 1.688007333

5 0.5 2.048770724

6 0.6 2.600025118

7 0.7 3.529011494

8 0.8 5.371468766

1.1 1.235432100 1.412163577 1.651283516 1.988944209 2.493516872 3.312038179 4.823403706
STOP

1.111000000 1.251530674 1.436057424 1.688007333 2.048770724 2.600025118 3.529011494 5.371468766
STOP

298 Appendix A Numerical methods
but they simply do whatever we ask them to do. Therefore we cannot completely (and blindly) trust their output. A qualitative analysis needs to be done first before we can rely on any numerical method to do the messy and cumbersome job. The following simple example will be a good warning.
Let us consider the initial value problem
x0.t/ D x2 C 1; x.0/ D 1;
which can be solved easily by separating the variables, and we get Á
x.t/ D tan t C : 4
Obviously, the solution is only defined on the interval OE0; 4 / as we need t C 4 < 2 . However, computers do not know this if we ask them to perform the discussed Euler methods on this problem. They would go on and compute `values' of x.t/ for t beyond 4 !
Furthermore, the Euler method is often not accurate enough. In more precise terms, it only has order one. This caused us to look for higher-order methods. One possibility is to use not only the previously computed value xk to determine xkC1, but to make the solution depend more on past values. This yields the so-called multistage methods. We will discuss one such method, the Runge­Kutta, in the next section.

A.2 The Runge­Kutta method

We now study a more advanced and accurate Runge­Kutta method to approximate a solution to the initial problem (A.1), namely

x0 D f .t; x/; x.t0/ D x0:

In the Euler method, the next value xkC1 is computed by the previous xk advancing along the approximated tangent. The Runge­Kutta method computes the next

value xkC1 via multiple stages in order to obtain better approximations. To this end, xkC1 will be xk plus a weighted average of a number s of increments (the number s is fixed and called the number of stages). Each increment is just a product of the step

size h and an estimated slope of the solution curve specified by the right-hand side

f .t; x/ in the equation (A.1).

For example, let us consider the 2-stage method given by the formula

Â

Ã

xkC1

D

xk C h

1 2 f .tk;

xk /

C

1 f
2

.tk

C

h;

xk

C

hf

.tk ;

xk//

D

xk

C

1 2 I1

C

1 2 I2:

(A.6)

One can see that xkC1 is obtained by advancing xk by the average of 2 increments I1; I2:

A.2 The Runge­Kutta method 299

1. I1 D hf .tk; xk/ is the increment based on the slope at the beginning of the interval, using the Euler method.
2. I2 D hf .tk C h; xk C hf .tk; xk// is the increment based on the slope at the end of the interval, using xk C hf .tk ; xk/.
A keen reader will notice that this method is just the improved Euler method discussed earlier!
Generalizing (A.6), we can take any number  2 .0; 1 and define

Â xkC1 D xk C 1

Ã

1

1

2 I1 C 2 I2;

(A.7)

where:

1. I1 D hf .tk; xk/ is the increment based on the slope at the beginning of the inter-

val. This increment is given the weight 1

1 2

.

2. I2 D hf .tk C h; xk C I1/ is the increment based on the slope at the point

tk C h of the interval, using xk C I1 D xk C hf .tk; xk/.

The reader can easily check that (A.6) is a special case of this generalization when  D 1. If one takes  D 1=2 then (A.7) results in the so-called midpoint method

1

1

xkC1

D

xk

C

hf

.tk

C

h; 2

xk

C

hf 2

.tk ;

xk//;

which looks similar to the formula in Euler's method but using the slope at midpoint of the interval.
Let us move on to another member of the family of Runge­Kutta methods which is so commonly used that it is often referred to as "RK4", "classical Runge­Kutta method" or simply as "the Runge­Kutta method".
The formula is as follows

1111 xkC1 D xk C 6 I1 C 3 I2 C 3 I3 C 6 I4:

(A.8)

Here, there are 4 increments (4 stages) and their weights are given by:

1. I1 D hf .tk; xk/ is the increment based on the slope at the beginning of the inter-

val.

This

increment

is

given

the

weight

1 6

.

2.

I2

D hf .tk

C

1 2

h;

xk

C

1 2

I1/

is

the

increment

based

on

the

slope

at

the

midpoint

tk

C

1 2

h

of

the

interval,

using

xk

C

1 2

I1

.

Its

weight

is

1 3

.

3.

I3

D hf .tk

C

1 2

h;

xk

C

1 2

I2/

is

the

increment

based

on

the

slope

at

the

midpoint

tk

C

1 2

h

of

the

interval,

but

now

using

xk

C

1 2

I2

.

Its

weight

is

still

1 3

.

4. I4 D hf .tk C h; xk C I3/ is the increment based on the slope at the end of the

interval,

using

xk

C

I3 .

Its

weight

is

1 6

.

300 Appendix A Numerical methods

We now describe the general s-stages method. We fix an integer s 1 and define
Xs xkC1 D xk C wi Ii ;
i D1
where wi 2 OE0; 1 are the weights whose sum must be 1. The increments I1; : : : ; Is are given by

I1 D hf tk; .xk/ I2 D hf .tk C c2h:xk C a21I1/ I3 D hf .tk C c3h; xk C a31I1 C a32I2/ :::
Is D hf .tk C csh; xk C as1I1 C as2I2 C

C as;s 1 Is 1 /:

We can see that, for m D 1; : : : ; s, Im is the increment based on the slope at tk C cmh and using xk advancing by a weighted sum of previous increments I1; : : : ; Im 1:

Im D hf .tk C cmh; xk C am1I1 C am2I2 C C am;m 1Im 1/;

which is the approximated slope at the time tk C cmh. It is then natural to require that the increments in x satisfy

am1 C am2 C C am;m 1 D cm:

In such a case, we say that the method is consistent. It is clear that the Runge­Kutta is much more complicated than the primitive Eu-
ler method and it is not practical to perform the calculation on a handheld calculator without programming ability. If the reader has some knowledge in programming then the following Maple programming code can be used to generate the approximation values in the general Runge­Kutta method.

RKgenVal WD proc.A; c; W; f; t0; x0; h; N; S/ local x; t; X; i; j; k; IN C; I ncI x WD x0I t WD t0I XOE0 WD xI Initial value for i from 1 by 1 to N do Compute the increments for j from 1 by 1 to S do IN C WD 0I for k from 1 by 1 to j 1 do IN C WD IN C C AOEj; k I ncOEk end do I I ncOEj  WD h f .t C cOE1; j  h; x C IN C / end do I IN C WD 0I

A.2 The Runge­Kutta method 301

for k from 1 by 1 to S do Weighted total increment IN C WD IN C C W OE1; k I ncOEkI
end do; x WD x C IN C I t WD t C hI XOEi  WD xI Record the new value end do; XI end proc

The above procedure requires the following inputs:

1. A matrix A holding the weights aij

2

00

A D 4666666666

a21 a31
:::

0 a32
:::

0 :::

3

0

0 :::

0 0
0

7777775777 :

aa1 as2

as;s 1 0

2. A vector c holding the time weights ci .
3. A vector W holding the increment weights wi .
4. The right-hand side f WD f .t; x/, the initial time t0, the initial condition x0 D x.t0/, the step size h, number of points to compute N and the number of stages S.

For example, the matrices for a 2-stage method can be

"

#

00

A WD

2 3

0

;

c WD

0

2 3

;

W WD

1 4

3 4

:

While for the classic RK4, we use

2

3

0 000

A WD 466666

1 2
0

0
1 2

0 0

0 0

757777 ;

c WD

0

1 2

1 2

1

;

W WD

1 6

1 3

1 3

1 6

:

0 010

Let us apply the above two methods with such parameters and revisit the example x0 D x2 C 1; x.0/ D 1:

302 Appendix A Numerical methods

Table A.3. approximation points

k 2-stages

Errors

4-stages

Errors

1 1.221333333 0.001715548 1.223048914 0.0000000330 2 1.502999707 0.005497940 1.508496167 0.000001480 3 1.881423779 0.014341347 1.895754160 0.000010966 4 2.427681154 0.037281607 2.464899687 0.000063074 5 3.300240967 0.107982483 3.407820425 0.000403025 6 4.928987792 0.402867449 5.327896817 0.003958424

We will use the step size h D 0:1 to compute m D 6 approximation points. The result is recorded in Table A.3.
We can see that the 4-stage method provides much smaller errors. Plotting the approximation points obtained by the two methods against the true solution x.t/ D tan.t C 4 /, we can see that the 4-stage points in Figure A.5b are much closer to the graph of the true solution.

(a)

(b)

Fig. A.5. The plots of the solution x.t / D tan.t C 4 / and approximation points. (a) 2-stages; (b) 4-stages

Answers to selected exercises

Chapter 1

1. x0 D 5x. 3. x D c e 4t C 1:

4. Use the uniqueness property.

6. k D ln 2.

7. Find the solution and then use the Intermediate Value Theorem.

8. (a) . 1; 1/, (b) . =2; 1/.

9.

x

D

2 3

t

2

C

c t

;

t

¤ 0.

11. x D 4et2.

12. x D c e t3=3.

13.

x

D

b a

t

1 a

C Ce at .

h 17. .
k

18. (a) k=1/2, (b) No!

19. e =2.

22. (a) q.t/ D 7t C 2, (b) q.t/ D t2 C 3.

26. Recall that solutions of such equations do not change sign.

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3

304 Answers to selected exercises 28. x D 3t. 29. x D at: if a > 0 minima, if a < 0 maxima.

Chapter 2
2. Suppose jjxjp jyjpj Ä Ljx yj and let y D 0. 4. All a ¤ 0. 6. Check the conditions for existence and uniqueness for x0 D ln x (x > 0). 9. Note that jxj1=4 is lipschitzian off x > 0. 12. Verify that f .x/ D sin x satisfies the conditions of the Global Existence Theo-
rem. 14. Verify that f .x/ D ln.1 C x2/ satisfies the conditions of the Global Existence
Theorem. 15. The function f .x/ D max¹1; xº is globally lipschitzian. 17. Use uniqueness to show that if z.t/ D x. t/ , then x.t/ D z.t/. 18. Solutions are either increasing or decreasing. 19. Solutions are increasing. 20. Show that if it changed sign, it would violate uniqueness. 24. Show that if x0.t / D 0 then x00.t / > 0. 26. Show that 0.a/ D 0 and 00.a/ < 0. 28. Show that 0.0/ D 00.0/ D 0 and 000.0/ < 0. 30. Solve y0 D 1 C 2t, y.0/ D 0 and use the Comparison Theorem.

Chapter 3

2.

x

D

1 e2t 1Ce2t

.

p

4. x D

1C

1C8et 2

.

6. x D 3.t 4 C c/ 1=3 :

7.

x

D

t

2

2 2c

;

t

D6

p  2c:

p 9. x D t2 1, t 1.

11.

x

D

2t

6 3 C1

;

t

>

1 2

1=3 :

13.

xD

1 2

t

4

C1

2:

14.

xD

1 4

t2

1 4

a2

2

and x

D

0.

15. p C 1 > 0.

Chapter 3 305

16. The limit is a constant, which depends on the initial conditions. (a), c D 0: (b)

1=2.

18.

2 3

x

3

C

x

Á

y6 6

y D c:

21.

axpC1 pC1

C bxy C

dyqC1 qC1

D c:

24. ex C ey

1 2

xy2

D

c.

26. x3 C 3x2y 3xy2 C y3 D c:

27. x3 C 3x2y C 6xy2 C 5y3 D c: a is the unique negative solution of 1 C 3a C 6a2 C 5a3 D 0.

30. a1 D 2, b1 D 2a2; x3 C 3x2y C 3a2xy2 C b2y3 D c.

31. A.y/ D y2 C Ä, Ä constant; x2 C Äx C xy2 D c:

33.

satisfies

0.y/

D

y

f 0.y f .y/

/

:

36.

1 3

x

3

1 2

x2

C

y.x

1/2 D c.

38. Show that an integrating factor is .y/ D p 1 :
1Cy2

40. x D 0 or

t2 2x2

C

ln



x t



D

ln



1 t



C

c;

t 6D 0:

42. t

x2 t

D

c.

43.

1 2

.x

t/2 C 2x

t D c.

44. 2.x C t/ C ln j2.x t/ C 1j D c.

47. x D  p 1 :
ce2t2 2
48. x D z 1, with z D e t2=2

R

et2=2dt

C

Á c

306 Answers to selected exercises

49.

² x02 Solve 2x0

D x2 C t2 D 0:

1

50.

x

D

1 4

t

2

.

52. x D ct

c2. The

singular solution is

x

D

t2 4

:

53. x D ct C ec. The singular solution is x D t ln. t/

t; t < 0:

54. x D ct ln c, c > 0: The singular solution is x D 1 C ln t; t > 0:

56.  D h./ and  D g./.

Chapter 4

1. The function xjxj has a continuous first derivative.

2. The function max¹0; xjxjº has a continuous first derivative.

4.

Show

that

d dt

.x

2

C

y2/

D

0:

6.

Show that

dH .x;y / dt

D

0.

7. x00 D x.

11. Set z.t/ D x.t C T / and use the uniqueness of the ivp.

12. Set z.t/ D x. t/ and use uniqueness.

13. x00.t/ is increasing.

Chapter 5

A2. b) W . 2 / D ¤ 0, c) Use Abel's Theorem.

p

A5. W . 4 / D

2 2

¤

0:

A6. f .t/ D .t2 C 1/.arctan t C 1/:

A7 W .zx1; zx2/ D z2W .x1; x2/:

A10. x1 and x2 are linearly dependent.

A11. W .7/ D 6.

Chapter 5 307

B2. x D c1e t sin t C c2e t cos t.

B3. x D c1e 4t C c2te 4t .

B5. x D et 1 C e2t 2.

p

B6.

x D p2 e t sin
6

6 2

t

.

B8. One root of the characteristic equation is positive (if  > 0) or null (if  D 0).

B9.  < 0.

B11. Use the uniqueness of the ivp.

B15. a D

1 2

.

B17. a2 < b.

B18. D k, k D 1; 2; ::: .

B19. a b D k , k D 1; 2; ::: . B24. x D a ae 2t .

C2.

x D c1e2t C c2e 2t

t2

1 2

.

C4. x D c1 sin t C c2 cos t C 3t2 C t 6.

C6. x D c1et C c2e t C e2t .

p

p

C8.

x

D

c1

e

.

3C 2

13 /t

C

c2e. 3

2 13 /t

t2 C 5t

17:

C10. x D c1e t C c2e2t

t

C

1 2

1 2

et

.

C12. x D c1 sin t C c2 cos t C

1 3

sin

2t

C

1 8

cos

3t .

C14. x D c1 sin 2t C c2 cos 2t

1 3

t

sin

2t

4 9

cos

2t

.

C16.

x D c1et C c2e

t

C

1 k2

ekt; 1

x D c1et C c2e

t C 1tet; 2

x D c1et C c2e t

1 t et ; 2

.k ¤ 1/ .k D 1/ .k D 1/

C18. x D c1et C c2e2t

3t

C

3 2

t

2

et.

308 Answers to selected exercises

C20.

x

D

c1

p sin 2

t

C

c2

cos

p 2

t

C

pt 22

p sin 2

t.

C22. x D c1 sin t C c2 cos t t cos t C t sin t.

C24.

x

D

e e2

1 .et

e t/

t.

C26. Multiply the equation by x and integrate in OEa; b.

D1. Compare with x00 C x D 0.

D2. The first equation. D3. Show that x.0/ D x0.0/ D 0.

D4. Use the general solution of the nonhomogeneous equation to show that one can choose the constants to find the desired solution.

D8. .a/ evaluate the derivative and use the equations, .b/ by contradiction, using (a).

D9.

Set

D

v.t u.t

/ /

;

t

2 .a; a C

/ and show that

0 > 0.

D11.

x

D

t t C1

:

D13.

x

D

0

and

jx .t /j

D

j

ec2 cos.t Cc1/j

:

D14. .a/ x D e1 et , .b/ ln jx.t/j D 1 C 2t et .

D16. Distinguish between a < 1 or a > 5, 1 < a < 5 and a D 1 or a D 5.

D19.

x

D

c1t

C

c2 t3

C

1 5

t2

:

D20. P .t/ D 3a3 t C a3 t3.

Chapter 6

2. x D c1 C c2e t C c3et .

5. x D c1e t C c2e2t C c3te2t .

6.

x

D

3 2

1 2

sin

2t

1 2

cos

2t:

7. x D e t .

Chapter 7 309

9.

x

D

1 5

e

t

et

2 5

sin

t

C

1 5

cos

t

:

10. The characteristic equation has at least one negative zero.

11. Check the max and min of the characteristic equation.

13.

x

D

1 4

e

t

C

1 4

e

t

C

1 2

cos t:

15.

x

D

e a

bt
b

e a

at
b

, where

a; b

(a

¤

b) are the two positive roots of m4

4m2 C

1 D 0.

16. The characteristic equation has only positive solutions.

18. x D c1 C c2et C c3e t C c4 sin t C c5 cos t .

20. The characteristic equation has the negative root m D 1.

21. x D c1 C c2t C c3et C c4e t C c5 sin t C c6 cos t .

23.

x D c1 C c2t C c3e

t C c4e

2t

C

1 6

et

.

24. Using the method of Variation of Parameters one finds x D c1 C c2 sin 2t C

c3

cos

2t

C

1 8

ln

j

sec

2t

C

tan

2tj

1 8

ln

j

cos

2tj

sin

2t

1 4

t

cos

2

t

:

26.

xD

1

C

1 2

et

C

1 2

e

t

1 2

t

2

.

28. Find a proper subset of linearly dependent functions.

30. Show that W .t2; t2/ D 0 and explain why this implies

W .t; t2; t 3; sin t; cos t; t4; et ; e t ; t 4 t 2/ D 0:

31. W .6/ D 5e18.

32. Use Abel's Theorem.

33.

x

D

c1 t

C

c2

sin.ln t/

C

c3 cos.ln t/;

t

>

0:

Chapter 7

A1.

Â

x y

ÃÂ D

c1et c2e 3t

Ã .

A3.

x

Â D

c1eat C c2teat c2eat

Ã :

310 Answers to selected exercises

A5. x D e2t .c1 cos t C c2 sin t/; y D e2t . c1 sin t C c2 cos t/:

ÂÃ

ÂÃ

A7.

xD

1 0

et

0 1

et :

Â

Ã

A8.

xD

a cos 2t a sin 2t

:

A10. A11. B3.

x D c1e3t

1 3

t

1 3

;

y D c2e t C 2t

2:

x D c1et t2 2t 2; y D c2et 1.

D 1;

1,

x.t /

D

Â 2c2e t c1et 3c2e

Ã t:

B5.

x D 3c1 C 2c2e5t C 2et ; y D c1 C c2e5t

1 2

e

t

:

B6.

Â xD

e

t C 3e 3e3t

3t

Ã

:

B7.

x D c1et C c2e3t

2 27

2 9

t

C

2 3

t

2

;

y D c2e3t

2 27

2 9

t

1 3

t

2

:

B8. x D c1e2t C c2e3t ;

y D c1e2t :

B11. x D 3c1e2t C c2e 2t ;

y D c1e2t c2e 2t :

0 1 01

01

01

x

2

0

0

C2. @ y A D c1 @ 1 A et C c2 @ 1 A e t C c3 @ 0 A e2t:

z

4

0

1

C4.

0 xD@

1 3

e4t

C

2 3

e

t

0

1 A.

e4t

C7.

01 x
@y AD

0 1@
2

1 01

0

1

1

1

AC

1 3

@

0

A et

C

1 2

@

11

3
1

Ae

2t .

z

1

0

1

C8. a < 0.

C10. 0 < a < 2.

D2.

x

D

3 2

t

2

C

R

y.t /d t ;

yDe

1 2

t

2

c1

C

R 3

Á

t

2

e

1 2

t

2

d

t

.

D4. x D c1t C c2t 2, y D c1t 2 2c2t 1 1.

D6.

x D c1t

ec1; y D t

1 2

c1t

2

C

c2

as well as x D t ln t

t C c10 ;

yDt

1 2

t

2

ln t

C

1 4

t

2

C

c20 .

Chapter 8

Chapter 9 311

2. a D 7; b D 1.

3.  D .

6.

C

<

1 2

.

8. B2 9 < 0.

9.

Solutions

satisfy

x2

C

xy

C

1 2

y

2

D

1

which

is

an

ellipse.

10. Solutions satisfy x2 C xy 3y2 D 1 which is a hyperbola.

13.

x

D

1C 4

;

y

D

2 7

:

14. The solutions satisfy H.x; y/ D x C 2y ln x 2 ln y D k, x; y > 0; then take k D 4.

16. The nontrivial equilibrium of the system is x D 5; y D 3. 18. x0 satisfies x0000 D x00 3x02x00 . 20 Use the phase plane analysis.

21. x.t/ > 0, it is increasing for t > 0, decreasing for t < 0 and limt!1 x.t/ D C1:

23.

The solution verifies y2

x2

C

1 2

x4

D

1,

which

is

a

compact

curve

that

does

not contain equilibria.

p 26. The solution is y D  a2 x2 2x8:

29. The solution satisfies y2 x2 C 2x3 D 0 .

31. The solution satisfies y2 x2 C 2x3 D 1.

Chapter 9

2.

k

D

 k2 b2

2
,k

D

1; 2; : : : .

3.

k2 2 2

Ä

kOE1 C t Ä k2

2:

4.

2
4e

Ä

kOEet  Ä

2
4:

5. Use the variational characterization of the first eigenvalue.

312 Answers to selected exercises

7.

 M.b

2
a/2

Ä

1Ä

 m.b

2
a/2

:

10. k D k2, with k D 0; 1; 2::: . Notice that the eigenfunctions corresponding to D 0 are constants.

12. Multiply the equation by 'k and integrate. 14. u.t; x/ D e t sin x. 15. u.t; x/ D e c2t sin x:

16.

u.t; x/ D e

2 L2

t

sin

x L

.

Chapter 10

X tk

1. x D a1

: kS.k 1/S

k1

2. a1 D 0, ak D 0 for all k 3. Hence x.t/ D a0 C a2t2.

X

t 3nC1

3. x D t C .3n C 1/3n.3n 2/.3n 3/ 4 3

n1

C

t2 2

C

X

.3n

C

2/.3n

C

t 3nC2 1/.3n 1/.3n

2/

: 542

n1

4.

X xD .

1/n

t 2n

.

.2n/SS

n0

5. The roots of the indicial equation are r D 1=2. If r D 1=2, ak D 0, for all k 1 and x1.t/ D ct1=2. If r D 1=2, ak D 0 for all k 2 and x.t / D t 1=2.a0 C a1t /.

7. The indicial equation has a double root r D 2 yielding

x D a0t 2 X 22 t k k2 :

8. x D .4 1/A1e 1t C .4 2/A2e 2t , y D A1e 1t C A2e 2t , where

1;2 D

1



p 8

and

Ai

D

2

i i

2 C 2.

9. xa.t/ D aJ0.t/.

Chapter 11 313

11. x.t/ D c1Jm.t/. 14. Differentiating the series term by term, show that J10 ./ D J1./.

18. Use the fact that between two consecutive zeros of J1 there is a zero of J0 to

infer

that

J1 .1 /

>

0.

Moreover, J2.1/

D

2 

1J1

.1

/

>

0.

20.

nD

n 2

Á2

where

J1.n/

D

0,

n

>

0;

yn.s/

D

p 2c

p n sJ1 .2

ns/.

21. D 1.

Chapter 11

2!s

!2 C s2

3. .s2 !2/2 , .s2 !2/2 .

!

s

4. .s /2 C !2 , .s /2 C !2 .

5.

1

e s

s C2e

3s e s

4s
.

6.

1 s2

s

1 1

:

X C1

ZT

8. Show that L¹f º D e nT s

e s f . /d :

0

0

9.

s s.1

e e

s
2s/ .

10.

1 s2

T s.1

e e

sT sT

/

:

14. e t sin t; e t cos t.

16. Use Theorem 11.3.7 with P .s/ D s 2 and Q.s/ D s3 s.

18. i C 1 C e t :

19. Show that F 0.s/ < 0 and F 00.s/ > 0.

20. Apply .P 4/ with g0.t/ D f .t/.

23. Use .P 4/ to find .1 C s2/X0.s/ C sX.s/ D 0:

24. x D sinh t.

314 Answers to selected exercises

25. x D t 1.

27.

L¹xº

D

1 3s

C

1 6.s 3/

1 2.s

1/

.

29.

x

D

Rt
0

et

²

Â Ha.Â /dÂ D

0 1 C et

a

if t if t

<a a

.

31. x D .k C a/et . Remark that this solves x00 x D 0 with the initial condition x.0/ D k C a.

32. x.t/ D sin t g.t/: If g.t/ D OE0;1.t/,

²

x.t/ D

1 cos t cos.t 1/

if t 2 OE0; 1 cos t; if t > 1:

²

33.

x D 1 C Ha.t/.t

a/ D

1 1Ct

if 0 Ä t < a a if t a:

Á

35.

xD6

t5 5S

C

t3 3S

D

t5 20

C t3:

36.

x.t / D p1

p sinh. k t/:

k

37.

x .t /

D

cos

k

t

C

sin k k

t

:

38.

x

D

15 8

e7t

e

t

,

y

D

1 8

3e

t C 5e7t

:

40.

x

D

1 2

.e

t

e t /;

y D e t:

Chapter 12
p 1. The eigenvalues of the coefficient matrix are D 3  8.
p 3. The eigenvalues of the coefficient matrix are D i 2.
4. If a < 0, unstable; if a > 0, asymptotically stable; if a D 0, stable, but not asymptotically stable.
6. Unstable.
10. If a < 0, the equilibrium is asymptotically stable. If a > 0 the equilibrium is unstable.
11. Show that at least one eigenvalue of the coefficient matrix is greater than 1.

Chapter 13 315

12. a < 1.

13. Unstable.

15. Unstable. 18. The solutions of 4 C 8 3 C 23 2 C 28 C 12 D 0 are D 1; 2; 2; 3.

19. Write the equivalent first order system and show that one eigenvalue of the coefficients matrix is positive.

21. x D 0 is asymptotically stable for < 0 and unstable for > 0.

24. The stable manifold is x3 D 0: the unstable manifold is the x3 axis.

25. The eigenvalues of the linearized system are 1; 2.

26. V .x; y/ > 0 and VP < 0 for all .x; y/ 6D .0; 0/.

28.

Apply

the

Instability

Theorem

with

W .x; y/

D

1 2

.x2

C

y2/.

29. The eigenvalues of the coefficient matrix of the linearized system are

p

D

1

1

4a :

2

30. Change variable ex D x C a and show that ex D 0; y D 0 is unstable for the corresponding system.

31. The potential F .x; y/ D .x2 C y2/2 has a strict minimum at .0; 0/.

32.

Show

that

V .x; y/

D

1 2

y2

C

Rx
0

g.s/ds

is

a

Liapunov

function.

Chapter 13

1. Multiply x00 D x3 by x and integrate.

3.

Letting ^.c/

Dc

1=3

R1
0

pdy ,
1 y6

show

that

the

equation

^.c/

D

pb 2k

has

infinitely many solutions ck.

5.

D is the first eigenvalue of the linearized problem x00 C x D 0; x.0/ D

x.1/ D 0.

6.

(a)

In

the

phase

plane

take

the

arc

c

of

equation

1 2

y2

C

x4

D

c

in

the

first

quadrant between x D 0 and x D 1.

(b) Consider the arc bc in the fourth quadrant.

316 Answers to selected exercises

8.

b

D

p1 2

R1
0

p dx .
1 x4

²

9.

G.t; s/ D

t .1 s.1

s/; t /;

if t if t

2 2

OE0; s OEs; 1

;

x .t /

D

1 2

t

2

1 2

t

.

8 <

1 k sinh.k/

sinh.k t /

sinhOEk.s

1/;

11.

G.t; s/ D : 1
k sinh.k/

sinh.ks/

sinhOEk.t

1/;

if t 2 OE0; s if t 2 OEs; 1

12. v Á 0 is a subsolution and w Á 1 is a supersolution.

14. v Á 0 is a subsolution and w Á 1 is a supersolution.

16. v D 0 is a subsolution and w D M is a supersolution. Positiveness follows by contradiction.

18. 0 < min¹ex; 1º Ä 1.

20. Write arctan x D x g.x/ with g.x/ D x arctan x and apply Theorem 13.4.1 of Chapter 13 with D 1.

References
1. Amann, H.: Ordinary Differential Equations: An Introduction to Nonlinear Analysis, De Gruyter, Berlin (1990)
2. Anton, H., Rorres, C.: Elementary Linear Algebra with Applications, Wiley, Chichester (2005)
3. Arnold, V.: Ordinary Differential Equations, Springer-Verlag, Berlin Heidelberg (1992)
4. Boyce, W.E., DiPrima, R.C.: Elementary Differential Equations and Boundary Value Problems, Wiley, Chichester (2009)
5. Braun, M.: Differential Equations and Their Applications, Springer-Verlag, New York (1975)
6. Campbell, S.L.: An Introduction to Differential Equations and Their Applications. Wadsworth, Belmont (1990)
7. Coddington, E.A.: An Introduction to Ordinary Differential Equations. PrenticeHall, New Jersey (1961)
8. Coddington, E.A., Levinson, N.: Theory of Ordinary Differential Equations. McGraw-Hill, London (1955)
9. Driver, R.D.: Introduction to Ordinary Differential Equations. Harper & Row, New York (1978)
10. Etgen, G.J. , Morris, W.L.: An Introduction to Ordinary Differential Equations. Harper & Row, New York (1977)
11. Hale, J.K.: Ordinary Differential Equations. Wiley-Interscience, New York (1969)
12. Ince, E.L.: Ordinary Differential Equations. Dover Publ. Inc., New York (1956) 13. La Salle, J., Lefschetz, S.: Stability by Lyapunov's direct method with appli-
cations. Acad. Press, New York (1961)
© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3

318 Selected Bibliography
14. Leighton, W.: An Introduction to the Theory of Ordinary Differential Equations. Wadsworth, Inc. Bellmont, California (1976)
12. Marsden, J., Weinstein, A.: Calculus I, II, III. Springer-Verlag, New York (1985) 13. Pontriaguine, L.: Equations Differentielles Ordinaires. MIR, Moscow (1975) 14. Redheffer, R., Redheffer, R.M.: Differential equations ­ Theory and Applica-
tions. Jones and Bartlett, Boston (1991) 15. Shields, P.C.: Elementary Linear Algebra, Worth, Inc., New York (1970) 16. Stecher, M.: Linear Algebra, Harper & Row, New York (1988)

Index

Abel's Theorem, 85, 126 absolutely convergent, 200 analytic function, 200 Ascoli Compactness Theorem, 24, 287 asymptotical stability, 252 autonomous, system, 71 auxiliary equation, 141
Bessel ­ equation, 211 ­ equation of order 1, 216 ­ function of order 0, of the first kind, 214 ­ function of order 0, of the second kind,
215 ­ function of order 1, of the first kind, 217 ­ function of order 1, of the second kind,
218 boundary value problems, 118
Cauchy problem, 17 center, 259 characteristic ­ equation, 94, 128, 141 ­ equation of higher order equations, 128 ­ exponents, 210 ­ polynomial of a matrix, 141 cofactor, 137 conservative systems, 168 constant solution, 39 convolution, 237 critically damped, 99
i-function, 243 determinant, 136

Dirac delta, 243
eigenfunction, 188 eigenspace corresponding to an eigenvalue,
141 eigenvalue ­ of A, 140 ­ of a second order equation, 188 eigenvector, 140 elastic ­ beam, 132 ­ spring, 108 envelope of curves, 62 equation ­ autonomous, 17 ­ Bernoulli, 61 ­ Clairaut, 64 ­ D'Alambert-Lagrange, 67 ­ exact , 44 ­ homogeneous, 58 ­ in normal form, 15 ­ linear, 17 ­ linear second order, 79 ­ logistic, 42 ­ non-autonomous, 17 ­ nonlinear, 17 ­ of the pendulum, 97 ­ with constant coefficients, 93 equilibrium solution, 39 Euler equation, 100 Euler's method, 294 Euler­Bernoulli beam equation, 132 exact differential, 44 exponential order, 226

© Springer International Publishing Switzerland 2015 S. Ahmad, A. Ambrosetti, A Textbook on Ordinary Differential Equations. 2nd Ed., UNITEXT ­ La Matematica per il 3+2 88, DOI 10.1007/978-3-319-16408-3

320 Index

focus, 259 forcing term ­ non resonant, 102, 105 ­ resonant, 102, 105 free harmonic oscillator, 80 Frobenius method, 206 fundamental solutions, 87
general solution, 2, 6, 45 global existence ­ and uniqueness for first order equations,
24 ­ for n order equations, 75 ­ for systems, 73 globally lipschitzian, 30 gradient system, 264 Green function, 282
Hamiltonian system, 263 ­ planar, 168 harmonic oscillator, 79 Heaviside function, 227 higher order equations, 71 homoclinic, 184 homogeneous, 5 hyperbolic equilibrium, 267
improved Euler's method, 295 inclined plane, 103 indicial equation, 210 initial value ­ or Cauchy, problem for n order equations,
74 ­ problem, 2, 17 ­ problem for systems, 72 instability, 252 ­ of Lotka-Volterra system, 266 integrating factor, 5, 54 inverse of a matrix, 139
Jordan ­ matrix, 143 ­ normal form, 143 jump discontinuity, 226
k-homogeneous function, 59

linear ­ autonomous system, 72 ­ system, 71 linearized ­ stability, 265 ­ system, 265 linearly ­ dependent, 126 ­ dependent functions, 83 ­ independent, 126 ­ independent functions, 83 lipschitzian ­ globally, 30 ­ locally, 30 local existence ­ and uniqueness for first order equations,
18 ­ for n order equation, 75 ­ for systems, 73 locally lipschitzian, 30 locally lipschitzian, of vector valued
functions, 73 logistic equation, 4, 42 Lotka Volterra system, 170
Malthusian model, 3, 41 matrix ­ cofactor, 137 ­ column vector, 135 ­ eigenvalue, 140 ­ eigenvector, 140 ­ inverse, 139 ­ minor, 137 ­ product, 136 ­ row vector, 135 minor, 137
n-th order equations in normal form, 74 node ­ stable, 256 ­ unstable, 256 nonhomogeneous, 5 ­ system, 158 nonlinear ­ eigenvalue problem, 289 ­ second order equations, 116 normal form, 15

L-transform, region of convergence, 225 Liapunov function, 252

ordinary point, 201 overdamped, 99

Peano Theorem, 24 periodic solution, 181 phase plane, 179 piecewise continuous, 226 pitchfork bifurcation, 266 Poincare inequality, 191 population dynamics, 3 power series, 199 prey-predator system, 170 Principle of Superposition, 83
qualitative properties, 25
radius of convergence, 200 ratio test, 200 Rayleigh Quotient, 191 RC circuit, 4, 233, 245, 246 reduction of order, 88 RLC circuit, 98 Runge­Kutta method, 298
saddle, 256 second order differential equation in normal
form, 74 separable equation, 39 separation of the variables, 194 shifted ­ delta function, 244 ­ Heaviside function, 244 shifting indices, 199 singular ­ point, 24, 79, 201 ­ solution, 62 singularity, 24

Index 321
solution ­ in generalized sense, 245, 246 ­ maximal interval of definition, 21 stability, 252 ­ definition, 252 ­ of the Lotka-Volterra system, 253 ­ of Van der Pol system, 265 stable manifold, 270 step function, 227 Sturm Comparison Theorem, 112 Sturm Separation Theorem, 111 system ­ homogeneous, 146 ­ in normal form, 71, 73 ­ nonhomogeneous, 146 ­ of differential equations, 71
Taylor expansion, 200 total energy, 179 trace of a matrix, 150
underdamped, 100 undetermined coefficients, 101, 131, 158 uniqueness ­ for n order equations, 75 ­ for systems, 73 unstable manifold, 270
variation of parameters, 91, 130, 160 variational characterization of the first
eigenvalue, 190
Wronskian, 85, 148

Collana Unitext ­ La Matematica per il 3+2
Series Editors: A. Quarteroni (Editor-in-Chief) L. Ambrosio P. Biscari C. Ciliberto M. Ledoux W.J. Runggaldier
Editor at Springer: F. Bonadei francesca.bonadei@springer.com
As of 2004, the books published in the series have been given a volume number. Titles in grey indicate editions out of print. As of 2011, the series also publishes books in English.
A. Bernasconi, B. Codenotti Introduzione alla complessità computazionale 1998, X+260 pp, ISBN 88-470-0020-3
A. Bernasconi, B. Codenotti, G. Resta Metodi matematici in complessità computazionale 1999, X+364 pp, ISBN 88-470-0060-2
E. Salinelli, F. Tomarelli Modelli dinamici discreti 2002, XII+354 pp, ISBN 88-470-0187-0
S. Bosch Algebra 2003, VIII+380 pp, ISBN 88-470-0221-4
S. Graffi, M. Degli Esposti Fisica matematica discreta 2003, X+248 pp, ISBN 88-470-0212-5

S. Margarita, E. Salinelli MultiMath ­ Matematica Multimediale per l'Università 2004, XX+270 pp, ISBN 88-470-0228-1
A. Quarteroni, R. Sacco, F.Saleri Matematica numerica (2a Ed.) 2000, XIV+448 pp, ISBN 88-470-0077-7 2002, 2004 ristampa riveduta e corretta (1a edizione 1998, ISBN 88-470-0010-6)
13. A. Quarteroni, F. Saleri Introduzione al Calcolo Scientifico (2a Ed.) 2004, X+262 pp, ISBN 88-470-0256-7 (1a edizione 2002, ISBN 88-470-0149-8)
14. S. Salsa Equazioni a derivate parziali - Metodi, modelli e applicazioni 2004, XII+426 pp, ISBN 88-470-0259-1
15. G. Riccardi Calcolo differenziale ed integrale 2004, XII+314 pp, ISBN 88-470-0285-0
16. M. Impedovo Matematica generale con il calcolatore 2005, X+526 pp, ISBN 88-470-0258-3
17. L. Formaggia, F. Saleri, A. Veneziani Applicazioni ed esercizi di modellistica numerica per problemi differenziali 2005, VIII+396 pp, ISBN 88-470-0257-5
18. S. Salsa, G. Verzini Equazioni a derivate parziali ­ Complementi ed esercizi 2005, VIII+406 pp, ISBN 88-470-0260-5 2007, ristampa con modifiche
19. C. Canuto, A. Tabacco Analisi Matematica I (2a Ed.) 2005, XII+448 pp, ISBN 88-470-0337-7 (1a edizione, 2003, XII+376 pp, ISBN 88-470-0220-6)

20. F. Biagini, M. Campanino Elementi di Probabilità e Statistica 2006, XII+236 pp, ISBN 88-470-0330-X
21. S. Leonesi, C. Toffalori Numeri e Crittografia 2006, VIII+178 pp, ISBN 88-470-0331-8
22. A. Quarteroni, F. Saleri Introduzione al Calcolo Scientifico (3a Ed.) 2006, X+306 pp, ISBN 88-470-0480-2
23. S. Leonesi, C. Toffalori Un invito all'Algebra 2006, XVII+432 pp, ISBN 88-470-0313-X
24. W.M. Baldoni, C. Ciliberto, G.M. Piacentini Cattaneo Aritmetica, Crittografia e Codici 2006, XVI+518 pp, ISBN 88-470-0455-1
25. A. Quarteroni Modellistica numerica per problemi differenziali (3a Ed.) 2006, XIV+452 pp, ISBN 88-470-0493-4 (1a edizione 2000, ISBN 88-470-0108-0) (2a edizione 2003, ISBN 88-470-0203-6)
26. M. Abate, F. Tovena Curve e superfici 2006, XIV+394 pp, ISBN 88-470-0535-3
27. L. Giuzzi Codici correttori 2006, XVI+402 pp, ISBN 88-470-0539-6
28. L. Robbiano Algebra lineare 2007, XVI+210 pp, ISBN 88-470-0446-2
29. E. Rosazza Gianin, C. Sgarra Esercizi di finanza matematica 2007, X+184 pp, ISBN 978-88-470-0610-2

30. A. Machì Gruppi ­ Una introduzione a idee e metodi della Teoria dei Gruppi 2007, XII+350 pp, ISBN 978-88-470-0622-5 2010, ristampa con modifiche
31 Y. Biollay, A. Chaabouni, J. Stubbe Matematica si parte! A cura di A. Quarteroni 2007, XII+196 pp, ISBN 978-88-470-0675-1
32. M. Manetti Topologia 2008, XII+298 pp, ISBN 978-88-470-0756-7
33. A. Pascucci Calcolo stocastico per la finanza 2008, XVI+518 pp, ISBN 978-88-470-0600-3
34. A. Quarteroni, R. Sacco, F. Saleri Matematica numerica (3a Ed.) 2008, XVI+510 pp, ISBN 978-88-470-0782-6
35. P. Cannarsa, T. D'Aprile Introduzione alla teoria della misura e all'analisi funzionale 2008, XII+268 pp, ISBN 978-88-470-0701-7
36. A. Quarteroni, F. Saleri Calcolo scientifico (4a Ed.) 2008, XIV+358 pp, ISBN 978-88-470-0837-3
37. C. Canuto, A. Tabacco Analisi Matematica I (3a Ed.) 2008, XIV+452 pp, ISBN 978-88-470-0871-3
38. S. Gabelli Teoria delle Equazioni e Teoria di Galois 2008, XVI+410 pp, ISBN 978-88-470-0618-8
39. A. Quarteroni Modellistica numerica per problemi differenziali (4a Ed.) 2008, XVI+560 pp, ISBN 978-88-470-0841-0

40. C. Canuto, A. Tabacco Analisi Matematica II 2008, XVI+536 pp, ISBN 978-88-470-0873-1 2010, ristampa con modifiche
41. E. Salinelli, F. Tomarelli Modelli Dinamici Discreti (2a Ed.) 2009, XIV+382 pp, ISBN 978-88-470-1075-8
42. S. Salsa, F.M.G. Vegni, A. Zaretti, P. Zunino Invito alle equazioni a derivate parziali 2009, XIV+440 pp, ISBN 978-88-470-1179-3
43. S. Dulli, S. Furini, E. Peron Data mining 2009, XIV+178 pp, ISBN 978-88-470-1162-5
44. A. Pascucci, W.J. Runggaldier Finanza Matematica 2009, X+264 pp, ISBN 978-88-470-1441-1
45. S. Salsa Equazioni a derivate parziali ­ Metodi, modelli e applicazioni (2a Ed.) 2010, XVI+614 pp, ISBN 978-88-470-1645-3
46. C. D'Angelo, A. Quarteroni Matematica Numerica ­ Esercizi, Laboratori e Progetti 2010, VIII+374 pp, ISBN 978-88-470-1639-2
47. V. Moretti Teoria Spettrale e Meccanica Quantistica ­ Operatori in spazi di Hilbert 2010, XVI+704 pp, ISBN 978-88-470-1610-1
48. C. Parenti, A. Parmeggiani Algebra lineare ed equazioni differenziali ordinarie 2010, VIII+208 pp, ISBN 978-88-470-1787-0
49. B. Korte, J. Vygen Ottimizzazione Combinatoria. Teoria e Algoritmi 2010, XVI+662 pp, ISBN 978-88-470-1522-7
50. D. Mundici Logica: Metodo Breve 2011, XII+126 pp, ISBN 978-88-470-1883-9

51. E. Fortuna, R. Frigerio, R. Pardini Geometria proiettiva. Problemi risolti e richiami di teoria 2011, VIII+274 pp, ISBN 978-88-470-1746-7
52. C. Presilla Elementi di Analisi Complessa. Funzioni di una variabile 2011, XII+324 pp, ISBN 978-88-470-1829-7
53. L. Grippo, M. Sciandrone Metodi di ottimizzazione non vincolata 2011, XIV+614 pp, ISBN 978-88-470-1793-1
54. M. Abate, F. Tovena Geometria Differenziale 2011, XIV+466 pp, ISBN 978-88-470-1919-5
55. M. Abate, F. Tovena Curves and Surfaces 2011, XIV+390 pp, ISBN 978-88-470-1940-9
56. A. Ambrosetti Appunti sulle equazioni differenziali ordinarie 2011, X+114 pp, ISBN 978-88-470-2393-2
57. L. Formaggia, F. Saleri, A. Veneziani Solving Numerical PDEs: Problems, Applications, Exercises 2011, X+434 pp, ISBN 978-88-470-2411-3
58. A. Machì Groups. An Introduction to Ideas and Methods of the Theory of Groups 2011, XIV+372 pp, ISBN 978-88-470-2420-5
59. A. Pascucci, W.J. Runggaldier Financial Mathematics. Theory and Problems for Multi-period Models 2011, X+288 pp, ISBN 978-88-470-2537-0
60. D. Mundici Logic: a Brief Course 2012, XII+124 pp, ISBN 978-88-470-2360-4
61. A. Machì Algebra for Symbolic Computation 2012, VIII+174 pp, ISBN 978-88-470-2396-3

62. A. Quarteroni, F. Saleri, P. Gervasio Calcolo Scientifico (5a ed.) 2012, XVIII+450 pp, ISBN 978-88-470-2744-2
63. A. Quarteroni Modellistica Numerica per Problemi Differenziali (5a ed.) 2012, XVIII+628 pp, ISBN 978-88-470-2747-3
64. V. Moretti Spectral Theory and Quantum Mechanics With an Introduction to the Algebraic Formulation 2013, XVI+728 pp, ISBN 978-88-470-2834-0
65. S. Salsa, F.M.G. Vegni, A. Zaretti, P. Zunino A Primer on PDEs. Models, Methods, Simulations 2013, XIV+482 pp, ISBN 978-88-470-2861-6
66. V.I. Arnold Real Algebraic Geometry 2013, X+110 pp, ISBN 978-3-642­36242-2
67. F. Caravenna, P. Dai Pra Probabilità. Un'introduzione attraverso modelli e applicazioni 2013, X+396 pp, ISBN 978-88-470-2594-3
68. A. de Luca, F. D'Alessandro Teoria degli Automi Finiti 2013, XII+316 pp, ISBN 978-88-470-5473-8
69. P. Biscari, T. Ruggeri, G. Saccomandi, M. Vianello Meccanica Razionale 2013, XII+352 pp, ISBN 978-88-470-5696-3
70. E. Rosazza Gianin, C. Sgarra Mathematical Finance: Theory Review and Exercises. From Binomial Model to Risk Measures 2013, X+278 pp, ISBN 978-3-319-01356-5
71. E. Salinelli, F. Tomarelli Modelli Dinamici Discreti (3a Ed.) 2014, XVI+394 pp, ISBN 978-88-470-5503-2

72. C. Presilla Elementi di Analisi Complessa. Funzioni di una variabile (2a Ed.) 2014, XII+360 pp, ISBN 978-88-470-5500-1
73. S. Ahmad, A. Ambrosetti A Textbook on Ordinary Differential Equations 2014, XIV+324 pp, ISBN 978-3-319-02128-7
74. A. Bermúdez, D. Gómez, P. Salgado Mathematical Models and Numerical Simulation in Electromagnetism 2014, XVIII+430 pp, ISBN 978-3-319-02948-1
75. A. Quarteroni Matematica Numerica. Esercizi, Laboratori e Progetti (2a Ed.) 2013, XVIII+406 pp, ISBN 978-88-470-5540-7
76. E. Salinelli, F. Tomarelli Discrete Dynamical Models 2014, XVI+386 pp, ISBN 978-3-319-02290-1
77. A. Quarteroni, R. Sacco, F. Saleri, P. Gervasio Matematica Numerica (4a Ed.) 2014, XVIII+532 pp, ISBN 978-88-470-5643-5
78. M. Manetti Topologia (2a Ed.) 2014, XII+334 pp, ISBN 978-88-470-5661-9
79. M. Iannelli, A. Pugliese An Introduction to Mathematical Population Dynamics. Along the trail of Volterra and Lotka 2014, XIV+338 pp, ISBN 978-3-319-03025-8
80. V. M. Abrusci, L. Tortora de Falco Logica. Volume 1 2014, X+180 pp, ISBN 978-88-470-5537-7
81. P. Biscari, T. Ruggeri, G. Saccomandi, M. Vianello Meccanica Razionale (2a Ed.) 2014, XII+390 pp, ISBN 978-88-470-5725-8
82. C. Canuto, A. Tabacco Analisi Matematica I (4a Ed.) 2014, XIV+508 pp, ISBN 978-88-470-5722-7

83. C. Canuto, A. Tabacco Analisi Matematica II (2a Ed.) 2014, XII+576 pp, ISBN 978-88-470-5728-9
84. C. Canuto, A. Tabacco Mathematical Analysis I (2nd Ed.) 2015, XIV+484 pp, ISBN 978-3-319-12771-2
85. C. Canuto, A. Tabacco Mathematical Analysis II (2nd Ed.) 2015, XII+550 pp, ISBN 978-3-319-12756-9
86. S. Salsa Partial Differential Equations in Action. From Modelling to Theory (2nd Ed.) 2015, XVIII+688 pp, ISBN 978-3-319-15092-5
87. S. Salsa, G. Verzini Partial Differential Equations in Action. Complements and Exercises 2015, VIII+422 pp, ISBN 978-3-319-15415-2
88. S. Ahmad, A. Ambrosetti A Textbook on Ordinary Differential Equations (2nd Ed.) 2015, XIV+322 pp, ISBN 978-3-319-16407-6
The online version of the books published in this series is available at SpringerLink. For further information, please visit the following link: http://www.springer.com/series/5418

